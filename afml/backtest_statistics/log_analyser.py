import json
from pathlib import Path
from typing import Dict, Union

import pandas as pd


def load_model_logs(log_path: Union[str, Path]) -> Dict[str, pd.DataFrame]:
    """
    Loads structured JSONL logs into human-readable pandas DataFrames.

    It processes logs generated by performance_analysis.py, separating them
    by event type into distinct DataFrames.

    Args:
        log_path: Path to a single .jsonl log file or a directory containing log files.

    Returns:
        A dictionary of pandas DataFrames, keyed by the log event type
        (e.g., 'model_configuration', 'performance_results', 'trade_decisions').
    """
    path = Path(log_path)
    if path.is_dir():
        log_files = sorted(path.glob("*.jsonl"))
    else:
        log_files = [path]

    if not log_files:
        print(f"No .jsonl files found in '{log_path}'")
        return {}

    # Hold records for each event type before converting to DataFrame
    records = {
        "model_configuration": [],
        "performance_results": [],
        "trade_decisions": [],
    }

    for file in log_files:
        with open(file, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    log_entry = json.loads(line)

                    # The actual log content is in the 'message' field
                    message = log_entry.get("message", {})

                    # Check for batched trade decisions
                    if message.get("batch_event") == "trade_decisions":
                        records["trade_decisions"].extend(message.get("trades", []))
                    # Check for other event types
                    elif "event" in message:
                        event_type = message["event"]
                        if event_type in records:
                            records[event_type].append(message)

                except (json.JSONDecodeError, TypeError):
                    # Silently ignore lines that are not valid JSON or not structured as expected
                    continue

    # Convert lists of records into DataFrames
    dataframes = {}
    if records["model_configuration"]:
        df = pd.json_normalize(records["model_configuration"], sep="_")
        df["timestamp"] = pd.to_datetime(df["timestamp"])
        dataframes["model_configuration"] = df.set_index("timestamp")

    if records["performance_results"]:
        df = pd.json_normalize(records["performance_results"], sep="_")
        df["timestamp"] = pd.to_datetime(df["timestamp"])
        dataframes["performance_results"] = df.set_index("timestamp")

    if records["trade_decisions"]:
        df = pd.DataFrame(records["trade_decisions"])
        df["timestamp"] = pd.to_datetime(df["timestamp"])
        dataframes["trade_decisions"] = df.set_index("timestamp")

    print(f"âœ… Loaded logs from {len(log_files)} file(s). Found:")
    for name, df in dataframes.items():
        print(f"  - {len(df)} '{name}' records.")

    return dataframes


# Example Usage:
#
# # Load all logs from the 'logs' directory
# all_logs = load_model_logs('logs/')
#
# # Access a specific DataFrame
# if 'performance_results' in all_logs:
#     results_df = all_logs['performance_results']
#     print("\nPerformance Results:")
#     print(results_df[['strategy_name', 'meta_metrics_sharpe_ratio', 'primary_metrics_sharpe_ratio']].head())
