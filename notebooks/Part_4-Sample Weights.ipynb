{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883cfcc8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Meta-Labeling Experiments: A Step-by-Step Guide\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook recreates the meta-labeling experiments from Hudson & Thames' research in a beginner-friendly manner. Meta-labeling is a machine learning technique that sits on top of a primary trading strategy to improve performance by filtering out false positive signals.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Primary Model**: Generates trading signals (buy/sell/hold)\n",
    "- **Triple Barrier Method**: Advanced labeling technique that accounts for stop-loss, take-profit, and time-based exits\n",
    "- **Meta-Labeling**: Secondary ML model that decides whether to act on primary model signals\n",
    "- **Goal**: Improve Sharpe ratio, reduce drawdown, and increase precision\n",
    "\n",
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607009b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 15:00:29.263\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m386\u001b[0m - \u001b[34m\u001b[1mAuto-reload functionality available\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:29.265\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m688\u001b[0m - \u001b[34m\u001b[1mEnhanced cache features available:\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:29.266\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m689\u001b[0m - \u001b[34m\u001b[1m  - Robust cache keys for NumPy/Pandas\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:29.268\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m690\u001b[0m - \u001b[34m\u001b[1m  - MLflow integration: ✓\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:29.271\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m691\u001b[0m - \u001b[34m\u001b[1m  - Backtest caching: ✓\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:29.273\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m692\u001b[0m - \u001b[34m\u001b[1m  - Cache monitoring: ✓\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:30.191\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m_configure_numba\u001b[0m:\u001b[36m59\u001b[0m - \u001b[34m\u001b[1mNumba cache configured: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\numba_cache\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:30.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mAFML cache system initialized:\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:30.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m  Joblib cache: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\joblib_cache\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:30.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1m  Numba cache: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\numba_cache\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:31.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache.selective_cleaner\u001b[0m:\u001b[36m_load_tracking_data\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mLoaded tracking data for 17 functions\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.163\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mImported lightweight modules directly\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m486\u001b[0m - \u001b[1mAFML v1.0.0 ready - 10 heavy modules available for lazy loading\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.178\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m489\u001b[0m - \u001b[34m\u001b[1mCache status: Hit rate: 0.0% | Tracked functions: 0 | Heavy modules loaded: 0\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.182\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m493\u001b[0m - \u001b[34m\u001b[1m✓ Cache monitoring available\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m495\u001b[0m - \u001b[34m\u001b[1m✓ MLflow integration available\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.187\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m497\u001b[0m - \u001b[34m\u001b[1m✓ Backtest caching available\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36msetup_jupyter\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mSetting up AFML for Jupyter notebook...\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36msetup_jupyter_cache\u001b[0m:\u001b[36m583\u001b[0m - \u001b[1mSetting up cache for Jupyter notebook...\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.201\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m_configure_numba\u001b[0m:\u001b[36m59\u001b[0m - \u001b[34m\u001b[1mNumba cache configured: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\numba_cache\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mAFML cache system initialized:\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m  Joblib cache: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\joblib_cache\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1m  Numba cache: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\numba_cache\u001b[0m\n",
      "2025/11/01 15:00:39 INFO mlflow.tracking.fluent: Experiment with name 'jupyter_experiments' does not exist. Creating a new experiment.\n",
      "\u001b[32m2025-11-01 15:00:39.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache.mlflow_integration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mMLflow tracking enabled: experiment=jupyter_experiments\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36msetup_jupyter_cache\u001b[0m:\u001b[36m613\u001b[0m - \u001b[1m✅ Jupyter cache ready!\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36msetup_jupyter_cache\u001b[0m:\u001b[36m614\u001b[0m - \u001b[1m   Use helpers: cache_status(), print_health(), optimize()\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache.auto_reload\u001b[0m:\u001b[36mstart_watching\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mWatching for changes: C:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache.auto_reload\u001b[0m:\u001b[36mstart_watching\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mWatching for changes: C:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36msetup_jupyter\u001b[0m:\u001b[36m299\u001b[0m - \u001b[1mAuto-reload enabled\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:39.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36msetup_jupyter\u001b[0m:\u001b[36m318\u001b[0m - \u001b[1m✅ AFML Jupyter environment ready!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Dir: c:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# --- Extension Setup ---\n",
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 3 -p\n",
    "\n",
    "# --- Module Imports ---\n",
    "import sys\n",
    "sys.path.append(\"..\")  # Adjust if your afml repo is nested differently\n",
    "\n",
    "# --- Autoreload Target ---\n",
    "%aimport afml\n",
    "\n",
    "# --- AFML Initialization ---\n",
    "# Setup with auto-reload enabled\n",
    "import afml\n",
    "\n",
    "# Enhanced setup with all features\n",
    "components = afml.setup_jupyter(\n",
    "    enable_mlflow=True,      # Set True if you have mlflow installed\n",
    "    enable_monitoring=True,    # Cache analytics\n",
    "    enable_auto_reload=True    # Auto-reload on file changes\n",
    ")\n",
    "\n",
    "# # --- Logging (Optional but Recommended) ---\n",
    "# from loguru import logger\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Optional: clear old logs\n",
    "# log_path = Path(\"logs\") / \"afml_session.log\"\n",
    "# log_path.parent.mkdir(exist_ok=True)\n",
    "# log_path.unlink(missing_ok=True)\n",
    "\n",
    "# # Configure Loguru\n",
    "# logger.add(log_path, level=\"INFO\", rotation=\"10 MB\", retention=\"10 days\")\n",
    "# logger.info(\"Session started\")\n",
    "\n",
    "# --- Environment Diagnostics ---\n",
    "from pathlib import Path\n",
    "print(f\"Working Dir: {Path.cwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2507ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import winsound\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import MetaTrader5 as mt5\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from afml.cache import cache_maintenance\n",
    "from afml.cross_validation import (\n",
    "    PurgedKFold,\n",
    "    PurgedSplit,\n",
    "    analyze_cross_val_scores,\n",
    "    ml_cross_val_score,\n",
    "    probability_weighted_accuracy,\n",
    ")\n",
    "from afml.cross_validation.scoring import probability_weighted_accuracy\n",
    "from afml.data_structures.bars import *\n",
    "from afml.ensemble.sb_bagging import (\n",
    "    SequentiallyBootstrappedBaggingClassifier,\n",
    "    compute_custom_oob_metrics,\n",
    ")\n",
    "from afml.labeling.triple_barrier import (\n",
    "    add_vertical_barrier,\n",
    "    get_event_weights,\n",
    "    triple_barrier_labels,\n",
    ")\n",
    "from afml.mt5.load_data import get_bars, login_mt5\n",
    "from afml.sample_weights.optimized_attribution import (\n",
    "    get_weights_by_time_decay_optimized,\n",
    ")\n",
    "\n",
    "# from afml.sampling import get_ind_mat_average_uniqueness, get_ind_matrix, seq_bootstrap\n",
    "from afml.strategies import (\n",
    "    BollingerStrategy,\n",
    "    MACrossoverStrategy,\n",
    "    create_bollinger_features,\n",
    "    get_entries,\n",
    ")\n",
    "from afml.util import get_daily_vol, value_counts_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.style.use(\"dark_background\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41127511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CACHE HEALTH REPORT\n",
      "======================================================================\n",
      "\n",
      "Overall Statistics:\n",
      "  Total Functions:     0\n",
      "  Total Calls:         0\n",
      "  Overall Hit Rate:    0.0%\n",
      "  Total Cache Size:    0.00 MB\n",
      "\n",
      "Recommendations:\n",
      "  1. No cached functions found. Start using @cacheable decorators.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add to your startup script or notebook\n",
    "from afml.cache import print_cache_health\n",
    "\n",
    "# Check cache health anytime\n",
    "print_cache_health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c50509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afml.cache import get_cache_efficiency_report\n",
    "\n",
    "# Find functions with low hit rates or high call counts\n",
    "df = get_cache_efficiency_report()\n",
    "if not df.empty:\n",
    "    df.sort_values('calls', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963854bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afml.numba_warmup import register_numba_dummy\n",
    "\n",
    "# register_numba_dummy(\n",
    "#     \"_precompute_active_indices_nopython\",\n",
    "#     args=(np.array([np.int64(0)]), np.array([np.int64(0)]), np.array([np.int64(0)])),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160822e7",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f257b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"EURUSD\"\n",
    "start_date, end_date = \"2018-01-01\", \"2024-12-31\"\n",
    "sample_start, sample_end = start_date, \"2023-12-31\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129c536",
   "metadata": {},
   "source": [
    "## 2. Bollinger Band Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_timeframe = \"M5\"\n",
    "file = Path(r\"..\\data\\EURUSD_M5_time_2018-01-01-2024-12-31.parq\")\n",
    "bb_time_bars = pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_period, bb_std = 20, 2 # Bollinger Band parameters\n",
    "bb_strategy = BollingerStrategy(window=bb_period, num_std=bb_std)\n",
    "bb_lookback = 10\n",
    "bb_pt_barrier, bb_sl_barrier, bb_time_horizon = (1, 2, dict(days=1))\n",
    "min_ret = 5e-5\n",
    "bb_vol_multiplier = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83dccff",
   "metadata": {},
   "source": [
    "### Time-Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d9465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bollinger_w20_std2 Signals:\n",
      "\n",
      "        count  proportion\n",
      "side                     \n",
      " 0    373,536    0.842213\n",
      "-1     35,095    0.079129\n",
      " 1     34,886    0.078658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 15:00:46.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.filters.filters\u001b[0m:\u001b[36mcusum_filter\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1m19,458 CUSUM-filtered events\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:46.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.strategies.signal_processing\u001b[0m:\u001b[36mget_entries\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mBollinger_w20_std2 | 10,384 (14.84%) trade events selected by CUSUM filter using series.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "bb_side = bb_strategy.generate_signals(bb_time_bars)\n",
    "bb_df = bb_time_bars.loc[sample_start : sample_end]\n",
    "\n",
    "print(f\"{bb_strategy.get_strategy_name()} Signals:\")\n",
    "value_counts_data(bb_side.reindex(bb_df.index), verbose=True)\n",
    "\n",
    "# Volatility target for barriers\n",
    "vol_lookback = 100\n",
    "vol_target = get_daily_vol(bb_df.close, vol_lookback) * bb_vol_multiplier\n",
    "close = bb_df.close\n",
    "_, t_events = get_entries(bb_strategy, bb_df, filter_threshold=vol_target)\n",
    "\n",
    "vertical_barriers = add_vertical_barrier(t_events, close, **bb_time_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ada8a2",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d09b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-01 15:00:55.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.features.moving_averages\u001b[0m:\u001b[36mcalculate_ma_differences\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m\n",
      "Dropped features with correlation > 0.75: \n",
      "\t['sma_diff_10_200', 'sma_diff_10_50', 'sma_diff_20_100', 'sma_diff_20_200', 'sma_diff_20_50', 'sma_diff_50_100', 'sma_diff_50_200']\n",
      "Kept features: \n",
      "\t['sma_diff_10_20', 'sma_diff_10_100', 'sma_diff_100_200']\u001b[0m\n",
      "\u001b[32m2025-11-01 15:00:56.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.features.moving_averages\u001b[0m:\u001b[36mget_ma_crossovers\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1m\n",
      "Dropped features with correlation > 0.75: \n",
      "\t['sma_cross_20_100', 'sma_cross_20_200', 'sma_cross_20_50', 'sma_cross_50_200']\n",
      "Kept features: \n",
      "\t['sma_cross_10_20', 'sma_cross_10_50', 'sma_cross_10_100', 'sma_cross_10_200', 'sma_cross_50_100', 'sma_cross_100_200']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 516825 entries, 2018-01-02 23:20:00 to 2024-12-31 00:00:00\n",
      "Data columns (total 49 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   spread               516825 non-null  float32\n",
      " 1   vol                  516825 non-null  float32\n",
      " 2   h1_vol               516825 non-null  float32\n",
      " 3   h4_vol               516825 non-null  float32\n",
      " 4   d1_vol               516825 non-null  float32\n",
      " 5   ret                  516825 non-null  float32\n",
      " 6   ret_5                516825 non-null  float32\n",
      " 7   ret_10               516825 non-null  float32\n",
      " 8   ret_1_lag_1          516825 non-null  float32\n",
      " 9   ret_5_lag_1          516825 non-null  float32\n",
      " 10  ret_10_lag_1         516825 non-null  float32\n",
      " 11  ret_1_lag_2          516825 non-null  float32\n",
      " 12  ret_5_lag_2          516825 non-null  float32\n",
      " 13  ret_10_lag_2         516825 non-null  float32\n",
      " 14  ret_1_lag_3          516825 non-null  float32\n",
      " 15  ret_5_lag_3          516825 non-null  float32\n",
      " 16  ret_10_lag_3         516825 non-null  float32\n",
      " 17  ret_skew             516825 non-null  float32\n",
      " 18  ret_kurt             516825 non-null  float32\n",
      " 19  autocorr             516825 non-null  float32\n",
      " 20  autocorr_1           516825 non-null  float32\n",
      " 21  autocorr_2           516825 non-null  float32\n",
      " 22  autocorr_3           516825 non-null  float32\n",
      " 23  autocorr_4           516825 non-null  float32\n",
      " 24  autocorr_5           516825 non-null  float32\n",
      " 25  bbb_20_2.0           516825 non-null  float32\n",
      " 26  bbp_20_2.0           516825 non-null  float64\n",
      " 27  truerange_1          516825 non-null  float32\n",
      " 28  atrr_14              516825 non-null  float32\n",
      " 29  rsi_14               516825 non-null  float32\n",
      " 30  stochrsik_14_14_3_3  516825 non-null  float32\n",
      " 31  stochrsid_14_14_3_3  516825 non-null  float32\n",
      " 32  adx_14               516825 non-null  float32\n",
      " 33  dmp_14               516825 non-null  float32\n",
      " 34  dmn_14               516825 non-null  float32\n",
      " 35  dm_net               516825 non-null  float32\n",
      " 36  macd_12_26_9         516825 non-null  float32\n",
      " 37  macdh_12_26_9        516825 non-null  float32\n",
      " 38  sma_diff_10_20       516825 non-null  float32\n",
      " 39  sma_diff_10_100      516825 non-null  float32\n",
      " 40  sma_diff_100_200     516825 non-null  float32\n",
      " 41  sma_cross_10_20      516825 non-null  int8   \n",
      " 42  sma_cross_10_50      516825 non-null  int8   \n",
      " 43  sma_cross_10_100     516825 non-null  int8   \n",
      " 44  sma_cross_10_200     516825 non-null  int8   \n",
      " 45  sma_cross_50_100     516825 non-null  int8   \n",
      " 46  sma_cross_100_200    516825 non-null  int8   \n",
      " 47  prev_signal          516825 non-null  int8   \n",
      " 48  side                 516825 non-null  int8   \n",
      "dtypes: float32(40), float64(1), int8(8)\n",
      "memory usage: 90.7 MB\n"
     ]
    }
   ],
   "source": [
    "bb_feat = create_bollinger_features(bb_time_bars, bb_period, bb_std)\n",
    "bb_feat_time = bb_feat.join(bb_side, how=\"inner\")\n",
    "bb_feat_time.info()\n",
    "# not_stationary = is_stationary(bb_feat_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1c961",
   "metadata": {},
   "source": [
    "#### Triple-Barrier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf6686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple-Barrier (pt=1, sl=2, h={'days': 1}):\n",
      "\n",
      "     count  proportion\n",
      "bin                   \n",
      "-1   5,109    0.505741\n",
      " 1   4,993    0.494259\n",
      "\n",
      "Average Uniqueness: 0.7465\n"
     ]
    }
   ],
   "source": [
    "bb_events_tb = triple_barrier_labels(\n",
    "    close,\n",
    "    vol_target,\n",
    "    t_events,\n",
    "    pt_sl=[bb_pt_barrier, bb_sl_barrier],\n",
    "    min_ret=min_ret,\n",
    "    vertical_barrier_times=vertical_barriers,\n",
    "    vertical_barrier_zero=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "bb_events_tb_time = bb_events_tb.copy()\n",
    "print(f\"Triple-Barrier (pt={bb_pt_barrier}, sl={bb_sl_barrier}, h={bb_time_horizon}):\")\n",
    "value_counts_data(bb_events_tb.bin, verbose=True)\n",
    "\n",
    "weights = get_event_weights(bb_events_tb, close)\n",
    "av_uniqueness = weights['tW'].mean()\n",
    "print(f\"Average Uniqueness: {av_uniqueness:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b85936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple-Barrier (pt=1, sl=2, h={'days': 1}):\n",
      "\n",
      "     count  proportion\n",
      "bin                   \n",
      "1    6,506    0.626601\n",
      "0    3,877    0.373399\n",
      "\n",
      "Average Uniqueness: 0.5488\n"
     ]
    }
   ],
   "source": [
    "bb_events_tb = triple_barrier_labels(\n",
    "    close,\n",
    "    vol_target,\n",
    "    t_events,\n",
    "    pt_sl=[bb_pt_barrier, bb_sl_barrier],\n",
    "    min_ret=min_ret,\n",
    "    vertical_barrier_times=vertical_barriers,\n",
    "    side_prediction=bb_side,\n",
    "    vertical_barrier_zero=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "bb_events_tb_time_meta = bb_events_tb.copy()\n",
    "print(f\"Triple-Barrier (pt={bb_pt_barrier}, sl={bb_sl_barrier}, h={bb_time_horizon}):\")\n",
    "value_counts_data(bb_events_tb.bin, verbose=True)\n",
    "\n",
    "weights = get_event_weights(bb_events_tb, close)\n",
    "av_uniqueness = weights['tW'].mean()\n",
    "print(f\"Average Uniqueness: {av_uniqueness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac89d4",
   "metadata": {},
   "source": [
    "#### Primary Model - CV of Weighting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83808c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "N_JOBS = cpu_count() - 1\n",
    "N_ESTIMATORS = 100\n",
    "random_state = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = bb_events_tb_time.copy()\n",
    "X = bb_feat_time.reindex(cont.index)\n",
    "y = cont[\"bin\"]\n",
    "t1 = cont[\"t1\"]\n",
    "\n",
    "test_size = 0.3\n",
    "\n",
    "train, test = PurgedSplit(t1, test_size).split(X)\n",
    "X_train, X_test, y_train, y_test = (\n",
    "        X.iloc[train],\n",
    "        X.iloc[test],\n",
    "        y.iloc[train],\n",
    "        y.iloc[test],\n",
    "    )\n",
    "\n",
    "cont_train = get_event_weights(cont.iloc[train], bb_df.close)\n",
    "bb_cont_train = cont_train.copy()\n",
    "\n",
    "n_splits = 5\n",
    "pct_embargo = 0.01\n",
    "cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Uniqueness in Training Set: 0.7440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['unweighted', 'uniqueness', 'return'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_u = cont_train.tW.mean()\n",
    "print(f\"Average Uniqueness in Training Set: {avg_u:.4f}\")\n",
    "weighting_schemes = {\n",
    "    \"unweighted\": pd.Series(1., index=cont_train.index),\n",
    "    \"uniqueness\": cont_train[\"tW\"],\n",
    "    \"return\": cont_train[\"w\"],\n",
    "    }\n",
    "\n",
    "decay_factors = [0.05, 0.25, 0.5, 0.75]\n",
    "time_decay_weights = {}\n",
    "for time_decay in decay_factors:\n",
    "    for linear in (1, 0):\n",
    "        decay_w = get_weights_by_time_decay_optimized(\n",
    "                    triple_barrier_events=cont,\n",
    "                    close_index=close.index,\n",
    "                    last_weight=time_decay,\n",
    "                    linear=linear,\n",
    "                    av_uniqueness=cont_train[\"tW\"],\n",
    "                )\n",
    "        method = \"linear\" if linear else \"exp\"\n",
    "        time_decay_weights[f\"{method}_time_decay_{time_decay}\"] = decay_w\n",
    "        \n",
    "# for k, v in time_decay_weights.items():\n",
    "#     if k.startswith(\"linear\"):\n",
    "#         weighting_schemes[k] = v\n",
    "\n",
    "weighting_schemes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beab8ff",
   "metadata": {},
   "source": [
    "##### Selection of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c2bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standard': RandomForestClassifier(criterion='entropy', max_depth=6,\n",
       "                        min_weight_fraction_leaf=0.05, n_jobs=3, random_state=7),\n",
       " 'balanced_subsample': RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
       "                        max_depth=6, min_weight_fraction_leaf=0.05, n_jobs=3,\n",
       "                        random_state=7),\n",
       " 'max_samples': RandomForestClassifier(criterion='entropy', max_depth=6,\n",
       "                        max_samples=0.7440101296064058,\n",
       "                        min_weight_fraction_leaf=0.05, n_jobs=3, random_state=7),\n",
       " 'combined': RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
       "                        max_depth=6, max_samples=0.7440101296064058,\n",
       "                        min_weight_fraction_leaf=0.05, n_jobs=3, random_state=7)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_w_leaf = 0.05\n",
    "max_depth = 6\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    random_state=random_state,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    n_jobs=N_JOBS,  # Use all available cores\n",
    "    )\n",
    "\n",
    "clf0 = rf\n",
    "clf1 = clone(rf).set_params(class_weight='balanced_subsample')\n",
    "clf2 = clone(rf).set_params(max_samples=avg_u)\n",
    "clf3 = clone(rf).set_params(max_samples=avg_u, class_weight='balanced_subsample')\n",
    "\n",
    "clfs = {k: v for k, v in zip(['standard', 'balanced_subsample', 'max_samples', 'combined'], [clf0, clf1, clf2, clf3])}\n",
    "clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06278dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Weighting Schemes\n",
      "return standard model achieved the best neg_log_loss score of -0.6612\n",
      "None standard model achieved the best neg_log_loss score of -0.6612\n",
      "\n",
      "                          unweighted        uniqueness            return\n",
      "standard            -0.6945 ± 0.0014  -0.6943 ± 0.0016  -0.6612 ± 0.0044\n",
      "balanced_subsample  -0.6943 ± 0.0008  -0.6941 ± 0.0014  -0.6612 ± 0.0048\n",
      "max_samples         -0.6945 ± 0.0015  -0.6943 ± 0.0016  -0.6612 ± 0.0047\n",
      "combined            -0.6943 ± 0.0012  -0.6941 ± 0.0012  -0.6613 ± 0.0052\n",
      "\n",
      "Selected Best Classifier (standard): RandomForestClassifier(criterion='entropy', max_depth=6,\n",
      "                       min_weight_fraction_leaf=0.05, n_jobs=3, random_state=7)\n"
     ]
    }
   ],
   "source": [
    "cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)\n",
    "cv_scores_d = {k: {} for k in clfs.keys()}\n",
    "print(rf.__class__.__name__, \"Weighting Schemes\")\n",
    "all_clf_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "best_models = []\n",
    "best_score, best_model, best_scheme = None, None, None\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    for param, clf in clfs.items():\n",
    "        w = sample_weights.values\n",
    "        cv_scores = ml_cross_val_score(\n",
    "            clf, X_train, y_train, cv_gen, \n",
    "            sample_weight_train=w, \n",
    "            sample_weight_score=w,\n",
    "            scoring=\"neg_log_loss\",\n",
    "        )\n",
    "        score = cv_scores.mean()\n",
    "        cv_scores_d[param][scheme] = score\n",
    "        best_score = max(best_score, score) if best_score is not None else score\n",
    "        if score == best_score:\n",
    "            best_model = param\n",
    "            best_scheme = scheme\n",
    "        all_clf_scores_df.loc[param, scheme] = f\"{cv_scores.mean():.4f} ± {cv_scores.std():.4f}\"\n",
    "print(f\"{best_scheme} {best_model} model achieved the best neg_log_loss score of {best_score:.4f}\")\n",
    "    # best_models.append(best_model)\n",
    "\n",
    "best_decay = None\n",
    "for scheme, decay_factor in time_decay_weights.items():\n",
    "    if scheme.startswith(\"linear\"):\n",
    "        sample_weights = weighting_schemes[best_scheme] * decay_factor\n",
    "        w = sample_weights.values\n",
    "        cv_scores = ml_cross_val_score(\n",
    "            clf, X_train, y_train, cv_gen, \n",
    "            sample_weight_train=w, \n",
    "            sample_weight_score=w,\n",
    "            scoring=\"neg_log_loss\",\n",
    "        )\n",
    "        score = cv_scores.mean()\n",
    "        decay_scheme = f\"{best_scheme}_{scheme}\"\n",
    "        # cv_scores_d[best_model][decay_scheme] = score\n",
    "        best_score = max(best_score, score) if best_score is not None else score\n",
    "        if score == best_score:\n",
    "            best_decay = decay_scheme\n",
    "print(f\"{best_decay} {best_model} model achieved the best neg_log_loss score of {best_score:.4f}\\n\")\n",
    "        \n",
    "\n",
    "pprint(all_clf_scores_df, sort_dicts=False)\n",
    "# best_model = max(best_models, key=best_models.count)\n",
    "best_clf = clone(clfs[best_model])\n",
    "print(f\"\\nSelected Best Classifier ({best_model}): {best_clf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311350fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    unweighted        uniqueness            return\n",
      "accuracy       0.5014 ± 0.0165   0.4966 ± 0.0167   0.6254 ± 0.0143\n",
      "pwa            0.5003 ± 0.0115   0.5048 ± 0.0158   0.6351 ± 0.0107\n",
      "neg_log_loss  -0.6945 ± 0.0014  -0.6943 ± 0.0016  -0.6612 ± 0.0044\n",
      "precision      0.4926 ± 0.0249   0.4880 ± 0.0229   0.6205 ± 0.0266\n",
      "recall         0.3727 ± 0.0804   0.3947 ± 0.0866   0.6056 ± 0.0210\n",
      "f1             0.4172 ± 0.0581   0.4287 ± 0.0600   0.6128 ± 0.0215\n",
      "\n",
      "return model achieved the best neg_log_loss score of -0.6612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from afml.cross_validation.cross_validation import analyze_cross_val_scores\n",
    "\n",
    "all_cv_scores_d = {}\n",
    "all_cms = {}\n",
    "best_score, best_model = None, None\n",
    "all_cv_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "scoring = 'f1' if set(y_train.unique()) == {0, 1} else 'neg_log_loss'\n",
    "# best_clf = clfs['balanced_subsample']\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    w = sample_weights.values\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        best_clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    score = cv_scores[scoring].mean()\n",
    "    all_cv_scores_d[scheme] = cv_scores\n",
    "    all_cms[scheme] = cms\n",
    "    best_score = max(best_score, score) if best_score is not None else score\n",
    "    if score == best_score:\n",
    "        best_model = scheme\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores_df.loc[idx, scheme] = f\"{row['mean']:.4f} ± {row['std']:.4f}\"\n",
    "\n",
    "pprint(all_cv_scores_df)\n",
    "print(f\"\\n{best_model} model achieved the best {scoring} score of {best_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rf = SequentiallyBootstrappedBaggingClassifier(\n",
    "    samples_info_sets=cont_train.t1,\n",
    "    price_bars_index=bb_df.index,\n",
    "    estimator=None,\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    max_features=1,\n",
    "    bootstrap_features=False,\n",
    "    oob_score=True,\n",
    "    # max_samples=avg_u,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    verbose=False,\n",
    ")\n",
    "# seq_rf_bf = clone(seq_rf).set_params(bootstrap_features=True) # bootstrap_features\n",
    "\n",
    "w = weighting_schemes[best_scheme].values\n",
    "cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        seq_rf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "all_cms[scheme] = cms\n",
    "\n",
    "scheme = 'seq_bootstrap'\n",
    "for idx, row in cv_scores_df.iterrows():\n",
    "    all_cv_scores_df.loc[idx, scheme] = f\"{row['mean']:.4f} ± {row['std']:.4f}\"\n",
    "\n",
    "pprint(all_cv_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81fbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fold': 1, 'TN': 560.99, 'FP': 287.41, 'FN': 303.04, 'TP': 507.41},\n",
      " {'fold': 2, 'TN': 389.91, 'FP': 231.5, 'FN': 242.77, 'TP': 324.69},\n",
      " {'fold': 3, 'TN': 458.48, 'FP': 284.82, 'FN': 269.05, 'TP': 451.65},\n",
      " {'fold': 4, 'TN': 470.74, 'FP': 244.17, 'FN': 302.44, 'TP': 475.39},\n",
      " {'fold': 5, 'TN': 440.61, 'FP': 229.35, 'FN': 243.93, 'TP': 353.65}]\n"
     ]
    }
   ],
   "source": [
    "all_cms[scheme] = cms\n",
    "pprint(all_cms, sort_dicts=False)\n",
    "winsound.Beep(1000, 1000)\n",
    "# pprint(all_cms[best_model], sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498b33d",
   "metadata": {},
   "source": [
    "##### Sequential Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb415eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_w_leaf = 0.05\n",
    "max_depth = 6\n",
    "min_samples_split = 20\n",
    "min_samples_leaf = 10\n",
    "n_estimators = 100\n",
    "# random_state = 7\n",
    "idx = y_train.index.intersection(cont_train.index)\n",
    "w_train = cont_train.loc[idx, \"w\"] # Return-attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b182072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More straightforward and gives you better control\n",
    "base_tree = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    # class_weight='balanced',\n",
    "    \n",
    "    # Pre-pruning parameters\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    # min_samples_split=min_samples_split,\n",
    "    # min_samples_leaf=min_samples_leaf,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "base_rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=1,\n",
    "    bootstrap=False,\n",
    "    class_weight='balanced_subsample',\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    )\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced_subsample',\n",
    "    n_estimators=n_estimators,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,  # Use all available cores\n",
    "    random_state=random_state,\n",
    "    )\n",
    "bagged_rf = BaggingClassifier(\n",
    "    estimator=base_rf,\n",
    "    n_estimators=n_estimators,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "bagged_tree = BaggingClassifier(\n",
    "    estimator=base_tree,\n",
    "    n_estimators=n_estimators,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "adaboost = AdaBoostClassifier(\n",
    "        estimator=base_rf,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "seq_rf = SequentiallyBootstrappedBaggingClassifier(\n",
    "    samples_info_sets=cont_train.t1,\n",
    "    price_bars_index=bb_df.index,\n",
    "    estimator=base_tree,\n",
    "    n_estimators=n_estimators,\n",
    "    max_features=1,\n",
    "    bootstrap_features=False,\n",
    "    oob_score=True,\n",
    "    # max_samples=avg_u,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    verbose=False,\n",
    ")\n",
    "seq_rf_bf = clone(seq_rf).set_params(bootstrap_features=True) # bootstrap_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF OOB Score: 0.4846\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 12\u001b[0m\n\u001b[0;32m      4\u001b[0m rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      5\u001b[0m     X_train\u001b[38;5;241m.\u001b[39mloc[idx],\n\u001b[0;32m      6\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mloc[idx],\n\u001b[0;32m      7\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mw_train\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRF OOB Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf\u001b[38;5;241m.\u001b[39moob_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m bagged_tree \u001b[38;5;241m=\u001b[39m \u001b[43mbagged_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBagged Decision Tree OOB Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbagged_tree\u001b[38;5;241m.\u001b[39moob_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m bagged_rf \u001b[38;5;241m=\u001b[39m bagged_rf\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     21\u001b[0m     X_train\u001b[38;5;241m.\u001b[39mloc[idx],\n\u001b[0;32m     22\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mloc[idx],\n\u001b[0;32m     23\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mw_train\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m     24\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     69\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:389\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    386\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    387\u001b[0m     fit_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:532\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, check_input, **fit_params)\u001b[0m\n\u001b[0;32m    529\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[1;32m--> 532\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    551\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[0;32m    552\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"RF OOB Score: {rf.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "bagged_tree = bagged_tree.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"Bagged Decision Tree OOB Score: {bagged_tree.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "bagged_rf = bagged_rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"Bagged RF OOB Score: {bagged_rf.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "adaboost.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"AdaBoost Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52934d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "seq_rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential Bootstrap OOB Score: {seq_rf.oob_score_:.4f} | Done in {time1}\")\n",
    "\n",
    "time0 = time.time()\n",
    "seq_rf_bf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential RF Bootstrapped Features OOB Score: {seq_rf_bf.oob_score_:.4f} | Done in {time1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "standard_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_tree",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f4d994c4-3425-4a4a-86d4-7555044c7af7",
       "rows": [
        [
         "accuracy",
         "0.5162",
         "0.5142",
         "0.5149",
         "0.4974"
        ],
        [
         "pwa",
         "0.5221",
         "0.5241",
         "0.5209",
         "0.5064"
        ],
        [
         "neg_log_loss",
         "-0.6925",
         "-0.6924",
         "-0.6926",
         "-0.6931"
        ],
        [
         "precision",
         "0.5179",
         "0.5156",
         "0.515",
         "0.5007"
        ],
        [
         "recall",
         "0.5593",
         "0.5738",
         "0.619",
         "0.4925"
        ],
        [
         "f1",
         "0.5378",
         "0.5431",
         "0.5622",
         "0.4965"
        ],
        [
         "oob",
         "0.5059",
         "0.5051",
         "0.5031",
         "0.2432"
        ],
        [
         "oob_test_gap",
         "-0.0102",
         "-0.0091",
         "-0.0117",
         "-0.2541"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_rf</th>\n",
       "      <th>bagged_rf</th>\n",
       "      <th>bagged_tree</th>\n",
       "      <th>sequential_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.5149</td>\n",
       "      <td>0.4974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwa</th>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.6925</td>\n",
       "      <td>-0.6924</td>\n",
       "      <td>-0.6926</td>\n",
       "      <td>-0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.5007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.5593</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.5378</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.4965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob</th>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.5051</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.2432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob_test_gap</th>\n",
       "      <td>-0.0102</td>\n",
       "      <td>-0.0091</td>\n",
       "      <td>-0.0117</td>\n",
       "      <td>-0.2541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              standard_rf  bagged_rf  bagged_tree  sequential_rf\n",
       "accuracy           0.5162     0.5142       0.5149         0.4974\n",
       "pwa                0.5221     0.5241       0.5209         0.5064\n",
       "neg_log_loss      -0.6925    -0.6924      -0.6926        -0.6931\n",
       "precision          0.5179     0.5156       0.5150         0.5007\n",
       "recall             0.5593     0.5738       0.6190         0.4925\n",
       "f1                 0.5378     0.5431       0.5622         0.4965\n",
       "oob                0.5059     0.5051       0.5031         0.2432\n",
       "oob_test_gap      -0.0102    -0.0091      -0.0117        -0.2541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensembles = {\n",
    "    \"adaboost\": {\"classifier\": adaboost, \n",
    "                 \"pred\": adaboost.predict(X_test),\n",
    "                 \"prob\": adaboost.predict_proba(X_test),\n",
    "                 \"oob\": np.nan,\n",
    "                },\n",
    "    \"standard_rf\": {\"classifier\": rf, \n",
    "                 \"pred\": rf.predict(X_test),\n",
    "                 \"prob\": rf.predict_proba(X_test),\n",
    "                 \"oob\": rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_rf\": {\"classifier\": bagged_rf, \n",
    "                 \"pred\": bagged_rf.predict(X_test),\n",
    "                 \"prob\": bagged_rf.predict_proba(X_test),\n",
    "                 \"oob\": bagged_rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_tree\": {\"classifier\": bagged_tree, \n",
    "                 \"pred\": bagged_tree.predict(X_test),\n",
    "                 \"prob\": bagged_tree.predict_proba(X_test),\n",
    "                 \"oob\": bagged_tree.oob_score_,\n",
    "                },\n",
    "    \"sequential_rf\": {\"classifier\": seq_rf, \n",
    "                   \"pred\": seq_rf.predict(X_test),\n",
    "                   \"prob\": seq_rf.predict_proba(X_test),\n",
    "                   \"oob\": seq_rf.oob_score_,\n",
    "                   },\n",
    "    \"sequential_rf_bf\": {\"classifier\": seq_rf_bf, \n",
    "                   \"pred\": seq_rf_bf.predict(X_test),\n",
    "                   \"prob\": seq_rf_bf.predict_proba(X_test),\n",
    "                   \"oob\": seq_rf_bf.oob_score_,\n",
    "                   },                 \n",
    "}\n",
    "\n",
    "scoring_methods = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"pwa\": probability_weighted_accuracy,\n",
    "            \"neg_log_loss\": log_loss,\n",
    "            \"precision\": precision_score,\n",
    "            \"recall\": recall_score,\n",
    "            \"f1\": f1_score,\n",
    "        }\n",
    "\n",
    "all_scores_oos = pd.DataFrame()\n",
    "\n",
    "for clf in ensembles.keys():\n",
    "    for method, scoring in scoring_methods.items():\n",
    "        if scoring in (probability_weighted_accuracy, log_loss):\n",
    "            y_pred = ensembles[clf][\"prob\"]\n",
    "        else:\n",
    "            y_pred = ensembles[clf][\"pred\"]\n",
    "        score = scoring(y_test, y_pred)\n",
    "        if method == \"neg_log_loss\":\n",
    "            score *= -1\n",
    "        all_scores_oos.loc[method, clf] = score\n",
    "    all_scores_oos.loc[\"oob\", clf] = ensembles[clf][\"oob\"]\n",
    "    all_scores_oos.loc[\"oob_test_gap\", clf] = ensembles[clf][\"oob\"] - all_scores_oos.loc[\"accuracy\", clf]\n",
    "\n",
    "all_scores_oos.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40738aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_rf done.\n",
      "bagged_rf done.\n",
      "bagged_tree done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[52], line 10\u001b[0m\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clf, SequentiallyBootstrappedBaggingClassifier):\n",
      "\u001b[0;32m      9\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m---> 10\u001b[0m cv_scores, cv_scores_df, cms \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_cross_val_scores\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     15\u001b[0m all_cms\u001b[38;5;241m.\u001b[39mappend(cms)\n",
      "\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m cv_scores_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\cross_validation\\cross_validation.py:488\u001b[0m, in \u001b[0;36manalyze_cross_val_scores\u001b[1;34m(classifier, X, y, cv_gen, sample_weight_train, sample_weight_score)\u001b[0m\n",
      "\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq_bootstrap:\n",
      "\u001b[0;32m    485\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m clone(classifier)\u001b[38;5;241m.\u001b[39mset_params(\n",
      "\u001b[0;32m    486\u001b[0m         samples_info_sets\u001b[38;5;241m=\u001b[39mt1\u001b[38;5;241m.\u001b[39miloc[train]\n",
      "\u001b[0;32m    487\u001b[0m     )  \u001b[38;5;66;03m# Create new instance\u001b[39;00m\n",
      "\u001b[1;32m--> 488\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    493\u001b[0m prob \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict_proba(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n",
      "\u001b[0;32m    494\u001b[0m pred \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:312\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    Build a Sequentially Bootstrapped Bagging ensemble of estimators from the training\u001b[39;00m\n",
      "\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    set (X, y).\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    self : (object)\u001b[39;00m\n",
      "\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:559\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaggingClassifier._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n",
      "\u001b[0;32m    556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Call parent _fit method\u001b[39;00m\n",
      "\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:422\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n",
      "\u001b[0;32m    419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds, seeds])\n",
      "\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# Build estimators in parallel\u001b[39;00m\n",
      "\u001b[1;32m--> 422\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_indices_\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    435\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# Unpack results\u001b[39;00m\n",
      "\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n",
      "\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n",
      "\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n",
      "\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n",
      "\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n",
      "\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n",
      "\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n",
      "\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n",
      "\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n",
      "\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n",
      "\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n",
      "\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n",
      "\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n",
      "\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n",
      "\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n",
      "\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n",
      "\u001b[0;32m   1799\u001b[0m     ):\n",
      "\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n",
      "\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n",
      "\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_cv_scores = pd.DataFrame()\n",
    "all_cv_scores_std = pd.DataFrame(dtype=pd.StringDtype())\n",
    "all_cms = []\n",
    "\n",
    "for name in ensembles.keys():\n",
    "    clf = ensembles[name][\"classifier\"]\n",
    "    w = cont_train['tW'].values\n",
    "    if isinstance(clf, SequentiallyBootstrappedBaggingClassifier):\n",
    "        w = None\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    all_cms.append(cms)\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores.loc[idx, name] = row['mean']\n",
    "        all_cv_scores_std.loc[idx, name] = f\"{row['mean']:.3f} ± {row['std']:.3f}\"\n",
    "    print(name, \"done.\")\n",
    "    \n",
    "# all_cv_scores.round(4)\n",
    "all_cv_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07230ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fold': 1, 'TN': 549.73, 'FP': 494.95, 'FN': 477.13, 'TP': 474.95},\n",
      " {'fold': 2, 'TN': 524.85, 'FP': 460.91, 'FN': 504.02, 'TP': 518.75},\n",
      " {'fold': 3, 'TN': 461.98, 'FP': 596.42, 'FN': 422.17, 'TP': 553.53}]\n"
     ]
    }
   ],
   "source": [
    "pprint(all_cms, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e170c",
   "metadata": {},
   "source": [
    "#### Meta-Labelled- CV of Weighting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9519e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = bb_events_tb_time_meta.copy()\n",
    "X = bb_feat_time.reindex(cont.index)\n",
    "y = cont[\"bin\"]\n",
    "t1 = cont[\"t1\"]\n",
    "\n",
    "test_size = 0.3\n",
    "\n",
    "train, test = PurgedSplit(t1, test_size).split(X)\n",
    "X_train, X_test, y_train, y_test = (\n",
    "        X.iloc[train],\n",
    "        X.iloc[test],\n",
    "        y.iloc[train],\n",
    "        y.iloc[test],\n",
    "    )\n",
    "\n",
    "cont_train = get_event_weights(cont.iloc[train], bb_df.close)\n",
    "bb_cont_train_meta = cont_train.copy()\n",
    "\n",
    "n_splits = 5\n",
    "pct_embargo = 0.01\n",
    "cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['unweighted', 'uniqueness', 'return'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_u = cont_train.tW.mean()\n",
    "weighting_schemes = {\n",
    "    \"unweighted\": pd.Series(1., index=cont_train.index),\n",
    "    \"uniqueness\": cont_train[\"tW\"],\n",
    "    \"return\": cont_train[\"w\"],\n",
    "    }\n",
    "\n",
    "decay_factors = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "time_decay_weights = {}\n",
    "for time_decay in decay_factors:\n",
    "    for linear in (1, 0):\n",
    "        decay_w = get_weights_by_time_decay_optimized(\n",
    "                    triple_barrier_events=cont,\n",
    "                    close_index=close.index,\n",
    "                    last_weight=time_decay,\n",
    "                    linear=linear,\n",
    "                    av_uniqueness=cont_train[\"tW\"],\n",
    "                )\n",
    "        method = \"linear\" if linear else \"exp\"\n",
    "        time_decay_weights[f\"{method}_time_decay_{time_decay}\"] = decay_w\n",
    "        \n",
    "# for k, v in time_decay_weights.items():\n",
    "#     weighting_schemes[k] = v\n",
    "\n",
    "weighting_schemes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b52a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average uniqueness: 0.5473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "min_w_leaf = 0.05\n",
    "print(f\"Average uniqueness: {avg_u:.4f}\\n\")\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    random_state=random_state,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=6,\n",
    "    n_jobs=N_JOBS,  # Use all available cores\n",
    "    )\n",
    "\n",
    "clf0 = rf\n",
    "clf1 = clone(rf).set_params(class_weight='balanced_subsample')\n",
    "clf2 = clone(rf).set_params(max_samples=avg_u)\n",
    "clf3 = clone(rf).set_params(max_samples=avg_u, class_weight='balanced_subsample')\n",
    "clfs = {k: v for k, v in zip(['standard', 'balanced_subsample', 'max_samples', 'combined'], [clf0, clf1, clf2, clf3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5665489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)\n",
    "# cv_scores_d = {k: {} for k in clfs.keys()}\n",
    "# print(rf.__class__.__name__, \"Weighting Schemes\")\n",
    "# all_clf_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "# best_models = []\n",
    "\n",
    "# for scheme, sample_weights in weighting_schemes.items():\n",
    "#     best_score, best_model = None, None\n",
    "#     for param, clf in clfs.items():\n",
    "#         w = sample_weights.values\n",
    "#         cv_scores = ml_cross_val_score(\n",
    "#             clf, X_train, y_train, cv_gen, \n",
    "#             sample_weight_train=w, \n",
    "#             sample_weight_score=w,\n",
    "#             scoring=\"f1\",\n",
    "#         )\n",
    "#         score = cv_scores.mean()\n",
    "#         cv_scores_d[param][scheme] = score\n",
    "#         best_score = max(best_score, score) if best_score is not None else score\n",
    "#         if score == best_score:\n",
    "#             best_model = param\n",
    "#         all_clf_scores_df.loc[param, scheme] = f\"{cv_scores.mean():.6f} ± {cv_scores.std():.4f}\"\n",
    "#     best_models.append(best_model)\n",
    "#     print(f\"{scheme} {best_model} model achieved the best f1 score of {best_score:.6f}\")\n",
    "\n",
    "# print()\n",
    "# pprint(all_clf_scores_df, sort_dicts=False)\n",
    "# best_model = max(best_models, key=best_models.count)\n",
    "# best_clf = clone(clfs[best_model])\n",
    "# print(f\"\\nSelected Best Classifier ({best_model}): {best_clf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd491f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   unweighted       uniqueness           return\n",
      "accuracy       0.6262 ± 0.022   0.6175 ± 0.024   0.6228 ± 0.022\n",
      "pwa            0.6309 ± 0.027   0.6251 ± 0.031   0.6317 ± 0.019\n",
      "neg_log_loss  -0.6604 ± 0.015  -0.6641 ± 0.016  -0.6611 ± 0.008\n",
      "precision      0.6262 ± 0.022   0.6176 ± 0.024   0.0000 ± 0.000\n",
      "recall         1.0000 ± 0.000   0.9998 ± 0.001   0.0000 ± 0.000\n",
      "f1             0.7699 ± 0.016   0.7632 ± 0.019   0.0000 ± 0.000\n",
      "\n",
      "unweighted model achieved the best f1 score of 0.769903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_cv_scores_d = {}\n",
    "all_cms = {}\n",
    "best_score, best_model = None, None\n",
    "all_cv_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "best_clf = clfs[\"max_samples\"]\n",
    "scoring = 'f1' if set(y_train.unique()) == {0, 1} else 'neg_log_loss'\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    w = sample_weights.values\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        best_clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    score = cv_scores[scoring].mean()\n",
    "    all_cv_scores_d[scheme] = cv_scores\n",
    "    all_cms[scheme] = cms\n",
    "    best_score = max(best_score, score) if best_score is not None else score\n",
    "    if score == best_score:\n",
    "        best_model = scheme\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores_df.loc[idx, scheme] = f\"{row['mean']:.4f} ± {row['std']:.3f}\"\n",
    "pprint(all_cv_scores_df)\n",
    "print(f\"\\n{best_model} model achieved the best {scoring} score of {best_score:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108fd6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unweighted': [{'fold': 1, 'TN': 0.0, 'FP': 313.0, 'FN': 0.0, 'TP': 518.0},\n",
      "                {'fold': 2, 'TN': 0.0, 'FP': 328.0, 'FN': 0.0, 'TP': 503.0},\n",
      "                {'fold': 3, 'TN': 0.0, 'FP': 271.0, 'FN': 0.0, 'TP': 560.0},\n",
      "                {'fold': 4, 'TN': 0.0, 'FP': 300.0, 'FN': 0.0, 'TP': 531.0},\n",
      "                {'fold': 5, 'TN': 0.0, 'FP': 304.0, 'FN': 0.0, 'TP': 527.0},\n",
      "                {'fold': 6, 'TN': 0.0, 'FP': 327.0, 'FN': 0.0, 'TP': 504.0},\n",
      "                {'fold': 7, 'TN': 0.0, 'FP': 335.0, 'FN': 0.0, 'TP': 495.0},\n",
      "                {'fold': 8, 'TN': 0.0, 'FP': 306.0, 'FN': 0.0, 'TP': 524.0},\n",
      "                {'fold': 9, 'TN': 0.0, 'FP': 299.0, 'FN': 0.0, 'TP': 531.0},\n",
      "                {'fold': 10, 'TN': 0.0, 'FP': 322.0, 'FN': 0.0, 'TP': 508.0}],\n",
      " 'uniqueness': [{'fold': 1, 'TN': 0.0, 'FP': 179.9, 'FN': 0.0, 'TP': 295.4},\n",
      "                {'fold': 2, 'TN': 0.0, 'FP': 181.38, 'FN': 0.0, 'TP': 260.87},\n",
      "                {'fold': 3, 'TN': 0.0, 'FP': 148.29, 'FN': 0.0, 'TP': 296.99},\n",
      "                {'fold': 4, 'TN': 0.0, 'FP': 170.65, 'FN': 0.0, 'TP': 292.36},\n",
      "                {'fold': 5, 'TN': 0.0, 'FP': 164.7, 'FN': 0.0, 'TP': 282.74},\n",
      "                {'fold': 6, 'TN': 0.0, 'FP': 181.01, 'FN': 0.5, 'TP': 263.38},\n",
      "                {'fold': 7, 'TN': 0.0, 'FP': 190.87, 'FN': 0.0, 'TP': 265.45},\n",
      "                {'fold': 8, 'TN': 0.0, 'FP': 168.99, 'FN': 0.0, 'TP': 285.09},\n",
      "                {'fold': 9, 'TN': 0.0, 'FP': 169.56, 'FN': 0.0, 'TP': 284.92},\n",
      "                {'fold': 10, 'TN': 0.0, 'FP': 182.96, 'FN': 0.0, 'TP': 280.07}],\n",
      " 'return': [{'fold': 1, 'TN': 585.06, 'FP': 0.0, 'FN': 376.61, 'TP': 0.0},\n",
      "            {'fold': 2, 'TN': 558.98, 'FP': 0.0, 'FN': 304.2, 'TP': 0.0},\n",
      "            {'fold': 3, 'TN': 341.24, 'FP': 0.0, 'FN': 234.33, 'TP': 0.0},\n",
      "            {'fold': 4, 'TN': 381.34, 'FP': 0.0, 'FN': 211.98, 'TP': 0.0},\n",
      "            {'fold': 5, 'TN': 502.06, 'FP': 0.0, 'FN': 328.28, 'TP': 0.0},\n",
      "            {'fold': 6, 'TN': 571.72, 'FP': 0.0, 'FN': 329.69, 'TP': 0.0},\n",
      "            {'fold': 7, 'TN': 505.12, 'FP': 0.0, 'FN': 264.63, 'TP': 0.0},\n",
      "            {'fold': 8, 'TN': 353.08, 'FP': 0.0, 'FN': 234.24, 'TP': 0.0},\n",
      "            {'fold': 9, 'TN': 535.19, 'FP': 0.0, 'FN': 352.73, 'TP': 0.0},\n",
      "            {'fold': 10, 'TN': 851.14, 'FP': 0.0, 'FN': 484.4, 'TP': 0.0}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(all_cms, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5b1bc",
   "metadata": {},
   "source": [
    "##### Sequential Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee3894c",
   "metadata": {},
   "source": [
    "###### Classifier Initializion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379210a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from afml.cross_validation.scoring import probability_weighted_accuracy\n",
    "from afml.ensemble.sb_bagging import (\n",
    "    SequentiallyBootstrappedBaggingClassifier,\n",
    "    compute_custom_oob_metrics,\n",
    ")\n",
    "\n",
    "min_w_leaf = 0.05\n",
    "max_depth = 6\n",
    "min_samples_split = 20\n",
    "min_samples_leaf = 10\n",
    "n_estimators = 100\n",
    "random_state = 7\n",
    "\n",
    "# More straightforward and gives you better control\n",
    "base_tree = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced',\n",
    "    \n",
    "    # Pre-pruning parameters\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    # min_samples_split=min_samples_split,\n",
    "    # min_samples_leaf=min_samples_leaf,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "base_rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=1,\n",
    "    bootstrap=False,\n",
    "    class_weight='balanced_subsample',\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    )\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced_subsample',\n",
    "    n_estimators=n_estimators,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,  # Use all available cores\n",
    "    random_state=random_state,\n",
    "    )\n",
    "bagged_rf = BaggingClassifier(\n",
    "    estimator=base_rf,\n",
    "    n_estimators=n_estimators,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "bagged_tree = BaggingClassifier(\n",
    "    estimator=base_tree,\n",
    "    n_estimators=n_estimators,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "adaboost = AdaBoostClassifier(\n",
    "        estimator=base_rf,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "seq_rf = SequentiallyBootstrappedBaggingClassifier(\n",
    "    samples_info_sets=cont_train.t1,\n",
    "    price_bars_index=bb_df.index,\n",
    "    estimator=base_rf,\n",
    "    n_estimators=n_estimators,\n",
    "    max_features=1,\n",
    "    bootstrap_features=False,\n",
    "    oob_score=True,\n",
    "    max_samples=avg_u,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    verbose=False,\n",
    ")\n",
    "seq_rf_bf = clone(seq_rf).set_params(bootstrap_features=True) # bootstrap_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5fc7fe",
   "metadata": {},
   "source": [
    "###### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fec154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Decision Tree OOB Score: 0.5031\n",
      "RF OOB Score: 0.5059\n",
      "Bagged RF OOB Score: 0.5051\n",
      "Sequential Bootstrap OOB Score: 0.2432\n",
      "\n",
      "Sequential Bootstrap Training done in 0 days 00:08:31\n"
     ]
    }
   ],
   "source": [
    "idx = y_train.index.intersection(cont_train.index)\n",
    "w_train = cont_train.loc[idx, \"tW\"] # Return-attribution\n",
    "\n",
    "rf = rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"RF OOB Score: {rf.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "bagged_tree = bagged_tree.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"Bagged Decision Tree OOB Score: {bagged_tree.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "bagged_rf = bagged_rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"Bagged RF OOB Score: {bagged_rf.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "adaboost.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"AdaBoost Done\")\n",
    "\n",
    "\n",
    "time0 = time.time()\n",
    "seq_rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential RF OOB Score: {seq_rf.oob_score_:.4f}\")\n",
    "print(f\"\\nSequential RF Training done in {time1}\")\n",
    "\n",
    "\n",
    "time0 = time.time()\n",
    "seq_rf_bf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential Bootstrapped Features OOB Score: {seq_rf_bf.oob_score_:.4f}\")\n",
    "print(f\"\\nSequential Bootstrapped Features Training done in {time1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150fae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "standard_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_tree",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f4d994c4-3425-4a4a-86d4-7555044c7af7",
       "rows": [
        [
         "accuracy",
         "0.5162",
         "0.5142",
         "0.5149",
         "0.4974"
        ],
        [
         "pwa",
         "0.5221",
         "0.5241",
         "0.5209",
         "0.5064"
        ],
        [
         "neg_log_loss",
         "-0.6925",
         "-0.6924",
         "-0.6926",
         "-0.6931"
        ],
        [
         "precision",
         "0.5179",
         "0.5156",
         "0.515",
         "0.5007"
        ],
        [
         "recall",
         "0.5593",
         "0.5738",
         "0.619",
         "0.4925"
        ],
        [
         "f1",
         "0.5378",
         "0.5431",
         "0.5622",
         "0.4965"
        ],
        [
         "oob",
         "0.5059",
         "0.5051",
         "0.5031",
         "0.2432"
        ],
        [
         "oob_test_gap",
         "-0.0102",
         "-0.0091",
         "-0.0117",
         "-0.2541"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_rf</th>\n",
       "      <th>bagged_rf</th>\n",
       "      <th>bagged_tree</th>\n",
       "      <th>sequential_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.5149</td>\n",
       "      <td>0.4974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwa</th>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.6925</td>\n",
       "      <td>-0.6924</td>\n",
       "      <td>-0.6926</td>\n",
       "      <td>-0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.5007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.5593</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.5378</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.4965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob</th>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.5051</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.2432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob_test_gap</th>\n",
       "      <td>-0.0102</td>\n",
       "      <td>-0.0091</td>\n",
       "      <td>-0.0117</td>\n",
       "      <td>-0.2541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              standard_rf  bagged_rf  bagged_tree  sequential_rf\n",
       "accuracy           0.5162     0.5142       0.5149         0.4974\n",
       "pwa                0.5221     0.5241       0.5209         0.5064\n",
       "neg_log_loss      -0.6925    -0.6924      -0.6926        -0.6931\n",
       "precision          0.5179     0.5156       0.5150         0.5007\n",
       "recall             0.5593     0.5738       0.6190         0.4925\n",
       "f1                 0.5378     0.5431       0.5622         0.4965\n",
       "oob                0.5059     0.5051       0.5031         0.2432\n",
       "oob_test_gap      -0.0102    -0.0091      -0.0117        -0.2541"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembles = {\n",
    "    \"adaboost\": {\"classifier\": adaboost, \n",
    "                 \"pred\": adaboost.predict(X_test),\n",
    "                 \"prob\": adaboost.predict_proba(X_test),\n",
    "                 \"oob\": np.nan,\n",
    "                },\n",
    "    \"standard_rf\": {\"classifier\": rf, \n",
    "                 \"pred\": rf.predict(X_test),\n",
    "                 \"prob\": rf.predict_proba(X_test),\n",
    "                 \"oob\": rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_rf\": {\"classifier\": bagged_rf, \n",
    "                 \"pred\": bagged_rf.predict(X_test),\n",
    "                 \"prob\": bagged_rf.predict_proba(X_test),\n",
    "                 \"oob\": bagged_rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_tree\": {\"classifier\": bagged_tree, \n",
    "                 \"pred\": bagged_tree.predict(X_test),\n",
    "                 \"prob\": bagged_tree.predict_proba(X_test),\n",
    "                 \"oob\": bagged_tree.oob_score_,\n",
    "                },\n",
    "    \"sequential_rf\": {\"classifier\": seq_rf, \n",
    "                   \"pred\": seq_rf.predict(X_test),\n",
    "                   \"prob\": seq_rf.predict_proba(X_test),\n",
    "                   \"oob\": seq_rf.oob_score_,\n",
    "                   },\n",
    "    \"sequential_rf_bf\": {\"classifier\": seq_rf_bf, \n",
    "                   \"pred\": seq_rf_bf.predict(X_test),\n",
    "                   \"prob\": seq_rf_bf.predict_proba(X_test),\n",
    "                   \"oob\": seq_rf_bf.oob_score_,\n",
    "                   },                 \n",
    "}\n",
    "\n",
    "scoring_methods = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"pwa\": probability_weighted_accuracy,\n",
    "            \"neg_log_loss\": log_loss,\n",
    "            \"precision\": precision_score,\n",
    "            \"recall\": recall_score,\n",
    "            \"f1\": f1_score,\n",
    "        }\n",
    "\n",
    "all_scores_oos = pd.DataFrame()\n",
    "\n",
    "for clf in ensembles.keys():\n",
    "    for method, scoring in scoring_methods.items():\n",
    "        if scoring in (probability_weighted_accuracy, log_loss):\n",
    "            y_pred = ensembles[clf][\"prob\"]\n",
    "        else:\n",
    "            y_pred = ensembles[clf][\"pred\"]\n",
    "        score = scoring(y_test, y_pred)\n",
    "        if method == \"neg_log_loss\":\n",
    "            score *= -1\n",
    "        all_scores_oos.loc[method, clf] = score\n",
    "    all_scores_oos.loc[\"oob\", clf] = ensembles[clf][\"oob\"]\n",
    "    all_scores_oos.loc[\"oob_test_gap\", clf] = ensembles[clf][\"oob\"] - all_scores_oos.loc[\"accuracy\", clf]\n",
    "\n",
    "all_scores_oos.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d42ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_rf done.\n",
      "bagged_rf done.\n",
      "bagged_tree done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clf, SequentiallyBootstrappedBaggingClassifier):\n\u001b[0;32m      9\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m cv_scores, cv_scores_df, cms \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_cross_val_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m all_cms\u001b[38;5;241m.\u001b[39mappend(cms)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m cv_scores_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\cross_validation\\cross_validation.py:488\u001b[0m, in \u001b[0;36manalyze_cross_val_scores\u001b[1;34m(classifier, X, y, cv_gen, sample_weight_train, sample_weight_score)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq_bootstrap:\n\u001b[0;32m    485\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m clone(classifier)\u001b[38;5;241m.\u001b[39mset_params(\n\u001b[0;32m    486\u001b[0m         samples_info_sets\u001b[38;5;241m=\u001b[39mt1\u001b[38;5;241m.\u001b[39miloc[train]\n\u001b[0;32m    487\u001b[0m     )  \u001b[38;5;66;03m# Create new instance\u001b[39;00m\n\u001b[1;32m--> 488\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m prob \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict_proba(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n\u001b[0;32m    494\u001b[0m pred \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:312\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    Build a Sequentially Bootstrapped Bagging ensemble of estimators from the training\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    set (X, y).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    self : (object)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:559\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaggingClassifier._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Call parent _fit method\u001b[39;00m\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:422\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds, seeds])\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# Build estimators in parallel\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_indices_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# Unpack results\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_cv_scores = pd.DataFrame()\n",
    "all_cv_scores_std = pd.DataFrame(dtype=pd.StringDtype())\n",
    "all_cms = []\n",
    "\n",
    "for name in ensembles.keys():\n",
    "    clf = ensembles[name][\"classifier\"]\n",
    "    w = cont_train['tW'].values\n",
    "    if isinstance(clf, SequentiallyBootstrappedBaggingClassifier):\n",
    "        w = None\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    all_cms.append(cms)\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores.loc[idx, name] = row['mean']\n",
    "        all_cv_scores_std.loc[idx, name] = f\"{row['mean']:.3f} ± {row['std']:.3f}\"\n",
    "    print(name, \"done.\")\n",
    "    \n",
    "# all_cv_scores.round(4)\n",
    "all_cv_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da5fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fold': 1, 'TN': 549.73, 'FP': 494.95, 'FN': 477.13, 'TP': 474.95},\n",
      " {'fold': 2, 'TN': 524.85, 'FP': 460.91, 'FN': 504.02, 'TP': 518.75},\n",
      " {'fold': 3, 'TN': 461.98, 'FP': 596.42, 'FN': 422.17, 'TP': 553.53}]\n"
     ]
    }
   ],
   "source": [
    "pprint(all_cms, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec20ef",
   "metadata": {},
   "source": [
    "## 3. Moving Average Crossover Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f163b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afml.strategies.ma_crossover_feature_engine import ForexFeatureEngine\n",
    "\n",
    "ma_timeframe = \"M5\"\n",
    "file = Path(r\"..\\data\\EURUSD_M15_time_2018-01-01-2024-12-31.parq\")\n",
    "ma_time_bars = pd.read_parquet(file)\n",
    "\n",
    "fast_window, slow_window = 20, 50\n",
    "ma_strategy = MACrossoverStrategy(fast_window, slow_window)\n",
    "ma_pt_barrier, ma_sl_barrier, ma_time_horizon = (0, 2, dict(days=5))\n",
    "ma_vol_multiplier = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e673d8",
   "metadata": {},
   "source": [
    "### Time-Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c09a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-27 06:58:41.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.filters.filters\u001b[0m:\u001b[36mcusum_filter\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1m12,748 CUSUM-filtered events\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACrossover_20_50 Signals:\n",
      "\n",
      "       count  proportion\n",
      "side                    \n",
      "-1    61,845    0.502062\n",
      " 1    61,287    0.497532\n",
      " 0        50    0.000406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-27 06:58:42.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.strategies.signal_processing\u001b[0m:\u001b[36mget_entries\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mMACrossover_20_50 | 12,744 (10.35%) trade events selected by CUSUM filter (threshold = 0.1252%).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ma_side = ma_strategy.generate_signals(ma_time_bars)\n",
    "ma_df = ma_time_bars.loc[sample_start : sample_end]\n",
    "\n",
    "\n",
    "print(f\"{ma_strategy.get_strategy_name()} Signals:\")\n",
    "value_counts_data(ma_side.reindex(ma_df.index), verbose=True)\n",
    "\n",
    "# Volatility target for barriers\n",
    "vol_lookback = fast_window\n",
    "vol_target = get_daily_vol(ma_df.close, vol_lookback) * ma_vol_multiplier\n",
    "close = ma_df.close\n",
    "\n",
    "thres = vol_target.mean()\n",
    "_, t_events = get_entries(ma_strategy, ma_df, filter_threshold=vol_target.mean())\n",
    "\n",
    "vertical_barriers = add_vertical_barrier(t_events, close, **ma_time_horizon)\n",
    "linear_decay = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f7545",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 106.62 MB to 55.49 MB (48.0% reduction)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 172386 entries, 2018-01-01 23:15:00 to 2024-12-31 00:00:00\n",
      "Data columns (total 94 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   ma_10                           172386 non-null  float32\n",
      " 1   ma_20                           172386 non-null  float32\n",
      " 2   ma_50                           172386 non-null  float32\n",
      " 3   ma_100                          172386 non-null  float32\n",
      " 4   ma_200                          172386 non-null  float32\n",
      " 5   ma_10_20_cross                  172386 non-null  float64\n",
      " 6   ma_20_50_cross                  172386 non-null  float64\n",
      " 7   ma_50_200_cross                 172386 non-null  float64\n",
      " 8   ma_spread_10_20                 172386 non-null  float32\n",
      " 9   ma_spread_20_50                 172386 non-null  float32\n",
      " 10  ma_spread_50_200                172386 non-null  float32\n",
      " 11  ma_20_slope                     172386 non-null  float32\n",
      " 12  ma_50_slope                     172386 non-null  float32\n",
      " 13  price_above_ma_20               172386 non-null  float64\n",
      " 14  price_above_ma_50               172386 non-null  float64\n",
      " 15  ma_ribbon_aligned               172386 non-null  float64\n",
      " 16  atr_14                          172386 non-null  float32\n",
      " 17  atr_21                          172386 non-null  float32\n",
      " 18  atr_regime                      172386 non-null  float32\n",
      " 19  realized_vol_10                 172386 non-null  float32\n",
      " 20  realized_vol_20                 172386 non-null  float32\n",
      " 21  realized_vol_50                 172386 non-null  float32\n",
      " 22  vol_of_vol                      172386 non-null  float32\n",
      " 23  hl_range                        172386 non-null  float32\n",
      " 24  hl_range_ma                     172386 non-null  float32\n",
      " 25  hl_range_regime                 172386 non-null  float32\n",
      " 26  bb_upper                        172386 non-null  float32\n",
      " 27  bb_lower                        172386 non-null  float32\n",
      " 28  bb_percent                      172386 non-null  float64\n",
      " 29  bb_bandwidth                    172386 non-null  float32\n",
      " 30  bb_squeeze                      172386 non-null  float32\n",
      " 31  efficiency_ratio_14             172386 non-null  float32\n",
      " 32  efficiency_ratio_30             172386 non-null  float32\n",
      " 33  adx_14                          172386 non-null  float32\n",
      " 34  dmp_14                          172386 non-null  float32\n",
      " 35  dmn_14                          172386 non-null  float32\n",
      " 36  adx_trend_strength              172386 non-null  float64\n",
      " 37  adx_trend_direction             172386 non-null  float64\n",
      " 38  trend_window                    172386 non-null  float32\n",
      " 39  trend_slope                     172386 non-null  float32\n",
      " 40  trend_t_value                   172386 non-null  float32\n",
      " 41  trend_rsquared                  172386 non-null  float32\n",
      " 42  trend_ret                       172386 non-null  float32\n",
      " 43  roc_10                          172386 non-null  float32\n",
      " 44  roc_20                          172386 non-null  float32\n",
      " 45  momentum_14                     172386 non-null  float32\n",
      " 46  hh_ll_20                        172386 non-null  float32\n",
      " 47  trend_persistence               172386 non-null  float32\n",
      " 48  return_skew_20                  172386 non-null  float32\n",
      " 49  return_kurtosis_20              172386 non-null  float32\n",
      " 50  var_95                          172386 non-null  float32\n",
      " 51  cvar_95                         172386 non-null  float32\n",
      " 52  market_stress                   172386 non-null  float64\n",
      " 53  current_drawdown                172386 non-null  float32\n",
      " 54  days_since_high                 172386 non-null  float64\n",
      " 55  hour_sin_h1                     172386 non-null  float32\n",
      " 56  hour_cos_h1                     172386 non-null  float32\n",
      " 57  hour_sin_h2                     172386 non-null  float32\n",
      " 58  hour_cos_h2                     172386 non-null  float32\n",
      " 59  hour_sin_h3                     172386 non-null  float32\n",
      " 60  hour_cos_h3                     172386 non-null  float32\n",
      " 61  dayofweek_sin                   172386 non-null  float32\n",
      " 62  dayofweek_cos                   172386 non-null  float32\n",
      " 63  dayofyear_sin                   172386 non-null  float32\n",
      " 64  dayofyear_cos                   172386 non-null  float32\n",
      " 65  sydney_session                  172386 non-null  float64\n",
      " 66  tokyo_session                   172386 non-null  float64\n",
      " 67  london_session                  172386 non-null  float64\n",
      " 68  ny_session                      172386 non-null  float64\n",
      " 69  session_overlap                 172386 non-null  float64\n",
      " 70  friday_ny_close                 172386 non-null  float64\n",
      " 71  sunday_open                     172386 non-null  float64\n",
      " 72  month_end                       172386 non-null  float64\n",
      " 73  quarter_end                     172386 non-null  float64\n",
      " 74  sydney_session_vol              172386 non-null  float32\n",
      " 75  tokyo_session_vol               172386 non-null  float32\n",
      " 76  london_session_vol              172386 non-null  float32\n",
      " 77  ny_session_vol                  172386 non-null  float32\n",
      " 78  session_overlap_vol             172386 non-null  float32\n",
      " 79  friday_ny_close_vol             172386 non-null  float32\n",
      " 80  month_end_vol                   172386 non-null  float32\n",
      " 81  quarter_end_vol                 172386 non-null  float32\n",
      " 82  doji                            172386 non-null  float64\n",
      " 83  hammer                          172386 non-null  float64\n",
      " 84  inside_bar                      172386 non-null  float64\n",
      " 85  outside_bar                     172386 non-null  float64\n",
      " 86  near_recent_high                172386 non-null  float64\n",
      " 87  near_recent_low                 172386 non-null  float64\n",
      " 88  fractal_trend_strength          172386 non-null  float32\n",
      " 89  fractal_trend_direction         172386 non-null  float32\n",
      " 90  fractal_ma_ratio                172386 non-null  float32\n",
      " 91  fractal_trend_confirmation      172386 non-null  float64\n",
      " 92  distance_to_fractal_resistance  172386 non-null  float32\n",
      " 93  distance_to_fractal_support     172386 non-null  float32\n",
      "dtypes: float32(67), float64(27)\n",
      "memory usage: 84.9 MB\n"
     ]
    }
   ],
   "source": [
    "ma_feat_engine = ForexFeatureEngine(pair_name=symbol)\n",
    "ma_feat_time = ma_feat_engine.calculate_all_features(ma_time_bars, ma_timeframe, lr_period=(5, 20))\n",
    "ma_feat_time.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1de34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0. ma_10\n",
      "  1. ma_20\n",
      "  2. ma_50\n",
      "  3. ma_100\n",
      "  4. ma_200\n",
      "  5. ma_10_20_cross\n",
      "  6. ma_20_50_cross\n",
      "  7. ma_50_200_cross\n",
      "  8. ma_spread_10_20\n",
      "  9. ma_spread_20_50\n",
      " 10. ma_spread_50_200\n",
      " 11. ma_20_slope\n",
      " 12. ma_50_slope\n",
      " 13. price_above_ma_20\n",
      " 14. price_above_ma_50\n",
      " 15. ma_ribbon_aligned\n",
      " 16. atr_14\n",
      " 17. atr_21\n",
      " 18. atr_regime\n",
      " 19. realized_vol_10\n",
      " 20. realized_vol_20\n",
      " 21. realized_vol_50\n",
      " 22. vol_of_vol\n",
      " 23. hl_range\n",
      " 24. hl_range_ma\n",
      " 25. hl_range_regime\n",
      " 26. bb_upper\n",
      " 27. bb_lower\n",
      " 28. bb_percent\n",
      " 29. bb_bandwidth\n",
      " 30. bb_squeeze\n",
      " 31. efficiency_ratio_14\n",
      " 32. efficiency_ratio_30\n",
      " 33. adx_14\n",
      " 34. dmp_14\n",
      " 35. dmn_14\n",
      " 36. adx_trend_strength\n",
      " 37. adx_trend_direction\n",
      " 38. trend_window\n",
      " 39. trend_slope\n",
      " 40. trend_t_value\n",
      " 41. trend_rsquared\n",
      " 42. trend_ret\n",
      " 43. roc_10\n",
      " 44. roc_20\n",
      " 45. momentum_14\n",
      " 46. hh_ll_20\n",
      " 47. trend_persistence\n",
      " 48. return_skew_20\n",
      " 49. return_kurtosis_20\n",
      " 50. var_95\n",
      " 51. cvar_95\n",
      " 52. market_stress\n",
      " 53. current_drawdown\n",
      " 54. days_since_high\n",
      " 55. hour_sin_h1\n",
      " 56. hour_cos_h1\n",
      " 57. hour_sin_h2\n",
      " 58. hour_cos_h2\n",
      " 59. hour_sin_h3\n",
      " 60. hour_cos_h3\n",
      " 61. dayofweek_sin\n",
      " 62. dayofweek_cos\n",
      " 63. dayofyear_sin\n",
      " 64. dayofyear_cos\n",
      " 65. sydney_session\n",
      " 66. tokyo_session\n",
      " 67. london_session\n",
      " 68. ny_session\n",
      " 69. session_overlap\n",
      " 70. friday_ny_close\n",
      " 71. sunday_open\n",
      " 72. month_end\n",
      " 73. quarter_end\n",
      " 74. sydney_session_vol\n",
      " 75. tokyo_session_vol\n",
      " 76. london_session_vol\n",
      " 77. ny_session_vol\n",
      " 78. session_overlap_vol\n",
      " 79. friday_ny_close_vol\n",
      " 80. month_end_vol\n",
      " 81. quarter_end_vol\n",
      " 82. doji\n",
      " 83. hammer\n",
      " 84. inside_bar\n",
      " 85. outside_bar\n",
      " 86. near_recent_high\n",
      " 87. near_recent_low\n",
      " 88. fractal_trend_strength\n",
      " 89. fractal_trend_direction\n",
      " 90. fractal_ma_ratio\n",
      " 91. fractal_trend_confirmation\n",
      " 92. distance_to_fractal_resistance\n",
      " 93. distance_to_fractal_support\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(ma_feat_time):\n",
    "    print(f\"{i:>3}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863eb59",
   "metadata": {},
   "source": [
    "#### Triple-Barrier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77596f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 12716 entries, 2018-01-03 02:45:00 to 2022-12-30 12:30:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   t1      12716 non-null  datetime64[ns]\n",
      " 1   trgt    12716 non-null  float64       \n",
      " 2   ret     12716 non-null  float64       \n",
      " 3   bin     12716 non-null  int8          \n",
      " 4   side    12716 non-null  int8          \n",
      "dtypes: datetime64[ns](1), float64(2), int8(2)\n",
      "memory usage: 422.2 KB\n",
      "Triple-Barrier (pt=0, sl=2, h={'days': 5}):\n",
      "\n",
      "     count  proportion\n",
      "bin                   \n",
      "0    9,109    0.716342\n",
      "1    3,607    0.283658\n",
      "\n",
      "Average Uniqueness: 0.0668\n"
     ]
    }
   ],
   "source": [
    "ma_events_tb = triple_barrier_labels(\n",
    "    close=close,\n",
    "    target=vol_target,\n",
    "    t_events=t_events,\n",
    "    pt_sl=[ma_pt_barrier, ma_sl_barrier],\n",
    "    min_ret=min_ret,\n",
    "    vertical_barrier_times=vertical_barriers,\n",
    "    side_prediction=ma_side,\n",
    "    vertical_barrier_zero=False,\n",
    "    verbose=False,\n",
    ")\n",
    "ma_events_tb_time = ma_events_tb.copy()\n",
    "ma_events_tb.info()\n",
    "\n",
    "print(f\"Triple-Barrier (pt={ma_pt_barrier}, sl={ma_sl_barrier}, h={ma_time_horizon}):\")\n",
    "value_counts_data(ma_events_tb.bin, verbose=True)\n",
    "\n",
    "weights = get_event_weights(ma_events_tb, close)\n",
    "av_uniqueness = weights['tW'].mean()\n",
    "print(f\"Average Uniqueness: {av_uniqueness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c240c6f",
   "metadata": {},
   "source": [
    "#### Cross-Validation of Weighting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72404d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = ma_events_tb_time.copy()\n",
    "X = ma_feat_time.reindex(cont.index)\n",
    "y = cont[\"bin\"]\n",
    "t1 = cont[\"t1\"]\n",
    "\n",
    "test_size = 0.2\n",
    "n_splits = 10\n",
    "pct_embargo = 0.01\n",
    "\n",
    "train, test = PurgedSplit(t1, test_size).split(X)\n",
    "X_train, X_test, y_train, y_test = (\n",
    "        X.iloc[train],\n",
    "        X.iloc[test],\n",
    "        y.iloc[train],\n",
    "        y.iloc[test],\n",
    "    )\n",
    "cont_train = get_event_weights(cont.iloc[train], ma_df.close)\n",
    "avg_u = cont_train.tW.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edaa4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['unweighted', 'uniqueness', 'return'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decay_factors = [0.0, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "time_decay_weights = {}\n",
    "for time_decay in decay_factors:\n",
    "    for linear in (1, 0):\n",
    "        decay_w = get_weights_by_time_decay_optimized(\n",
    "                    triple_barrier_events=cont,\n",
    "                    close_index=close.index,\n",
    "                    last_weight=time_decay,\n",
    "                    linear=linear,\n",
    "                    av_uniqueness=cont_train[\"tW\"],\n",
    "                )\n",
    "        method = \"linear\" if linear else \"exp\"\n",
    "        time_decay_weights[f\"{method}_time_decay_{time_decay}\"] = decay_w\n",
    "        \n",
    "weighting_schemes = {\n",
    "    \"unweighted\": pd.Series(1., index=cont_train.index),\n",
    "    \"uniqueness\": cont_train[\"tW\"],\n",
    "    \"return\": cont_train[\"w\"],\n",
    "    }\n",
    "\n",
    "# for k, v in time_decay_weights.items():\n",
    "#     weighting_schemes[k] = v\n",
    "\n",
    "weighting_schemes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd0230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average uniqueness: 0.0735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "min_w_leaf = 0.05\n",
    "print(f\"Average uniqueness: {avg_u:.4f}\\n\")\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=100,\n",
    "    random_state=random_state,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    )\n",
    "\n",
    "clf0 = rf\n",
    "clf1 = clone(rf).set_params(class_weight='balanced_subsample')\n",
    "clf2 = clone(rf).set_params(max_samples=avg_u)\n",
    "clf3 = clone(rf).set_params(max_samples=avg_u, class_weight='balanced_subsample')\n",
    "clfs = {k: v for k, v in zip(['standard', 'balanced_subsample', 'max_samples', 'combined'], [clf0, clf1, clf2, clf3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a9faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cont_train[\"tW\"].hist(bins=100, grid=False)\n",
    "plt.title(f\"Average Uniqueness - MA_{fast_window}_{slow_window} Crossover Strategy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d38785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Weighting Schemes\n",
      "unweighted balanced_subsample model achieved the best f1 score of 0.405778\n",
      "uniqueness balanced_subsample model achieved the best f1 score of 0.326313\n",
      "return combined model achieved the best f1 score of 0.674708\n",
      "\n",
      "                           unweighted         uniqueness             return\n",
      "standard            0.000000 ± 0.0000  0.000000 ± 0.0000  0.480684 ± 0.1373\n",
      "balanced_subsample  0.405778 ± 0.0620  0.326313 ± 0.0933  0.674708 ± 0.0518\n",
      "max_samples         0.000000 ± 0.0000  0.000000 ± 0.0000  0.291804 ± 0.1409\n",
      "combined            0.358043 ± 0.0838  0.249652 ± 0.1109  0.674708 ± 0.0518\n",
      "\n",
      "Selected Best Classifier (balanced_subsample): RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       min_weight_fraction_leaf=0.05, n_jobs=-1,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)\n",
    "cv_scores_d = {k: {} for k in clfs.keys()}\n",
    "print(rf.__class__.__name__, \"Weighting Schemes\")\n",
    "all_clf_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "best_models = []\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    best_score, best_model = None, None\n",
    "    for param, clf in clfs.items():\n",
    "        w = sample_weights.values\n",
    "        cv_scores = ml_cross_val_score(\n",
    "            clf, X_train, y_train, cv_gen, \n",
    "            sample_weight_train=w, \n",
    "            sample_weight_score=w,\n",
    "            scoring=\"f1\",\n",
    "        )\n",
    "        score = cv_scores.mean()\n",
    "        cv_scores_d[param][scheme] = score\n",
    "        best_score = max(best_score, score) if best_score is not None else score\n",
    "        if score == best_score:\n",
    "            best_model = param\n",
    "        all_clf_scores_df.loc[param, scheme] = f\"{cv_scores.mean():.6f} ± {cv_scores.std():.4f}\"\n",
    "    best_models.append(best_model)\n",
    "    print(f\"{scheme} {best_model} model achieved the best f1 score of {best_score:.6f}\")\n",
    "\n",
    "print()\n",
    "pprint(all_clf_scores_df, sort_dicts=False)\n",
    "best_model = max(best_models, key=best_models.count)\n",
    "best_clf = clone(clfs[best_model])\n",
    "print(f\"\\nSelected Best Classifier ({best_model}): {best_clf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   unweighted       uniqueness           return\n",
      "accuracy       0.5640 ± 0.081   0.6234 ± 0.070   0.5116 ± 0.063\n",
      "pwa            0.5954 ± 0.103   0.7045 ± 0.070   0.5103 ± 0.065\n",
      "neg_log_loss  -0.6810 ± 0.025  -0.6501 ± 0.024  -0.7781 ± 0.058\n",
      "precision      0.3450 ± 0.036   0.3223 ± 0.046   0.5116 ± 0.063\n",
      "recall         0.5335 ± 0.186   0.3749 ± 0.181   1.0000 ± 0.000\n",
      "f1             0.4058 ± 0.062   0.3263 ± 0.093   0.6747 ± 0.052\n",
      "\n",
      "return model achieved the best f1 score of 0.674708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_cv_scores_d = {}\n",
    "all_cms = {}\n",
    "best_score, best_model = None, None\n",
    "all_cv_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    w = sample_weights.values\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        best_clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    score = cv_scores['f1'].mean()\n",
    "    all_cv_scores_d[scheme] = cv_scores\n",
    "    all_cms[scheme] = cms\n",
    "    best_score = max(best_score, score) if best_score is not None else score\n",
    "    if score == best_score:\n",
    "        best_model = scheme\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores_df.loc[idx, scheme] = f\"{row['mean']:.6f} ± {row['std']:.3f}\"\n",
    "pprint(all_cv_scores_df)\n",
    "print(f\"\\n{best_model} model achieved the best f1 score of {best_score:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d97e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unweighted': [{'fold': 1, 'TN': 393.0, 'FP': 328.0, 'FN': 110.0, 'TP': 185.0},\n",
      "                {'fold': 2, 'TN': 483.0, 'FP': 248.0, 'FN': 158.0, 'TP': 127.0},\n",
      "                {'fold': 3, 'TN': 450.0, 'FP': 279.0, 'FN': 156.0, 'TP': 131.0},\n",
      "                {'fold': 4, 'TN': 578.0, 'FP': 161.0, 'FN': 187.0, 'TP': 90.0},\n",
      "                {'fold': 5, 'TN': 139.0, 'FP': 482.0, 'FN': 80.0, 'TP': 315.0},\n",
      "                {'fold': 6, 'TN': 336.0, 'FP': 419.0, 'FN': 91.0, 'TP': 170.0},\n",
      "                {'fold': 7, 'TN': 518.0, 'FP': 229.0, 'FN': 158.0, 'TP': 111.0},\n",
      "                {'fold': 8, 'TN': 596.0, 'FP': 127.0, 'FN': 205.0, 'TP': 88.0},\n",
      "                {'fold': 9, 'TN': 480.0, 'FP': 267.0, 'FN': 150.0, 'TP': 119.0},\n",
      "                {'fold': 10,\n",
      "                 'TN': 129.0,\n",
      "                 'FP': 554.0,\n",
      "                 'FN': 41.0,\n",
      "                 'TP': 292.0}],\n",
      " 'uniqueness': [{'fold': 1, 'TN': 30.15, 'FP': 15.23, 'FN': 8.09, 'TP': 8.55},\n",
      "                {'fold': 2, 'TN': 38.07, 'FP': 12.72, 'FN': 11.85, 'TP': 5.95},\n",
      "                {'fold': 3, 'TN': 42.39, 'FP': 14.82, 'FN': 14.37, 'TP': 6.75},\n",
      "                {'fold': 4, 'TN': 90.37, 'FP': 8.22, 'FN': 27.62, 'TP': 3.48},\n",
      "                {'fold': 5, 'TN': 15.7, 'FP': 10.91, 'FN': 8.86, 'TP': 7.94},\n",
      "                {'fold': 6, 'TN': 25.53, 'FP': 18.85, 'FN': 6.98, 'TP': 7.0},\n",
      "                {'fold': 7, 'TN': 42.51, 'FP': 15.83, 'FN': 12.6, 'TP': 5.37},\n",
      "                {'fold': 8, 'TN': 68.25, 'FP': 6.42, 'FN': 21.56, 'TP': 3.62},\n",
      "                {'fold': 9, 'TN': 52.85, 'FP': 14.41, 'FN': 14.41, 'TP': 6.12},\n",
      "                {'fold': 10, 'TN': 11.95, 'FP': 18.37, 'FN': 2.93, 'TP': 9.08}],\n",
      " 'return': [{'fold': 1, 'TN': 0.0, 'FP': 435.9, 'FN': 0.0, 'TP': 519.53},\n",
      "            {'fold': 2, 'TN': 0.0, 'FP': 514.25, 'FN': 0.0, 'TP': 489.13},\n",
      "            {'fold': 3, 'TN': 0.0, 'FP': 536.09, 'FN': 0.0, 'TP': 440.01},\n",
      "            {'fold': 4, 'TN': 0.0, 'FP': 657.04, 'FN': 0.0, 'TP': 642.66},\n",
      "            {'fold': 5, 'TN': 0.0, 'FP': 302.37, 'FN': 0.0, 'TP': 646.52},\n",
      "            {'fold': 6, 'TN': 0.0, 'FP': 484.12, 'FN': 0.0, 'TP': 447.37},\n",
      "            {'fold': 7, 'TN': 0.0, 'FP': 547.72, 'FN': 0.0, 'TP': 466.52},\n",
      "            {'fold': 8, 'TN': 0.0, 'FP': 568.0, 'FN': 0.0, 'TP': 563.98},\n",
      "            {'fold': 9, 'TN': 0.0, 'FP': 579.0, 'FN': 0.0, 'TP': 534.86},\n",
      "            {'fold': 10, 'TN': 0.0, 'FP': 361.7, 'FN': 0.0, 'TP': 423.23}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(all_cms, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(1000, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfinlab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
