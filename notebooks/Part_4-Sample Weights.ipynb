{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883cfcc8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Meta-Labeling Experiments: A Step-by-Step Guide\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook recreates the meta-labeling experiments from Hudson & Thames' research in a beginner-friendly manner. Meta-labeling is a machine learning technique that sits on top of a primary trading strategy to improve performance by filtering out false positive signals.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Primary Model**: Generates trading signals (buy/sell/hold)\n",
    "- **Triple Barrier Method**: Advanced labeling technique that accounts for stop-loss, take-profit, and time-based exits\n",
    "- **Meta-Labeling**: Secondary ML model that decides whether to act on primary model signals\n",
    "- **Goal**: Improve Sharpe ratio, reduce drawdown, and increase precision\n",
    "\n",
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607009b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-03 22:21:16.514\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m389\u001b[0m - \u001b[34m\u001b[1mAuto-reload not available (install watchdog for file watching)\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:16.515\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m688\u001b[0m - \u001b[34m\u001b[1mEnhanced cache features available:\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:16.516\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m689\u001b[0m - \u001b[34m\u001b[1m  - Robust cache keys for NumPy/Pandas\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:16.525\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m690\u001b[0m - \u001b[34m\u001b[1m  - MLflow integration: ✓\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:16.527\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m691\u001b[0m - \u001b[34m\u001b[1m  - Backtest caching: ✓\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:16.529\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m692\u001b[0m - \u001b[34m\u001b[1m  - Cache monitoring: ✓\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:17.538\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m_configure_numba\u001b[0m:\u001b[36m59\u001b[0m - \u001b[34m\u001b[1mNumba cache configured: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\numba_cache\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:17.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mAFML cache system initialized:\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:17.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m  Joblib cache: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\joblib_cache\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:17.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1m  Numba cache: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\numba_cache\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:17.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1m  Loaded stats: 3 functions, 98.0% hit rate\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:20.522\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache.selective_cleaner\u001b[0m:\u001b[36m_load_tracking_data\u001b[0m:\u001b[36m39\u001b[0m - \u001b[34m\u001b[1mLoaded tracking data for 17 functions\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.616\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m146\u001b[0m - \u001b[34m\u001b[1mImported lightweight modules directly\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m467\u001b[0m - \u001b[1mAFML v1.0.0 ready - 10 heavy modules available for lazy loading\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.625\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m470\u001b[0m - \u001b[34m\u001b[1mCache status: Hit rate: 98.0% | Tracked functions: 3 | Heavy modules loaded: 0\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.633\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m474\u001b[0m - \u001b[34m\u001b[1m✓ Cache monitoring available\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.640\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m476\u001b[0m - \u001b[34m\u001b[1m✓ MLflow integration available\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.642\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m478\u001b[0m - \u001b[34m\u001b[1m✓ Backtest caching available\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36msetup_jupyter\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mSetting up AFML for Jupyter notebook...\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36msetup_jupyter_cache\u001b[0m:\u001b[36m583\u001b[0m - \u001b[1mSetting up cache for Jupyter notebook...\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.661\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36m_configure_numba\u001b[0m:\u001b[36m59\u001b[0m - \u001b[34m\u001b[1mNumba cache configured: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\numba_cache\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mAFML cache system initialized:\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1m  Joblib cache: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\joblib_cache\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1m  Numba cache: C:\\Users\\JoeN\\AppData\\Local\\afml\\afml\\Cache\\numba_cache\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36minitialize_cache_system\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1m  Loaded stats: 3 functions, 98.0% hit rate\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache.mlflow_integration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mMLflow tracking enabled: experiment=jupyter_experiments\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36msetup_jupyter_cache\u001b[0m:\u001b[36m613\u001b[0m - \u001b[1m✅ Jupyter cache ready!\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.cache\u001b[0m:\u001b[36msetup_jupyter_cache\u001b[0m:\u001b[36m614\u001b[0m - \u001b[1m   Use helpers: cache_status(), print_health(), optimize()\u001b[0m\n",
      "\u001b[32m2025-11-03 22:21:30.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml\u001b[0m:\u001b[36msetup_jupyter\u001b[0m:\u001b[36m304\u001b[0m - \u001b[1m✅ AFML Jupyter environment ready!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Dir: c:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# --- Extension Setup ---\n",
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 3 -p\n",
    "\n",
    "# --- Module Imports ---\n",
    "import sys\n",
    "sys.path.append(\"..\")  # Adjust if your afml repo is nested differently\n",
    "\n",
    "# --- Autoreload Target ---\n",
    "%aimport afml\n",
    "\n",
    "# --- AFML Initialization ---\n",
    "# Setup with auto-reload enabled\n",
    "import afml\n",
    "\n",
    "# Enhanced setup with all features\n",
    "components = afml.setup_jupyter(\n",
    "    enable_mlflow=True,      # Set True if you have mlflow installed\n",
    "    enable_monitoring=True,    # Cache analytics\n",
    ")\n",
    "\n",
    "# --- Environment Diagnostics ---\n",
    "from pathlib import Path\n",
    "print(f\"Working Dir: {Path.cwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2507ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import winsound\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import MetaTrader5 as mt5\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from afml.cross_validation import (\n",
    "    PurgedKFold,\n",
    "    PurgedSplit,\n",
    "    analyze_cross_val_scores,\n",
    "    ml_cross_val_score,\n",
    "    probability_weighted_accuracy,\n",
    ")\n",
    "from afml.cross_validation.scoring import probability_weighted_accuracy\n",
    "from afml.data_structures.bars import *\n",
    "from afml.ensemble.sb_bagging import (\n",
    "    SequentiallyBootstrappedBaggingClassifier,\n",
    "    compute_custom_oob_metrics,\n",
    "    estimate_ensemble_size,\n",
    ")\n",
    "from afml.labeling.triple_barrier import (\n",
    "    add_vertical_barrier,\n",
    "    get_event_weights,\n",
    "    triple_barrier_labels,\n",
    ")\n",
    "from afml.mt5.load_data import get_bars, login_mt5, get_ticks, save_data_to_parquet\n",
    "from afml.sample_weights.optimized_attribution import (\n",
    "    get_weights_by_time_decay_optimized,\n",
    ")\n",
    "\n",
    "# from afml.sampling import get_ind_mat_average_uniqueness, get_ind_matrix, seq_bootstrap\n",
    "from afml.strategies import (\n",
    "    BollingerStrategy,\n",
    "    MACrossoverStrategy,\n",
    "    create_bollinger_features,\n",
    "    get_entries,\n",
    "    ma_crossover_feature_engine,\n",
    ")\n",
    "from afml.util import get_daily_vol, value_counts_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.style.use(\"dark_background\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41127511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CACHE HEALTH REPORT\n",
      "======================================================================\n",
      "\n",
      "Overall Statistics:\n",
      "  Total Functions:     3\n",
      "  Total Calls:         153\n",
      "  Overall Hit Rate:    98.0%\n",
      "  Total Cache Size:    0.00 MB\n",
      "\n",
      "Top Performers (by hit rate):\n",
      "  1. triple_barrier_labels: 99.3% (151 calls)\n",
      "  2. create_bollinger_features: 0.0% (1 calls)\n",
      "  3. get_event_weights: 0.0% (1 calls)\n",
      "\n",
      "Worst Performers (by hit rate):\n",
      "  1. triple_barrier_labels: 99.3% (151 calls)\n",
      "  2. create_bollinger_features: 0.0% (1 calls)\n",
      "  3. get_event_weights: 0.0% (1 calls)\n",
      "\n",
      "Recommendations:\n",
      "  1. Excellent hit rate (>90%)! Cache system is performing well.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "function",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "calls",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hits",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "misses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hit_rate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "avg_time_ms",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cache_size_mb",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "last_access",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a52b7cd1-8616-4058-8051-7ea49679d7bf",
       "rows": [
        [
         "1",
         "afml.labeling.triple_barrier.triple_barrier_labels",
         "151",
         "150",
         "1",
         "99.3%",
         "N/A",
         "N/A",
         "N/A"
        ],
        [
         "0",
         "afml.strategies.bollinger_features.create_bollinger_features",
         "1",
         "0",
         "1",
         "0.0%",
         "N/A",
         "N/A",
         "N/A"
        ],
        [
         "2",
         "afml.labeling.triple_barrier.get_event_weights",
         "1",
         "0",
         "1",
         "0.0%",
         "N/A",
         "N/A",
         "N/A"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function</th>\n",
       "      <th>calls</th>\n",
       "      <th>hits</th>\n",
       "      <th>misses</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>avg_time_ms</th>\n",
       "      <th>cache_size_mb</th>\n",
       "      <th>last_access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afml.labeling.triple_barrier.triple_barrier_la...</td>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>99.3%</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afml.strategies.bollinger_features.create_boll...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afml.labeling.triple_barrier.get_event_weights</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            function  calls  hits  misses  \\\n",
       "1  afml.labeling.triple_barrier.triple_barrier_la...    151   150       1   \n",
       "0  afml.strategies.bollinger_features.create_boll...      1     0       1   \n",
       "2     afml.labeling.triple_barrier.get_event_weights      1     0       1   \n",
       "\n",
       "  hit_rate avg_time_ms cache_size_mb last_access  \n",
       "1    99.3%         N/A           N/A         N/A  \n",
       "0     0.0%         N/A           N/A         N/A  \n",
       "2     0.0%         N/A           N/A         N/A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add to your startup script or notebook\n",
    "from afml.cache import print_cache_health, get_cache_efficiency_report\n",
    "\n",
    "# Check cache health anytime\n",
    "print_cache_health()\n",
    "\n",
    "# Find functions with low hit rates or high call counts\n",
    "df = get_cache_efficiency_report()\n",
    "df.sort_values('calls', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160822e7",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f257b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"EURUSD\"\n",
    "start_date, end_date = \"2018-01-01\", \"2024-12-31\"\n",
    "sample_start, sample_end = start_date, \"2023-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129c536",
   "metadata": {},
   "source": [
    "## 2. Bollinger Band Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f960964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_timeframe = \"M5\"\n",
    "file = Path(r\"..\\data\\EURUSD_M5_time_2018-01-01-2024-12-31.parq\")\n",
    "bb_time_bars = pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaae6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_period, bb_std = 20, 2 # Bollinger Band parameters\n",
    "bb_strategy = BollingerStrategy(window=bb_period, num_std=bb_std)\n",
    "bb_lookback = 10\n",
    "bb_pt_barrier, bb_sl_barrier, bb_time_horizon = (1, 2, dict(days=1))\n",
    "min_ret = 5e-5\n",
    "bb_vol_multiplier = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83dccff",
   "metadata": {},
   "source": [
    "### Time-Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "144d9465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bollinger_w20_std2 Signals:\n",
      "\n",
      "        count  proportion\n",
      "side                     \n",
      " 0    373,536    0.842213\n",
      "-1     35,095    0.079129\n",
      " 1     34,886    0.078658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-03 20:29:13.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.filters.filters\u001b[0m:\u001b[36mcusum_filter\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1m19,458 CUSUM-filtered events\u001b[0m\n",
      "\u001b[32m2025-11-03 20:29:13.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.strategies.signal_processing\u001b[0m:\u001b[36mget_entries\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mBollinger_w20_std2 | 10,384 (14.84%) trade events selected by CUSUM filter using series.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "bb_side = bb_strategy.generate_signals(bb_time_bars)\n",
    "bb_df = bb_time_bars.loc[sample_start : sample_end]\n",
    "\n",
    "print(f\"{bb_strategy.get_strategy_name()} Signals:\")\n",
    "value_counts_data(bb_side.reindex(bb_df.index), verbose=True)\n",
    "\n",
    "# Volatility target for barriers\n",
    "vol_lookback = 100\n",
    "vol_target = get_daily_vol(bb_df.close, vol_lookback) * bb_vol_multiplier\n",
    "close = bb_df.close\n",
    "_, t_events = get_entries(bb_strategy, bb_df, filter_threshold=vol_target)\n",
    "\n",
    "vertical_barriers = add_vertical_barrier(t_events, close, **bb_time_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ada8a2",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d09b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 516825 entries, 2018-01-02 23:20:00 to 2024-12-31 00:00:00\n",
      "Data columns (total 49 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   spread               516825 non-null  float32\n",
      " 1   vol                  516825 non-null  float32\n",
      " 2   h1_vol               516825 non-null  float32\n",
      " 3   h4_vol               516825 non-null  float32\n",
      " 4   d1_vol               516825 non-null  float32\n",
      " 5   ret                  516825 non-null  float32\n",
      " 6   ret_5                516825 non-null  float32\n",
      " 7   ret_10               516825 non-null  float32\n",
      " 8   ret_1_lag_1          516825 non-null  float32\n",
      " 9   ret_5_lag_1          516825 non-null  float32\n",
      " 10  ret_10_lag_1         516825 non-null  float32\n",
      " 11  ret_1_lag_2          516825 non-null  float32\n",
      " 12  ret_5_lag_2          516825 non-null  float32\n",
      " 13  ret_10_lag_2         516825 non-null  float32\n",
      " 14  ret_1_lag_3          516825 non-null  float32\n",
      " 15  ret_5_lag_3          516825 non-null  float32\n",
      " 16  ret_10_lag_3         516825 non-null  float32\n",
      " 17  ret_skew             516825 non-null  float32\n",
      " 18  ret_kurt             516825 non-null  float32\n",
      " 19  autocorr             516825 non-null  float32\n",
      " 20  autocorr_1           516825 non-null  float32\n",
      " 21  autocorr_2           516825 non-null  float32\n",
      " 22  autocorr_3           516825 non-null  float32\n",
      " 23  autocorr_4           516825 non-null  float32\n",
      " 24  autocorr_5           516825 non-null  float32\n",
      " 25  bbb_20_2.0           516825 non-null  float32\n",
      " 26  bbp_20_2.0           516825 non-null  float64\n",
      " 27  truerange_1          516825 non-null  float32\n",
      " 28  atrr_14              516825 non-null  float32\n",
      " 29  rsi_14               516825 non-null  float32\n",
      " 30  stochrsik_14_14_3_3  516825 non-null  float32\n",
      " 31  stochrsid_14_14_3_3  516825 non-null  float32\n",
      " 32  adx_14               516825 non-null  float32\n",
      " 33  dmp_14               516825 non-null  float32\n",
      " 34  dmn_14               516825 non-null  float32\n",
      " 35  dm_net               516825 non-null  float32\n",
      " 36  macd_12_26_9         516825 non-null  float32\n",
      " 37  macdh_12_26_9        516825 non-null  float32\n",
      " 38  sma_diff_10_20       516825 non-null  float32\n",
      " 39  sma_diff_10_100      516825 non-null  float32\n",
      " 40  sma_diff_100_200     516825 non-null  float32\n",
      " 41  sma_cross_10_20      516825 non-null  int8   \n",
      " 42  sma_cross_10_50      516825 non-null  int8   \n",
      " 43  sma_cross_10_100     516825 non-null  int8   \n",
      " 44  sma_cross_10_200     516825 non-null  int8   \n",
      " 45  sma_cross_50_100     516825 non-null  int8   \n",
      " 46  sma_cross_100_200    516825 non-null  int8   \n",
      " 47  prev_signal          516825 non-null  int8   \n",
      " 48  side                 516825 non-null  int8   \n",
      "dtypes: float32(40), float64(1), int8(8)\n",
      "memory usage: 90.7 MB\n"
     ]
    }
   ],
   "source": [
    "bb_feat = create_bollinger_features(bb_time_bars, bb_period, bb_std)\n",
    "bb_feat_time = bb_feat.join(bb_side, how=\"inner\")\n",
    "bb_feat_time.info()\n",
    "# not_stationary = is_stationary(bb_feat_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1c961",
   "metadata": {},
   "source": [
    "#### Triple-Barrier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf6686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple-Barrier (pt=1, sl=2, h={'days': 1}):\n",
      "\n",
      "     count  proportion\n",
      "bin                   \n",
      "-1   5,109    0.505741\n",
      " 1   4,993    0.494259\n",
      "\n",
      "Average Uniqueness: 0.7465\n"
     ]
    }
   ],
   "source": [
    "bb_events_tb = triple_barrier_labels(\n",
    "    close,\n",
    "    vol_target,\n",
    "    t_events,\n",
    "    pt_sl=[bb_pt_barrier, bb_sl_barrier],\n",
    "    min_ret=min_ret,\n",
    "    vertical_barrier_times=vertical_barriers,\n",
    "    vertical_barrier_zero=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "bb_events_tb_time = bb_events_tb.copy()\n",
    "print(f\"Triple-Barrier (pt={bb_pt_barrier}, sl={bb_sl_barrier}, h={bb_time_horizon}):\")\n",
    "value_counts_data(bb_events_tb['bin'], verbose=True)\n",
    "\n",
    "weights = get_event_weights(bb_events_tb, close)\n",
    "av_uniqueness = weights['tW'].mean()\n",
    "print(f\"Average Uniqueness: {av_uniqueness:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b85936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple-Barrier (pt=1, sl=2, h={'days': 1}):\n",
      "\n",
      "     count  proportion\n",
      "bin                   \n",
      "1    6,506    0.626601\n",
      "0    3,877    0.373399\n",
      "\n",
      "Average Uniqueness: 0.5488\n"
     ]
    }
   ],
   "source": [
    "bb_events_tb = triple_barrier_labels(\n",
    "    close,\n",
    "    vol_target,\n",
    "    t_events,\n",
    "    pt_sl=[bb_pt_barrier, bb_sl_barrier],\n",
    "    min_ret=min_ret,\n",
    "    vertical_barrier_times=vertical_barriers,\n",
    "    side_prediction=bb_side,\n",
    "    vertical_barrier_zero=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "bb_events_tb_time_meta = bb_events_tb.copy()\n",
    "print(f\"Triple-Barrier (pt={bb_pt_barrier}, sl={bb_sl_barrier}, h={bb_time_horizon}):\")\n",
    "value_counts_data(bb_events_tb['bin'], verbose=True)\n",
    "\n",
    "weights = get_event_weights(bb_events_tb, close)\n",
    "av_uniqueness = weights['tW'].mean()\n",
    "print(f\"Average Uniqueness: {av_uniqueness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac89d4",
   "metadata": {},
   "source": [
    "#### Primary Model - CV of Weighting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83808c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "\n",
    "# Reserve 1 CPU if you want to do something else during training,\n",
    "# otherwise set to -1\n",
    "N_JOBS = cpu_count() - 1\n",
    "N_ESTIMATORS = 100\n",
    "random_state = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9509134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = bb_events_tb_time.copy()\n",
    "X = bb_feat_time.reindex(cont.index)\n",
    "y = cont[\"bin\"]\n",
    "t1 = cont[\"t1\"]\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "train, test = PurgedSplit(t1, test_size).split(X)\n",
    "X_train, X_test, y_train, y_test = (\n",
    "        X.iloc[train],\n",
    "        X.iloc[test],\n",
    "        y.iloc[train],\n",
    "        y.iloc[test],\n",
    "    )\n",
    "\n",
    "cont_train = get_event_weights(cont.iloc[train], bb_df.close)\n",
    "bb_cont_train = cont_train.copy()\n",
    "\n",
    "n_splits = 5\n",
    "pct_embargo = 0.01\n",
    "cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e03121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Uniqueness in Training Set: 0.7473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['unweighted', 'uniqueness', 'return'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_u = cont_train.tW.mean()\n",
    "print(f\"Average Uniqueness in Training Set: {avg_u:.4f}\")\n",
    "\n",
    "weighting_schemes = {\n",
    "    \"unweighted\": pd.Series(1., index=cont_train.index),\n",
    "    \"uniqueness\": cont_train[\"tW\"],\n",
    "    \"return\": cont_train[\"w\"],\n",
    "    }\n",
    "\n",
    "decay_factors = [0.0, 0.25, 0.5, 0.75]\n",
    "time_decay_weights = {}\n",
    "for time_decay in decay_factors:\n",
    "    decay_w = get_weights_by_time_decay_optimized(\n",
    "                triple_barrier_events=cont,\n",
    "                close_index=close.index,\n",
    "                last_weight=time_decay,\n",
    "                linear=True,\n",
    "                av_uniqueness=cont_train[\"tW\"],\n",
    "            )\n",
    "    time_decay_weights[f\"decay_{time_decay}\"] = decay_w\n",
    "        \n",
    "# for k, v in time_decay_weights.items():\n",
    "#     if k.startswith(\"linear\"):\n",
    "#         weighting_schemes[k] = v\n",
    "\n",
    "weighting_schemes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beab8ff",
   "metadata": {},
   "source": [
    "##### Selection of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d2c2bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standard': RandomForestClassifier(criterion='entropy', max_depth=6,\n",
       "                        min_weight_fraction_leaf=0.05, n_jobs=3, random_state=7),\n",
       " 'balanced_subsample': RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
       "                        max_depth=6, min_weight_fraction_leaf=0.05, n_jobs=3,\n",
       "                        random_state=7),\n",
       " 'max_samples': RandomForestClassifier(criterion='entropy', max_depth=6,\n",
       "                        max_samples=0.7472647467858778,\n",
       "                        min_weight_fraction_leaf=0.05, n_jobs=3, random_state=7),\n",
       " 'combined': RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
       "                        max_depth=6, max_samples=0.7472647467858778,\n",
       "                        min_weight_fraction_leaf=0.05, n_jobs=3, random_state=7)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_w_leaf = 0.05\n",
    "max_depth = 6\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    random_state=random_state,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    n_jobs=N_JOBS,  # Use all available cores\n",
    "    )\n",
    "\n",
    "clf0 = rf\n",
    "clf1 = clone(rf).set_params(class_weight='balanced_subsample')\n",
    "clf2 = clone(rf).set_params(max_samples=avg_u)\n",
    "clf3 = clone(rf).set_params(max_samples=avg_u, class_weight='balanced_subsample')\n",
    "\n",
    "clfs = {k: v for k, v in zip(['standard', 'balanced_subsample', 'max_samples', 'combined'], [clf0, clf1, clf2, clf3])}\n",
    "clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52efd9a4",
   "metadata": {},
   "source": [
    "Find what model produces best CV log loss score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06278dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Weighting Schemes\n",
      "return standard model achieved the best neg_log_loss score of -0.6613\n",
      "\n",
      "Weighting Scheme CV:\n",
      "                          unweighted        uniqueness            return\n",
      "standard            -0.6937 ± 0.0012  -0.6934 ± 0.0013  -0.6613 ± 0.0057\n",
      "balanced_subsample  -0.6938 ± 0.0014  -0.6935 ± 0.0015  -0.6614 ± 0.0058\n",
      "max_samples         -0.6936 ± 0.0009  -0.6934 ± 0.0012  -0.6617 ± 0.0052\n",
      "combined            -0.6938 ± 0.0008  -0.6935 ± 0.0013  -0.6617 ± 0.0052\n",
      "\n",
      "Selected Best Classifier (standard): RandomForestClassifier(criterion='entropy', max_depth=6,\n",
      "                       min_weight_fraction_leaf=0.05, n_jobs=3, random_state=7)\n"
     ]
    }
   ],
   "source": [
    "cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)\n",
    "cv_scores_d = {k: {} for k in clfs.keys()}\n",
    "print(rf.__class__.__name__, \"Weighting Schemes\")\n",
    "all_clf_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "best_models = []\n",
    "best_score, best_model, best_scheme = None, None, None\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    for param, clf in clfs.items():\n",
    "        cv_scores = ml_cross_val_score(\n",
    "            clf, X_train, y_train, cv_gen, \n",
    "            sample_weight_train=sample_weights, \n",
    "            sample_weight_score=sample_weights,\n",
    "            scoring=\"neg_log_loss\",\n",
    "        )\n",
    "        score = cv_scores.mean()\n",
    "        cv_scores_d[param][scheme] = score\n",
    "        best_score = max(best_score, score) if best_score is not None else score\n",
    "        if score == best_score:\n",
    "            best_model = param\n",
    "            best_scheme = scheme\n",
    "        all_clf_scores_df.loc[param, scheme] = f\"{cv_scores.mean():.4f} ± {cv_scores.std():.4f}\"\n",
    "\n",
    "best_clf = clone(clfs[best_model])\n",
    "print(f\"{best_scheme} {best_model} model achieved the best neg_log_loss score of {best_score:.4f}\")\n",
    "\n",
    "print(\"\\nWeighting Scheme CV:\")\n",
    "pprint(all_clf_scores_df)\n",
    "print(f\"\\nSelected Best Classifier ({best_model}): {best_clf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715022e",
   "metadata": {},
   "source": [
    "Analyze all CV scores for all weighting schemes with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "311350fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighting Scheme CV:\n",
      "                   accuracy              pwa      neg_log_loss  \\\n",
      "unweighted  0.5047 ± 0.0161  0.5085 ± 0.0171  -0.6937 ± 0.0012   \n",
      "uniqueness  0.5094 ± 0.0184  0.5133 ± 0.0147  -0.6934 ± 0.0013   \n",
      "return      0.6249 ± 0.0146  0.6343 ± 0.0139  -0.6613 ± 0.0057   \n",
      "\n",
      "                  precision           recall               f1  \n",
      "unweighted  0.4963 ± 0.0307  0.3294 ± 0.0785  0.3893 ± 0.0475  \n",
      "uniqueness  0.5027 ± 0.0407  0.3409 ± 0.0925  0.3972 ± 0.0626  \n",
      "return      0.6183 ± 0.0177  0.6025 ± 0.0327  0.6101 ± 0.0247  \n",
      "\n",
      "return model achieved the best neg_log_loss score of -0.6613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from afml.cross_validation.cross_validation import analyze_cross_val_scores\n",
    "\n",
    "all_cv_scores_d = {}\n",
    "all_cms = {}\n",
    "best_score, best_model = None, None\n",
    "all_cv_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "scoring = 'f1' if set(y_train.unique()) == {0, 1} else 'neg_log_loss'\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        best_clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=sample_weights, \n",
    "        sample_weight_score=sample_weights,\n",
    "    )\n",
    "    score = cv_scores[scoring].mean()\n",
    "    all_cv_scores_d[scheme] = cv_scores\n",
    "    all_cms[scheme] = cms\n",
    "    best_score = max(best_score, score) if best_score is not None else score\n",
    "    if score == best_score:\n",
    "        best_scheme = scheme\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores_df.loc[idx, scheme] = f\"{row['mean']:.4f} ± {row['std']:.4f}\"\n",
    "\n",
    "print(\"Weighting Scheme CV:\")\n",
    "pprint(all_cv_scores_df.T)\n",
    "print(f\"\\n{best_scheme} model achieved the best {scoring} score of {best_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4202d9a5",
   "metadata": {},
   "source": [
    "Test if time-decay improves performance of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d092e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Weighting Scheme CV - Return:\n",
      "                        return  return_decay_0.0 return_decay_0.25  \\\n",
      "accuracy       0.6249 ± 0.0146   0.6236 ± 0.0117   0.6236 ± 0.0120   \n",
      "pwa            0.6343 ± 0.0139   0.6332 ± 0.0144   0.6331 ± 0.0138   \n",
      "neg_log_loss  -0.6613 ± 0.0057  -0.6628 ± 0.0057  -0.6623 ± 0.0056   \n",
      "precision      0.6183 ± 0.0177   0.6184 ± 0.0162   0.6179 ± 0.0169   \n",
      "recall         0.6025 ± 0.0327   0.5966 ± 0.0310   0.5983 ± 0.0317   \n",
      "f1             0.6101 ± 0.0247   0.6071 ± 0.0227   0.6077 ± 0.0232   \n",
      "\n",
      "              return_decay_0.5 return_decay_0.75  \n",
      "accuracy       0.6224 ± 0.0121   0.6225 ± 0.0152  \n",
      "pwa            0.6336 ± 0.0137   0.6328 ± 0.0143  \n",
      "neg_log_loss  -0.6618 ± 0.0055  -0.6621 ± 0.0058  \n",
      "precision      0.6159 ± 0.0176   0.6156 ± 0.0191  \n",
      "recall         0.5999 ± 0.0297   0.6007 ± 0.0335  \n",
      "f1             0.6076 ± 0.0225   0.6079 ± 0.0257  \n",
      "\n",
      "return model achieved the best neg_log_loss score of -0.6613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_decay_cv_scores = all_cv_scores_df[[best_scheme]]\n",
    "\n",
    "for scheme, decay_factor in time_decay_weights.items():\n",
    "    sample_weights = weighting_schemes[best_scheme] * decay_factor\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        best_clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=sample_weights, \n",
    "        sample_weight_score=sample_weights,\n",
    "    )\n",
    "    score = cv_scores[scoring].mean()\n",
    "    scheme = f\"{best_scheme}_{scheme}\"\n",
    "    all_cv_scores_d[scheme] = cv_scores\n",
    "    all_cms[scheme] = cms\n",
    "    best_score = max(best_score, score) if best_score is not None else score\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        best_model_decay_cv_scores.loc[idx, scheme] = f\"{row['mean']:.4f} ± {row['std']:.4f}\"\n",
    "    if score == best_score:\n",
    "        best_scheme = scheme\n",
    "        weighting_schemes[best_scheme] = sample_weights\n",
    "        all_cv_scores_df[scheme] = best_model_decay_cv_scores[scheme]\n",
    "        \n",
    "\n",
    "print(f\"\\nBest Weighting Scheme CV - {best_scheme.title()}:\")\n",
    "pprint(best_model_decay_cv_scores)\n",
    "\n",
    "print(f\"\\n{best_scheme} model achieved the best {scoring} score of {best_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e9d79fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentiallyBootstrappedBaggingClassifier(estimator=RandomForestClassifier(bootstrap=False,\n",
      "                                                                           criterion='entropy',\n",
      "                                                                           max_depth=6,\n",
      "                                                                           min_weight_fraction_leaf=0.05,\n",
      "                                                                           n_estimators=1,\n",
      "                                                                           n_jobs=3),\n",
      "                                          max_features=1, n_estimators=100,\n",
      "                                          n_jobs=3, oob_score=True,\n",
      "                                          price_bars_index=DatetimeIndex(['2018-01-01 23:05:00', '2018-01-01 23:10:00',\n",
      "               '2018-01-01 23:15:00', '2018-01-01 23:20:00',...\n",
      "2018-01-03 01:30:00   2018-01-03 01:50:00\n",
      "2018-01-03 02:40:00   2018-01-03 04:00:00\n",
      "2018-01-03 05:35:00   2018-01-03 08:10:00\n",
      "2018-01-03 06:45:00   2018-01-03 07:55:00\n",
      "                              ...        \n",
      "2022-10-04 14:50:00   2022-10-04 17:30:00\n",
      "2022-10-05 02:10:00   2022-10-05 04:45:00\n",
      "2022-10-05 02:40:00   2022-10-05 09:20:00\n",
      "2022-10-05 14:50:00   2022-10-05 16:20:00\n",
      "2022-10-05 16:05:00   2022-10-06 01:55:00\n",
      "Name: t1, Length: 8082, dtype: datetime64[ns],\n",
      "                                          verbose=False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(seq_rf)\n\u001b[0;32m     18\u001b[0m w \u001b[38;5;241m=\u001b[39m weighting_schemes[best_scheme]\n\u001b[1;32m---> 19\u001b[0m cv_scores, cv_scores_df, cms \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_cross_val_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m all_cms[scheme] \u001b[38;5;241m=\u001b[39m cms\n\u001b[0;32m     26\u001b[0m scheme \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_bootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\joen\\documents\\github\\machine-learning-blueprint\\afml\\cross_validation\\cross_validation.py:391\u001b[0m, in \u001b[0;36manalyze_cross_val_scores\u001b[1;34m(classifier, X, y, cv_gen, sample_weight_train, sample_weight_score)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq_bootstrap:\n\u001b[0;32m    388\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m clone(classifier)\u001b[38;5;241m.\u001b[39mset_params(\n\u001b[0;32m    389\u001b[0m         samples_info_sets\u001b[38;5;241m=\u001b[39mt1\u001b[38;5;241m.\u001b[39miloc[train]\n\u001b[0;32m    390\u001b[0m     )  \u001b[38;5;66;03m# Create new instance\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m prob \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict_proba(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n\u001b[0;32m    397\u001b[0m pred \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n",
      "File \u001b[1;32mc:\\users\\joen\\documents\\github\\machine-learning-blueprint\\afml\\ensemble\\sb_bagging.py:323\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m    Build a Sequentially Bootstrapped Bagging ensemble of estimators from the training\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    set (X, y).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    self : (object)\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\joen\\documents\\github\\machine-learning-blueprint\\afml\\ensemble\\sb_bagging.py:570\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaggingClassifier._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# Call parent _fit method\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\joen\\documents\\github\\machine-learning-blueprint\\afml\\ensemble\\sb_bagging.py:433\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds, seeds])\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# Build estimators in parallel\u001b[39;00m\n\u001b[1;32m--> 433\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_indices_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Unpack results\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Base estimator for use with sequential bootstrapping\n",
    "base_rf = clone(best_clf).set_params(bootstrap=False, n_estimators=1, random_state=None, n_jobs=1)\n",
    "\n",
    "seq_rf = SequentiallyBootstrappedBaggingClassifier(\n",
    "    samples_info_sets=cont_train.t1,\n",
    "    price_bars_index=bb_df.index,\n",
    "    estimator=base_rf,\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    max_features=1,\n",
    "    bootstrap_features=True,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    verbose=False,\n",
    ")\n",
    "seq_rf\n",
    "\n",
    "w = weighting_schemes[best_scheme]\n",
    "cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        seq_rf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "all_cms[scheme] = cms\n",
    "\n",
    "scheme = 'seq_bootstrap'\n",
    "for idx, row in cv_scores_df.iterrows():\n",
    "    all_cv_scores_df.loc[idx, scheme] = f\"{row['mean']:.4f} ± {row['std']:.4f}\"\n",
    "\n",
    "all_cv_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81fbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unweighted': [{'fold': 1, 'TN': 418.0, 'FP': 323.0, 'FN': 406.0, 'TP': 268.0},\n",
      "                {'fold': 2, 'TN': 424.0, 'FP': 311.0, 'FN': 397.0, 'TP': 283.0},\n",
      "                {'fold': 3, 'TN': 452.0, 'FP': 272.0, 'FN': 415.0, 'TP': 275.0},\n",
      "                {'fold': 4, 'TN': 523.0, 'FP': 145.0, 'FN': 586.0, 'TP': 160.0},\n",
      "                {'fold': 5,\n",
      "                 'TN': 447.0,\n",
      "                 'FP': 289.0,\n",
      "                 'FN': 382.0,\n",
      "                 'TP': 296.0}],\n",
      " 'uniqueness': [{'fold': 1,\n",
      "                 'TN': 290.15,\n",
      "                 'FP': 264.99,\n",
      "                 'FN': 285.79,\n",
      "                 'TP': 219.37},\n",
      "                {'fold': 2,\n",
      "                 'TN': 300.46,\n",
      "                 'FP': 239.37,\n",
      "                 'FN': 287.24,\n",
      "                 'TP': 214.31},\n",
      "                {'fold': 3,\n",
      "                 'TN': 312.49,\n",
      "                 'FP': 225.93,\n",
      "                 'FN': 277.21,\n",
      "                 'TP': 229.54},\n",
      "                {'fold': 4,\n",
      "                 'TN': 380.43,\n",
      "                 'FP': 116.82,\n",
      "                 'FN': 438.11,\n",
      "                 'TP': 125.22},\n",
      "                {'fold': 5,\n",
      "                 'TN': 318.43,\n",
      "                 'FP': 227.8,\n",
      "                 'FN': 286.07,\n",
      "                 'TP': 221.94}],\n",
      " 'return': [{'fold': 1, 'TN': 560.99, 'FP': 287.41, 'FN': 303.04, 'TP': 507.41},\n",
      "            {'fold': 2, 'TN': 389.91, 'FP': 231.5, 'FN': 242.77, 'TP': 324.69},\n",
      "            {'fold': 3, 'TN': 458.48, 'FP': 284.82, 'FN': 269.05, 'TP': 451.65},\n",
      "            {'fold': 4, 'TN': 470.74, 'FP': 244.17, 'FN': 302.44, 'TP': 475.39},\n",
      "            {'fold': 5,\n",
      "             'TN': 440.61,\n",
      "             'FP': 229.35,\n",
      "             'FN': 243.93,\n",
      "             'TP': 353.65}],\n",
      " 'seq_bootstrap': [{'fold': 1,\n",
      "                    'TN': 465.21,\n",
      "                    'FP': 383.19,\n",
      "                    'FN': 421.68,\n",
      "                    'TP': 388.78},\n",
      "                   {'fold': 2,\n",
      "                    'TN': 359.72,\n",
      "                    'FP': 261.69,\n",
      "                    'FN': 302.48,\n",
      "                    'TP': 264.98},\n",
      "                   {'fold': 3,\n",
      "                    'TN': 366.89,\n",
      "                    'FP': 376.4,\n",
      "                    'FN': 383.23,\n",
      "                    'TP': 337.47},\n",
      "                   {'fold': 4,\n",
      "                    'TN': 446.24,\n",
      "                    'FP': 268.67,\n",
      "                    'FN': 452.1,\n",
      "                    'TP': 325.73},\n",
      "                   {'fold': 5,\n",
      "                    'TN': 364.63,\n",
      "                    'FP': 305.32,\n",
      "                    'FN': 292.12,\n",
      "                    'TP': 305.45}]}\n"
     ]
    }
   ],
   "source": [
    "all_cms[scheme] = cms\n",
    "# pprint(all_cms, sort_dicts=False)\n",
    "pprint(all_cms[best_model], sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e7d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Bootstrap done in 0 days 00:12:06\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "standard_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf_avgu",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf_unweighted_avgu",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7ed9ac37-e0c2-4db8-9da8-b21aea2df33a",
       "rows": [
        [
         "accuracy",
         "0.4855",
         "0.504",
         "0.5013",
         "0.5"
        ],
        [
         "pwa",
         "0.4918",
         "0.5024",
         "0.4899",
         "0.4916"
        ],
        [
         "neg_log_loss",
         "-0.7232",
         "-0.7016",
         "-0.7036",
         "-0.7033"
        ],
        [
         "precision",
         "0.4888",
         "0.5077",
         "0.5054",
         "0.5038"
        ],
        [
         "recall",
         "0.4852",
         "0.4728",
         "0.4315",
         "0.4315"
        ],
        [
         "f1",
         "0.487",
         "0.4896",
         "0.4655",
         "0.4649"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_rf</th>\n",
       "      <th>sequential_rf</th>\n",
       "      <th>sequential_rf_avgu</th>\n",
       "      <th>sequential_rf_unweighted_avgu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.4855</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwa</th>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.4916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.7232</td>\n",
       "      <td>-0.7016</td>\n",
       "      <td>-0.7036</td>\n",
       "      <td>-0.7033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.5038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.4315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.4870</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.4649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              standard_rf  sequential_rf  sequential_rf_avgu  \\\n",
       "accuracy           0.4855         0.5040              0.5013   \n",
       "pwa                0.4918         0.5024              0.4899   \n",
       "neg_log_loss      -0.7232        -0.7016             -0.7036   \n",
       "precision          0.4888         0.5077              0.5054   \n",
       "recall             0.4852         0.4728              0.4315   \n",
       "f1                 0.4870         0.4896              0.4655   \n",
       "\n",
       "              sequential_rf_unweighted_avgu  \n",
       "accuracy                             0.5000  \n",
       "pwa                                  0.4916  \n",
       "neg_log_loss                        -0.7033  \n",
       "precision                            0.5038  \n",
       "recall                               0.4315  \n",
       "f1                                   0.4649  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = weighting_schemes[best_scheme]\n",
    "rf = best_clf.set_params(oob_score=True).fit(\n",
    "    X_train, y_train, sample_weight=w,\n",
    ")\n",
    "\n",
    "time0 = time.time()\n",
    "seq_rf.set_params(oob_score=True).fit(\n",
    "    X_train, y_train, sample_weight=w,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential Bootstrap done in {time1}\")\n",
    "\n",
    "ensembles = {\n",
    "    \"standard_rf\": {\"classifier\": rf, \n",
    "                    \"pred\": rf.predict(X_test),\n",
    "                    \"prob\": rf.predict_proba(X_test),\n",
    "                    \"oob\": rf.oob_score_,\n",
    "                },\n",
    "    \"sequential_rf\": {\"classifier\": seq_rf, \n",
    "                      \"pred\": seq_rf.predict(X_test),\n",
    "                      \"prob\": seq_rf.predict_proba(X_test),\n",
    "                      \"oob\": seq_rf.oob_score_,\n",
    "                      },\n",
    "}\n",
    "\n",
    "scoring_methods = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"pwa\": probability_weighted_accuracy,\n",
    "            \"neg_log_loss\": log_loss,\n",
    "            \"precision\": precision_score,\n",
    "            \"recall\": recall_score,\n",
    "            \"f1\": f1_score,\n",
    "        }\n",
    "\n",
    "all_scores_oos = pd.DataFrame()\n",
    "\n",
    "for clf in ensembles.keys():\n",
    "    for method, scoring in scoring_methods.items():\n",
    "        if scoring in (probability_weighted_accuracy, log_loss):\n",
    "            y_pred = ensembles[clf][\"prob\"]\n",
    "        else:\n",
    "            y_pred = ensembles[clf][\"pred\"]\n",
    "        score = scoring(y_test, y_pred)\n",
    "        if method == \"neg_log_loss\":\n",
    "            score *= -1\n",
    "        all_scores_oos.loc[method, clf] = score\n",
    "    \n",
    "all_scores_oos.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f2756964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Bootstrap done in 0 days 00:13:43\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "standard_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf_avgu",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf_unweighted_avgu",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf_unweighted",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5c9e48ab-a9ed-4e2f-984b-6506df5154d6",
       "rows": [
        [
         "accuracy",
         "0.4855",
         "0.504",
         "0.5013",
         "0.5",
         "0.5069"
        ],
        [
         "pwa",
         "0.4918",
         "0.5024",
         "0.4899",
         "0.4916",
         "0.5045"
        ],
        [
         "neg_log_loss",
         "-0.7232",
         "-0.7016",
         "-0.7036",
         "-0.7033",
         "-0.7012"
        ],
        [
         "precision",
         "0.4888",
         "0.5077",
         "0.5054",
         "0.5038",
         "0.5111"
        ],
        [
         "recall",
         "0.4852",
         "0.4728",
         "0.4315",
         "0.4315",
         "0.4662"
        ],
        [
         "f1",
         "0.487",
         "0.4896",
         "0.4655",
         "0.4649",
         "0.4877"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_rf</th>\n",
       "      <th>sequential_rf</th>\n",
       "      <th>sequential_rf_avgu</th>\n",
       "      <th>sequential_rf_unweighted_avgu</th>\n",
       "      <th>sequential_rf_unweighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.4855</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwa</th>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.5045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.7232</td>\n",
       "      <td>-0.7016</td>\n",
       "      <td>-0.7036</td>\n",
       "      <td>-0.7033</td>\n",
       "      <td>-0.7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>0.5111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.4662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.4870</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.4649</td>\n",
       "      <td>0.4877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              standard_rf  sequential_rf  sequential_rf_avgu  \\\n",
       "accuracy           0.4855         0.5040              0.5013   \n",
       "pwa                0.4918         0.5024              0.4899   \n",
       "neg_log_loss      -0.7232        -0.7016             -0.7036   \n",
       "precision          0.4888         0.5077              0.5054   \n",
       "recall             0.4852         0.4728              0.4315   \n",
       "f1                 0.4870         0.4896              0.4655   \n",
       "\n",
       "              sequential_rf_unweighted_avgu  sequential_rf_unweighted  \n",
       "accuracy                             0.5000                    0.5069  \n",
       "pwa                                  0.4916                    0.5045  \n",
       "neg_log_loss                        -0.7033                   -0.7012  \n",
       "precision                            0.5038                    0.5111  \n",
       "recall                               0.4315                    0.4662  \n",
       "f1                                   0.4649                    0.4877  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "seq_rfa = clone(seq_rf).fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    sample_weight=None,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential Bootstrap done in {time1}\")\n",
    "\n",
    "\n",
    "pred = seq_rfa.predict(X_test)\n",
    "prob = seq_rfa.predict_proba(X_test)\n",
    "\n",
    "for method, scoring in scoring_methods.items():\n",
    "    if scoring in (probability_weighted_accuracy, log_loss):\n",
    "        y_pred = prob\n",
    "    else:\n",
    "        y_pred = pred\n",
    "    score = scoring(y_test, y_pred)\n",
    "    if method == \"neg_log_loss\":\n",
    "        score *= -1\n",
    "    all_scores_oos.loc[method, \"sequential_rf_unweighted\"] = score\n",
    "\n",
    "all_scores_oos.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042bf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498b33d",
   "metadata": {},
   "source": [
    "##### Sequential Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb415eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_w_leaf = 0.05\n",
    "max_depth = 6\n",
    "min_samples_split = 20\n",
    "min_samples_leaf = 10\n",
    "n_estimators = 100\n",
    "# random_state = 7\n",
    "idx = y_train.index.intersection(cont_train.index)\n",
    "w_train = cont_train.loc[idx, \"w\"] # Return-attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b182072",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced_subsample',\n",
    "    n_estimators=n_estimators,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,  # Use all available cores\n",
    "    random_state=random_state,\n",
    "    )\n",
    "base_tree = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    # class_weight='balanced',\n",
    "    \n",
    "    # Pre-pruning parameters\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    # min_samples_split=min_samples_split,\n",
    "    # min_samples_leaf=min_samples_leaf,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "bagged_tree = BaggingClassifier(\n",
    "    estimator=base_tree,\n",
    "    n_estimators=n_estimators,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "\n",
    "base_rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=1,\n",
    "    bootstrap=False,\n",
    "    class_weight='balanced_subsample',\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    )\n",
    "bagged_rf = BaggingClassifier(\n",
    "    estimator=base_rf,\n",
    "    n_estimators=n_estimators,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "\n",
    "adaboost = AdaBoostClassifier(\n",
    "        estimator=base_rf,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=random_state,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6b24fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF OOB Score: 0.4846\n",
      "Bagged Decision Tree OOB Score: 0.4853\n",
      "Bagged RF OOB Score: 0.4842\n",
      "AdaBoost Done\n"
     ]
    }
   ],
   "source": [
    "rf = rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"RF OOB Score: {rf.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "bagged_tree = bagged_tree.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"Bagged Decision Tree OOB Score: {bagged_tree.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "bagged_rf = bagged_rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"Bagged RF OOB Score: {bagged_rf.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "adaboost.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"AdaBoost Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fb2b927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging 100 estimators...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBagging \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_rf\u001b[38;5;241m.\u001b[39mn_estimators\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m time0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 27\u001b[0m \u001b[43mseq_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# sample_weight=w_train.values,\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m time1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(seconds\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m time0)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1s\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential Bootstrap OOB Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_rf\u001b[38;5;241m.\u001b[39moob_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Done in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\joen\\documents\\github\\machine-learning-blueprint\\afml\\ensemble\\sb_bagging.py:324\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    Build a Sequentially Bootstrapped Bagging ensemble of estimators from the training\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    set (X, y).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;124;03m    self : (object)\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\joen\\documents\\github\\machine-learning-blueprint\\afml\\ensemble\\sb_bagging.py:571\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaggingClassifier._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# Call parent _fit method\u001b[39;00m\n\u001b[1;32m--> 571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\joen\\documents\\github\\machine-learning-blueprint\\afml\\ensemble\\sb_bagging.py:434\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds, seeds])\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Build estimators in parallel\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_indices_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Unpack results\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_tree = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    # class_weight='balanced',\n",
    "    \n",
    "    # Pre-pruning parameters\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    # min_samples_split=min_samples_split,\n",
    "    # min_samples_leaf=min_samples_leaf,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "\n",
    "seq_rf = SequentiallyBootstrappedBaggingClassifier(\n",
    "    samples_info_sets=cont_train.t1,\n",
    "    price_bars_index=bb_df.index,\n",
    "    estimator=base_tree,\n",
    "    n_estimators=100,\n",
    "    max_features=1,\n",
    "    # max_samples=1,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    verbose=False,\n",
    ")\n",
    "print(f\"Bagging {seq_rf.n_estimators:,} estimators...\")\n",
    "time0 = time.time()\n",
    "seq_rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    # sample_weight=w_train.values,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential Bootstrap OOB Score: {seq_rf.oob_score_:.4f} | Done in {time1}\")\n",
    "print(f\"{seq_rf.__class__.__name__} {estimate_ensemble_size_(seq_rf):,.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "33536196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'coverage': 1.0, 'auc': 0.5}\n"
     ]
    }
   ],
   "source": [
    "seq_oob = compute_custom_oob_metrics(seq_rf, X_train.values, y_train.values, sample_weight=cont_train['w'])\n",
    "pprint(seq_oob, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5336bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "adaboost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "standard_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_tree",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9157b3b2-13d9-4036-ba83-e5baf76e3b4b",
       "rows": [
        [
         "accuracy",
         "0.4805",
         "0.4868",
         "0.4835",
         "0.4845",
         "0.5033"
        ],
        [
         "pwa",
         "0.4843",
         "0.4917",
         "0.4919",
         "0.4899",
         "0.5033"
        ],
        [
         "neg_log_loss",
         "-0.6993",
         "-0.7239",
         "-0.724",
         "-0.7252",
         "-17.9029"
        ],
        [
         "precision",
         "0.4835",
         "0.4902",
         "0.487",
         "0.488",
         "0.5033"
        ],
        [
         "recall",
         "0.4702",
         "0.4918",
         "0.4911",
         "0.4925",
         "1.0"
        ],
        [
         "f1",
         "0.4767",
         "0.491",
         "0.4891",
         "0.4902",
         "0.6696"
        ],
        [
         "oob",
         null,
         "0.4846",
         "0.4842",
         "0.4853",
         "0.0"
        ],
        [
         "oob_test_gap",
         null,
         "-0.0022",
         "0.0007",
         "0.0008",
         "-0.5033"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adaboost</th>\n",
       "      <th>standard_rf</th>\n",
       "      <th>bagged_rf</th>\n",
       "      <th>bagged_tree</th>\n",
       "      <th>sequential_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.4805</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwa</th>\n",
       "      <td>0.4843</td>\n",
       "      <td>0.4917</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.6993</td>\n",
       "      <td>-0.7239</td>\n",
       "      <td>-0.7240</td>\n",
       "      <td>-0.7252</td>\n",
       "      <td>-17.9029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.4702</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.4911</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.4842</td>\n",
       "      <td>0.4853</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob_test_gap</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.5033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              adaboost  standard_rf  bagged_rf  bagged_tree  sequential_rf\n",
       "accuracy        0.4805       0.4868     0.4835       0.4845         0.5033\n",
       "pwa             0.4843       0.4917     0.4919       0.4899         0.5033\n",
       "neg_log_loss   -0.6993      -0.7239    -0.7240      -0.7252       -17.9029\n",
       "precision       0.4835       0.4902     0.4870       0.4880         0.5033\n",
       "recall          0.4702       0.4918     0.4911       0.4925         1.0000\n",
       "f1              0.4767       0.4910     0.4891       0.4902         0.6696\n",
       "oob                NaN       0.4846     0.4842       0.4853         0.0000\n",
       "oob_test_gap       NaN      -0.0022     0.0007       0.0008        -0.5033"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembles = {\n",
    "    \"adaboost\": {\"classifier\": adaboost, \n",
    "                 \"pred\": adaboost.predict(X_test),\n",
    "                 \"prob\": adaboost.predict_proba(X_test),\n",
    "                },\n",
    "    \"standard_rf\": {\"classifier\": rf, \n",
    "                 \"pred\": rf.predict(X_test),\n",
    "                 \"prob\": rf.predict_proba(X_test),\n",
    "                 \"oob\": rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_rf\": {\"classifier\": bagged_rf, \n",
    "                 \"pred\": bagged_rf.predict(X_test),\n",
    "                 \"prob\": bagged_rf.predict_proba(X_test),\n",
    "                 \"oob\": bagged_rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_tree\": {\"classifier\": bagged_tree, \n",
    "                 \"pred\": bagged_tree.predict(X_test),\n",
    "                 \"prob\": bagged_tree.predict_proba(X_test),\n",
    "                 \"oob\": bagged_tree.oob_score_,\n",
    "                },\n",
    "    \"sequential_rf\": {\"classifier\": seq_rf, \n",
    "                   \"pred\": seq_rf.predict(X_test),\n",
    "                   \"prob\": seq_rf.predict_proba(X_test),\n",
    "                   \"oob\": seq_rf.oob_score_,\n",
    "                   },\n",
    "}\n",
    "\n",
    "scoring_methods = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"pwa\": probability_weighted_accuracy,\n",
    "            \"neg_log_loss\": log_loss,\n",
    "            \"precision\": precision_score,\n",
    "            \"recall\": recall_score,\n",
    "            \"f1\": f1_score,\n",
    "        }\n",
    "\n",
    "all_scores_oos = pd.DataFrame()\n",
    "\n",
    "for clf in ensembles.keys():\n",
    "    for method, scoring in scoring_methods.items():\n",
    "        if scoring in (probability_weighted_accuracy, log_loss):\n",
    "            y_pred = ensembles[clf][\"prob\"]\n",
    "        else:\n",
    "            y_pred = ensembles[clf][\"pred\"]\n",
    "        score = scoring(y_test, y_pred)\n",
    "        if method == \"neg_log_loss\":\n",
    "            score *= -1\n",
    "        all_scores_oos.loc[method, clf] = score\n",
    "    oob_score = ensembles[clf].get(\"oob\", np.nan)\n",
    "    all_scores_oos.loc[\"oob\", clf] = oob_score\n",
    "    all_scores_oos.loc[\"oob_test_gap\", clf] = oob_score - all_scores_oos.loc[\"accuracy\", clf]\n",
    "\n",
    "winsound.Beep(1000,1000)\n",
    "all_scores_oos.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fac119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "adaboost",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "standard_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_tree",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "21a320c7-891f-45fa-aaea-40e906edbf69",
       "rows": [
        [
         "accuracy",
         "0.4733",
         "0.4858",
         "0.4842",
         "0.4848",
         "0.4848"
        ],
        [
         "pwa",
         "0.4701",
         "0.4924",
         "0.4915",
         "0.4943",
         "0.4918"
        ],
        [
         "neg_log_loss",
         "-0.7173",
         "-0.7266",
         "-0.7264",
         "-0.7498",
         "-0.7343"
        ],
        [
         "precision",
         "0.4777",
         "0.4893",
         "0.4876",
         "0.4881",
         "0.4881"
        ],
        [
         "recall",
         "0.4984",
         "0.4944",
         "0.4885",
         "0.4852",
         "0.4852"
        ],
        [
         "f1",
         "0.4878",
         "0.4918",
         "0.488",
         "0.4867",
         "0.4867"
        ],
        [
         "oob",
         null,
         "0.4844",
         "0.485",
         "0.4846",
         "0.2282"
        ],
        [
         "oob_test_gap",
         null,
         "-0.0014",
         "0.0009",
         "-0.0002",
         "-0.2566"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adaboost</th>\n",
       "      <th>standard_rf</th>\n",
       "      <th>bagged_rf</th>\n",
       "      <th>bagged_tree</th>\n",
       "      <th>sequential_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.4858</td>\n",
       "      <td>0.4842</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.4848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwa</th>\n",
       "      <td>0.4701</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.4915</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.4918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.7173</td>\n",
       "      <td>-0.7266</td>\n",
       "      <td>-0.7264</td>\n",
       "      <td>-0.7498</td>\n",
       "      <td>-0.7343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.4777</td>\n",
       "      <td>0.4893</td>\n",
       "      <td>0.4876</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>0.4881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.4984</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.4852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.4867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4844</td>\n",
       "      <td>0.4850</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.2282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob_test_gap</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.2566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              adaboost  standard_rf  bagged_rf  bagged_tree  sequential_rf\n",
       "accuracy        0.4733       0.4858     0.4842       0.4848         0.4848\n",
       "pwa             0.4701       0.4924     0.4915       0.4943         0.4918\n",
       "neg_log_loss   -0.7173      -0.7266    -0.7264      -0.7498        -0.7343\n",
       "precision       0.4777       0.4893     0.4876       0.4881         0.4881\n",
       "recall          0.4984       0.4944     0.4885       0.4852         0.4852\n",
       "f1              0.4878       0.4918     0.4880       0.4867         0.4867\n",
       "oob                NaN       0.4844     0.4850       0.4846         0.2282\n",
       "oob_test_gap       NaN      -0.0014     0.0009      -0.0002        -0.2566"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensembles = {\n",
    "    \"adaboost\": {\"classifier\": adaboost, \n",
    "                 \"pred\": adaboost.predict(X_test),\n",
    "                 \"prob\": adaboost.predict_proba(X_test),\n",
    "                },\n",
    "    \"standard_rf\": {\"classifier\": rf, \n",
    "                 \"pred\": rf.predict(X_test),\n",
    "                 \"prob\": rf.predict_proba(X_test),\n",
    "                 \"oob\": rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_rf\": {\"classifier\": bagged_rf, \n",
    "                 \"pred\": bagged_rf.predict(X_test),\n",
    "                 \"prob\": bagged_rf.predict_proba(X_test),\n",
    "                 \"oob\": bagged_rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_tree\": {\"classifier\": bagged_tree, \n",
    "                 \"pred\": bagged_tree.predict(X_test),\n",
    "                 \"prob\": bagged_tree.predict_proba(X_test),\n",
    "                 \"oob\": bagged_tree.oob_score_,\n",
    "                },\n",
    "    \"sequential_rf\": {\"classifier\": seq_rf, \n",
    "                   \"pred\": seq_rf.predict(X_test),\n",
    "                   \"prob\": seq_rf.predict_proba(X_test),\n",
    "                   \"oob\": seq_rf.oob_score_,\n",
    "                   },\n",
    "}\n",
    "\n",
    "scoring_methods = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"pwa\": probability_weighted_accuracy,\n",
    "            \"neg_log_loss\": log_loss,\n",
    "            \"precision\": precision_score,\n",
    "            \"recall\": recall_score,\n",
    "            \"f1\": f1_score,\n",
    "        }\n",
    "\n",
    "all_scores_oos = pd.DataFrame()\n",
    "\n",
    "for clf in ensembles.keys():\n",
    "    for method, scoring in scoring_methods.items():\n",
    "        if scoring in (probability_weighted_accuracy, log_loss):\n",
    "            y_pred = ensembles[clf][\"prob\"]\n",
    "        else:\n",
    "            y_pred = ensembles[clf][\"pred\"]\n",
    "        score = scoring(y_test, y_pred)\n",
    "        if method == \"neg_log_loss\":\n",
    "            score *= -1\n",
    "        all_scores_oos.loc[method, clf] = score\n",
    "    oob_score = ensembles[clf].get(\"oob\", np.nan)\n",
    "    all_scores_oos.loc[\"oob\", clf] = oob_score\n",
    "    all_scores_oos.loc[\"oob_test_gap\", clf] = oob_score - all_scores_oos.loc[\"accuracy\", clf]\n",
    "\n",
    "all_scores_oos.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67c2bd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentiallyBootstrappedBaggingClassifier(estimator=DecisionTreeClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                                           max_depth=6,\n",
       "                                                                           min_weight_fraction_leaf=0.05),\n",
       "                                          max_samples=0.5, n_estimators=100,\n",
       "                                          n_jobs=3, oob_score=True,\n",
       "                                          price_bars_index=DatetimeIndex([&#x27;2018-01-01 23:05:00&#x27;, &#x27;2018-01-01 23:10:00&#x27;,\n",
       "               &#x27;2018-01-01 23:15:00&#x27;, &#x27;2018-01-01 23:20:00&#x27;,\n",
       "               &#x27;2018-01-01 23:25:00&#x27;, &#x27;2018-01-01 23:30:0...\n",
       "2018-01-03 01:30:00   2018-01-03 01:50:00\n",
       "2018-01-03 02:40:00   2018-01-03 04:00:00\n",
       "2018-01-03 05:35:00   2018-01-03 08:10:00\n",
       "2018-01-03 06:45:00   2018-01-03 07:55:00\n",
       "                              ...        \n",
       "2022-02-28 00:05:00   2022-02-28 11:55:00\n",
       "2022-02-28 12:00:00   2022-02-28 14:25:00\n",
       "2022-02-28 17:30:00   2022-02-28 18:25:00\n",
       "2022-02-28 21:00:00   2022-03-01 02:55:00\n",
       "2022-03-01 10:50:00   2022-03-01 13:45:00\n",
       "Name: t1, Length: 7072, dtype: datetime64[ns],\n",
       "                                          verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SequentiallyBootstrappedBaggingClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SequentiallyBootstrappedBaggingClassifier(estimator=DecisionTreeClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                                           max_depth=6,\n",
       "                                                                           min_weight_fraction_leaf=0.05),\n",
       "                                          max_samples=0.5, n_estimators=100,\n",
       "                                          n_jobs=3, oob_score=True,\n",
       "                                          price_bars_index=DatetimeIndex([&#x27;2018-01-01 23:05:00&#x27;, &#x27;2018-01-01 23:10:00&#x27;,\n",
       "               &#x27;2018-01-01 23:15:00&#x27;, &#x27;2018-01-01 23:20:00&#x27;,\n",
       "               &#x27;2018-01-01 23:25:00&#x27;, &#x27;2018-01-01 23:30:0...\n",
       "2018-01-03 01:30:00   2018-01-03 01:50:00\n",
       "2018-01-03 02:40:00   2018-01-03 04:00:00\n",
       "2018-01-03 05:35:00   2018-01-03 08:10:00\n",
       "2018-01-03 06:45:00   2018-01-03 07:55:00\n",
       "                              ...        \n",
       "2022-02-28 00:05:00   2022-02-28 11:55:00\n",
       "2022-02-28 12:00:00   2022-02-28 14:25:00\n",
       "2022-02-28 17:30:00   2022-02-28 18:25:00\n",
       "2022-02-28 21:00:00   2022-03-01 02:55:00\n",
       "2022-03-01 10:50:00   2022-03-01 13:45:00\n",
       "Name: t1, Length: 7072, dtype: datetime64[ns],\n",
       "                                          verbose=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: DecisionTreeClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=6,\n",
       "                       min_weight_fraction_leaf=0.05)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=6,\n",
       "                       min_weight_fraction_leaf=0.05)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentiallyBootstrappedBaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                                           max_depth=6,\n",
       "                                                                           min_weight_fraction_leaf=0.05),\n",
       "                                          max_samples=0.5, n_estimators=100,\n",
       "                                          n_jobs=3, oob_score=True,\n",
       "                                          price_bars_index=DatetimeIndex(['2018-01-01 23:05:00', '2018-01-01 23:10:00',\n",
       "               '2018-01-01 23:15:00', '2018-01-01 23:20:00',\n",
       "               '2018-01-01 23:25:00', '2018-01-01 23:30:0...\n",
       "2018-01-03 01:30:00   2018-01-03 01:50:00\n",
       "2018-01-03 02:40:00   2018-01-03 04:00:00\n",
       "2018-01-03 05:35:00   2018-01-03 08:10:00\n",
       "2018-01-03 06:45:00   2018-01-03 07:55:00\n",
       "                              ...        \n",
       "2022-02-28 00:05:00   2022-02-28 11:55:00\n",
       "2022-02-28 12:00:00   2022-02-28 14:25:00\n",
       "2022-02-28 17:30:00   2022-02-28 18:25:00\n",
       "2022-02-28 21:00:00   2022-03-01 02:55:00\n",
       "2022-03-01 10:50:00   2022-03-01 13:45:00\n",
       "Name: t1, Length: 7072, dtype: datetime64[ns],\n",
       "                                          verbose=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40738aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_rf done.\n",
      "bagged_rf done.\n",
      "bagged_tree done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[52], line 10\u001b[0m\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clf, SequentiallyBootstrappedBaggingClassifier):\n",
      "\u001b[0;32m      9\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m---> 10\u001b[0m cv_scores, cv_scores_df, cms \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_cross_val_scores\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     15\u001b[0m all_cms\u001b[38;5;241m.\u001b[39mappend(cms)\n",
      "\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m cv_scores_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\cross_validation\\cross_validation.py:488\u001b[0m, in \u001b[0;36manalyze_cross_val_scores\u001b[1;34m(classifier, X, y, cv_gen, sample_weight_train, sample_weight_score)\u001b[0m\n",
      "\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq_bootstrap:\n",
      "\u001b[0;32m    485\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m clone(classifier)\u001b[38;5;241m.\u001b[39mset_params(\n",
      "\u001b[0;32m    486\u001b[0m         samples_info_sets\u001b[38;5;241m=\u001b[39mt1\u001b[38;5;241m.\u001b[39miloc[train]\n",
      "\u001b[0;32m    487\u001b[0m     )  \u001b[38;5;66;03m# Create new instance\u001b[39;00m\n",
      "\u001b[1;32m--> 488\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    493\u001b[0m prob \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict_proba(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n",
      "\u001b[0;32m    494\u001b[0m pred \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:312\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    Build a Sequentially Bootstrapped Bagging ensemble of estimators from the training\u001b[39;00m\n",
      "\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    set (X, y).\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    self : (object)\u001b[39;00m\n",
      "\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:559\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaggingClassifier._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n",
      "\u001b[0;32m    556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Call parent _fit method\u001b[39;00m\n",
      "\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:422\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n",
      "\u001b[0;32m    419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds, seeds])\n",
      "\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# Build estimators in parallel\u001b[39;00m\n",
      "\u001b[1;32m--> 422\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_indices_\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    435\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# Unpack results\u001b[39;00m\n",
      "\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n",
      "\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n",
      "\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n",
      "\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n",
      "\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n",
      "\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n",
      "\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n",
      "\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n",
      "\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n",
      "\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n",
      "\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n",
      "\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n",
      "\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n",
      "\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n",
      "\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n",
      "\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n",
      "\u001b[0;32m   1799\u001b[0m     ):\n",
      "\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n",
      "\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n",
      "\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_cv_scores = pd.DataFrame()\n",
    "all_cv_scores_std = pd.DataFrame(dtype=pd.StringDtype())\n",
    "all_cms = []\n",
    "\n",
    "for name in ensembles.keys():\n",
    "    clf = ensembles[name][\"classifier\"]\n",
    "    w = cont_train['tW'].values\n",
    "    if isinstance(clf, SequentiallyBootstrappedBaggingClassifier):\n",
    "        w = None\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    all_cms.append(cms)\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores.loc[idx, name] = row['mean']\n",
    "        all_cv_scores_std.loc[idx, name] = f\"{row['mean']:.3f} ± {row['std']:.3f}\"\n",
    "    print(name, \"done.\")\n",
    "    \n",
    "# all_cv_scores.round(4)\n",
    "all_cv_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07230ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fold': 1, 'TN': 549.73, 'FP': 494.95, 'FN': 477.13, 'TP': 474.95},\n",
      " {'fold': 2, 'TN': 524.85, 'FP': 460.91, 'FN': 504.02, 'TP': 518.75},\n",
      " {'fold': 3, 'TN': 461.98, 'FP': 596.42, 'FN': 422.17, 'TP': 553.53}]\n"
     ]
    }
   ],
   "source": [
    "pprint(all_cms, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e170c",
   "metadata": {},
   "source": [
    "#### Meta-Labelled- CV of Weighting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9519e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = bb_events_tb_time_meta.copy()\n",
    "X = bb_feat_time.reindex(cont.index)\n",
    "y = cont[\"bin\"]\n",
    "t1 = cont[\"t1\"]\n",
    "\n",
    "test_size = 0.3\n",
    "\n",
    "train, test = PurgedSplit(t1, test_size).split(X)\n",
    "X_train, X_test, y_train, y_test = (\n",
    "        X.iloc[train],\n",
    "        X.iloc[test],\n",
    "        y.iloc[train],\n",
    "        y.iloc[test],\n",
    "    )\n",
    "\n",
    "cont_train = get_event_weights(cont.iloc[train], bb_df.close)\n",
    "bb_cont_train_meta = cont_train.copy()\n",
    "\n",
    "n_splits = 5\n",
    "pct_embargo = 0.01\n",
    "cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['unweighted', 'uniqueness', 'return'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_u = cont_train.tW.mean()\n",
    "weighting_schemes = {\n",
    "    \"unweighted\": pd.Series(1., index=cont_train.index),\n",
    "    \"uniqueness\": cont_train[\"tW\"],\n",
    "    \"return\": cont_train[\"w\"],\n",
    "    }\n",
    "\n",
    "decay_factors = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "time_decay_weights = {}\n",
    "for time_decay in decay_factors:\n",
    "    for linear in (1, 0):\n",
    "        decay_w = get_weights_by_time_decay_optimized(\n",
    "                    triple_barrier_events=cont,\n",
    "                    close_index=close.index,\n",
    "                    last_weight=time_decay,\n",
    "                    linear=linear,\n",
    "                    av_uniqueness=cont_train[\"tW\"],\n",
    "                )\n",
    "        method = \"linear\" if linear else \"exp\"\n",
    "        time_decay_weights[f\"{method}_time_decay_{time_decay}\"] = decay_w\n",
    "        \n",
    "# for k, v in time_decay_weights.items():\n",
    "#     weighting_schemes[k] = v\n",
    "\n",
    "weighting_schemes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b52a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average uniqueness: 0.5473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "min_w_leaf = 0.05\n",
    "max_depth = 6\n",
    "\n",
    "print(f\"Average uniqueness: {avg_u:.4f}\\n\")\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    random_state=random_state,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    n_jobs=N_JOBS,  # Use all available cores\n",
    "    )\n",
    "\n",
    "clf0 = rf\n",
    "clf1 = clone(rf).set_params(class_weight='balanced_subsample')\n",
    "clf2 = clone(rf).set_params(max_samples=avg_u)\n",
    "clf3 = clone(rf).set_params(max_samples=avg_u, class_weight='balanced_subsample')\n",
    "clfs = {k: v for k, v in zip(['standard', 'balanced_subsample', 'max_samples', 'combined'], [clf0, clf1, clf2, clf3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5665489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)\n",
    "# cv_scores_d = {k: {} for k in clfs.keys()}\n",
    "# print(rf.__class__.__name__, \"Weighting Schemes\")\n",
    "# all_clf_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "# best_models = []\n",
    "\n",
    "# for scheme, sample_weights in weighting_schemes.items():\n",
    "#     best_score, best_model = None, None\n",
    "#     for param, clf in clfs.items():\n",
    "#         w = sample_weights.values\n",
    "#         cv_scores = ml_cross_val_score(\n",
    "#             clf, X_train, y_train, cv_gen, \n",
    "#             sample_weight_train=w, \n",
    "#             sample_weight_score=w,\n",
    "#             scoring=\"f1\",\n",
    "#         )\n",
    "#         score = cv_scores.mean()\n",
    "#         cv_scores_d[param][scheme] = score\n",
    "#         best_score = max(best_score, score) if best_score is not None else score\n",
    "#         if score == best_score:\n",
    "#             best_model = param\n",
    "#         all_clf_scores_df.loc[param, scheme] = f\"{cv_scores.mean():.6f} ± {cv_scores.std():.4f}\"\n",
    "#     best_models.append(best_model)\n",
    "#     print(f\"{scheme} {best_model} model achieved the best f1 score of {best_score:.6f}\")\n",
    "\n",
    "# print()\n",
    "# pprint(all_clf_scores_df, sort_dicts=False)\n",
    "# best_model = max(best_models, key=best_models.count)\n",
    "# best_clf = clone(clfs[best_model])\n",
    "# print(f\"\\nSelected Best Classifier ({best_model}): {best_clf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd491f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   unweighted       uniqueness           return\n",
      "accuracy       0.6262 ± 0.022   0.6175 ± 0.024   0.6228 ± 0.022\n",
      "pwa            0.6309 ± 0.027   0.6251 ± 0.031   0.6317 ± 0.019\n",
      "neg_log_loss  -0.6604 ± 0.015  -0.6641 ± 0.016  -0.6611 ± 0.008\n",
      "precision      0.6262 ± 0.022   0.6176 ± 0.024   0.0000 ± 0.000\n",
      "recall         1.0000 ± 0.000   0.9998 ± 0.001   0.0000 ± 0.000\n",
      "f1             0.7699 ± 0.016   0.7632 ± 0.019   0.0000 ± 0.000\n",
      "\n",
      "unweighted model achieved the best f1 score of 0.769903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_cv_scores_d = {}\n",
    "all_cms = {}\n",
    "best_score, best_model = None, None\n",
    "all_cv_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "best_clf = clfs[\"max_samples\"]\n",
    "scoring = 'f1' if set(y_train.unique()) == {0, 1} else 'neg_log_loss'\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    w = sample_weights.values\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        best_clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    score = cv_scores[scoring].mean()\n",
    "    all_cv_scores_d[scheme] = cv_scores\n",
    "    all_cms[scheme] = cms\n",
    "    best_score = max(best_score, score) if best_score is not None else score\n",
    "    if score == best_score:\n",
    "        best_model = scheme\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores_df.loc[idx, scheme] = f\"{row['mean']:.4f} ± {row['std']:.3f}\"\n",
    "pprint(all_cv_scores_df)\n",
    "print(f\"\\n{best_model} model achieved the best {scoring} score of {best_score:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108fd6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unweighted': [{'fold': 1, 'TN': 0.0, 'FP': 313.0, 'FN': 0.0, 'TP': 518.0},\n",
      "                {'fold': 2, 'TN': 0.0, 'FP': 328.0, 'FN': 0.0, 'TP': 503.0},\n",
      "                {'fold': 3, 'TN': 0.0, 'FP': 271.0, 'FN': 0.0, 'TP': 560.0},\n",
      "                {'fold': 4, 'TN': 0.0, 'FP': 300.0, 'FN': 0.0, 'TP': 531.0},\n",
      "                {'fold': 5, 'TN': 0.0, 'FP': 304.0, 'FN': 0.0, 'TP': 527.0},\n",
      "                {'fold': 6, 'TN': 0.0, 'FP': 327.0, 'FN': 0.0, 'TP': 504.0},\n",
      "                {'fold': 7, 'TN': 0.0, 'FP': 335.0, 'FN': 0.0, 'TP': 495.0},\n",
      "                {'fold': 8, 'TN': 0.0, 'FP': 306.0, 'FN': 0.0, 'TP': 524.0},\n",
      "                {'fold': 9, 'TN': 0.0, 'FP': 299.0, 'FN': 0.0, 'TP': 531.0},\n",
      "                {'fold': 10, 'TN': 0.0, 'FP': 322.0, 'FN': 0.0, 'TP': 508.0}],\n",
      " 'uniqueness': [{'fold': 1, 'TN': 0.0, 'FP': 179.9, 'FN': 0.0, 'TP': 295.4},\n",
      "                {'fold': 2, 'TN': 0.0, 'FP': 181.38, 'FN': 0.0, 'TP': 260.87},\n",
      "                {'fold': 3, 'TN': 0.0, 'FP': 148.29, 'FN': 0.0, 'TP': 296.99},\n",
      "                {'fold': 4, 'TN': 0.0, 'FP': 170.65, 'FN': 0.0, 'TP': 292.36},\n",
      "                {'fold': 5, 'TN': 0.0, 'FP': 164.7, 'FN': 0.0, 'TP': 282.74},\n",
      "                {'fold': 6, 'TN': 0.0, 'FP': 181.01, 'FN': 0.5, 'TP': 263.38},\n",
      "                {'fold': 7, 'TN': 0.0, 'FP': 190.87, 'FN': 0.0, 'TP': 265.45},\n",
      "                {'fold': 8, 'TN': 0.0, 'FP': 168.99, 'FN': 0.0, 'TP': 285.09},\n",
      "                {'fold': 9, 'TN': 0.0, 'FP': 169.56, 'FN': 0.0, 'TP': 284.92},\n",
      "                {'fold': 10, 'TN': 0.0, 'FP': 182.96, 'FN': 0.0, 'TP': 280.07}],\n",
      " 'return': [{'fold': 1, 'TN': 585.06, 'FP': 0.0, 'FN': 376.61, 'TP': 0.0},\n",
      "            {'fold': 2, 'TN': 558.98, 'FP': 0.0, 'FN': 304.2, 'TP': 0.0},\n",
      "            {'fold': 3, 'TN': 341.24, 'FP': 0.0, 'FN': 234.33, 'TP': 0.0},\n",
      "            {'fold': 4, 'TN': 381.34, 'FP': 0.0, 'FN': 211.98, 'TP': 0.0},\n",
      "            {'fold': 5, 'TN': 502.06, 'FP': 0.0, 'FN': 328.28, 'TP': 0.0},\n",
      "            {'fold': 6, 'TN': 571.72, 'FP': 0.0, 'FN': 329.69, 'TP': 0.0},\n",
      "            {'fold': 7, 'TN': 505.12, 'FP': 0.0, 'FN': 264.63, 'TP': 0.0},\n",
      "            {'fold': 8, 'TN': 353.08, 'FP': 0.0, 'FN': 234.24, 'TP': 0.0},\n",
      "            {'fold': 9, 'TN': 535.19, 'FP': 0.0, 'FN': 352.73, 'TP': 0.0},\n",
      "            {'fold': 10, 'TN': 851.14, 'FP': 0.0, 'FN': 484.4, 'TP': 0.0}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(all_cms, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5b1bc",
   "metadata": {},
   "source": [
    "##### Sequential Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379210a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from afml.cross_validation.scoring import probability_weighted_accuracy\n",
    "from afml.ensemble.sb_bagging import (\n",
    "    SequentiallyBootstrappedBaggingClassifier,\n",
    "    compute_custom_oob_metrics,\n",
    ")\n",
    "\n",
    "min_w_leaf = 0.05\n",
    "max_depth = 6\n",
    "min_samples_split = 20\n",
    "min_samples_leaf = 10\n",
    "n_estimators = 100\n",
    "random_state = 7\n",
    "\n",
    "# More straightforward and gives you better control\n",
    "base_tree = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced',\n",
    "    \n",
    "    # Pre-pruning parameters\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    # min_samples_split=min_samples_split,\n",
    "    # min_samples_leaf=min_samples_leaf,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "base_rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=1,\n",
    "    bootstrap=False,\n",
    "    class_weight='balanced_subsample',\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    )\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced_subsample',\n",
    "    n_estimators=n_estimators,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    max_depth=max_depth,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,  # Use all available cores\n",
    "    random_state=random_state,\n",
    "    )\n",
    "bagged_rf = BaggingClassifier(\n",
    "    estimator=base_rf,\n",
    "    n_estimators=n_estimators,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "bagged_tree = BaggingClassifier(\n",
    "    estimator=base_tree,\n",
    "    n_estimators=n_estimators,\n",
    "    max_samples=avg_u,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    )\n",
    "adaboost = AdaBoostClassifier(\n",
    "        estimator=base_rf,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "seq_rf = SequentiallyBootstrappedBaggingClassifier(\n",
    "    samples_info_sets=cont_train.t1,\n",
    "    price_bars_index=bb_df.index,\n",
    "    estimator=base_rf,\n",
    "    n_estimators=n_estimators,\n",
    "    max_features=1,\n",
    "    bootstrap_features=False,\n",
    "    oob_score=True,\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=random_state,\n",
    "    verbose=False,\n",
    ")\n",
    "seq_rf_bf = clone(seq_rf).set_params(bootstrap_features=True) # bootstrap_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fec154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Decision Tree OOB Score: 0.5031\n",
      "RF OOB Score: 0.5059\n",
      "Bagged RF OOB Score: 0.5051\n",
      "Sequential Bootstrap OOB Score: 0.2432\n",
      "\n",
      "Sequential Bootstrap Training done in 0 days 00:08:31\n"
     ]
    }
   ],
   "source": [
    "idx = y_train.index.intersection(cont_train.index)\n",
    "w_train = cont_train.loc[idx, \"tW\"] # Average Uniqueness\n",
    "rw_train = cont_train.loc[idx, \"w\"] # Return-attribution\n",
    "\n",
    "rf = rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"RF OOB Score: {rf.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "bagged_tree = bagged_tree.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"Bagged Decision Tree OOB Score: {bagged_tree.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "bagged_rf = bagged_rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=w_train.values,\n",
    ")\n",
    "print(f\"Bagged RF OOB Score: {bagged_rf.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "adaboost.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=rw_train.values,\n",
    ")\n",
    "print(f\"AdaBoost Done\")\n",
    "\n",
    "\n",
    "time0 = time.time()\n",
    "seq_rf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=rw_train.values,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential RF OOB Score: {seq_rf.oob_score_:.4f}\")\n",
    "print(f\"\\nSequential RF Training done in {time1}\")\n",
    "\n",
    "\n",
    "time0 = time.time()\n",
    "seq_rf_bf.fit(\n",
    "    X_train.loc[idx],\n",
    "    y_train.loc[idx],\n",
    "    sample_weight=rw_train.values,\n",
    ")\n",
    "time1 = pd.Timedelta(seconds=time.time() - time0).round('1s')\n",
    "print(f\"Sequential Bootstrapped Features OOB Score: {seq_rf_bf.oob_score_:.4f}\")\n",
    "print(f\"\\nSequential Bootstrapped Features Training done in {time1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150fae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "standard_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_rf",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bagged_tree",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sequential_rf",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f4d994c4-3425-4a4a-86d4-7555044c7af7",
       "rows": [
        [
         "accuracy",
         "0.5162",
         "0.5142",
         "0.5149",
         "0.4974"
        ],
        [
         "pwa",
         "0.5221",
         "0.5241",
         "0.5209",
         "0.5064"
        ],
        [
         "neg_log_loss",
         "-0.6925",
         "-0.6924",
         "-0.6926",
         "-0.6931"
        ],
        [
         "precision",
         "0.5179",
         "0.5156",
         "0.515",
         "0.5007"
        ],
        [
         "recall",
         "0.5593",
         "0.5738",
         "0.619",
         "0.4925"
        ],
        [
         "f1",
         "0.5378",
         "0.5431",
         "0.5622",
         "0.4965"
        ],
        [
         "oob",
         "0.5059",
         "0.5051",
         "0.5031",
         "0.2432"
        ],
        [
         "oob_test_gap",
         "-0.0102",
         "-0.0091",
         "-0.0117",
         "-0.2541"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_rf</th>\n",
       "      <th>bagged_rf</th>\n",
       "      <th>bagged_tree</th>\n",
       "      <th>sequential_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.5149</td>\n",
       "      <td>0.4974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwa</th>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_log_loss</th>\n",
       "      <td>-0.6925</td>\n",
       "      <td>-0.6924</td>\n",
       "      <td>-0.6926</td>\n",
       "      <td>-0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.5007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.5593</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.5378</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.4965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob</th>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.5051</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.2432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oob_test_gap</th>\n",
       "      <td>-0.0102</td>\n",
       "      <td>-0.0091</td>\n",
       "      <td>-0.0117</td>\n",
       "      <td>-0.2541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              standard_rf  bagged_rf  bagged_tree  sequential_rf\n",
       "accuracy           0.5162     0.5142       0.5149         0.4974\n",
       "pwa                0.5221     0.5241       0.5209         0.5064\n",
       "neg_log_loss      -0.6925    -0.6924      -0.6926        -0.6931\n",
       "precision          0.5179     0.5156       0.5150         0.5007\n",
       "recall             0.5593     0.5738       0.6190         0.4925\n",
       "f1                 0.5378     0.5431       0.5622         0.4965\n",
       "oob                0.5059     0.5051       0.5031         0.2432\n",
       "oob_test_gap      -0.0102    -0.0091      -0.0117        -0.2541"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembles = {\n",
    "    \"adaboost\": {\"classifier\": adaboost, \n",
    "                 \"pred\": adaboost.predict(X_test),\n",
    "                 \"prob\": adaboost.predict_proba(X_test),\n",
    "                 \"oob\": np.nan,\n",
    "                },\n",
    "    \"standard_rf\": {\"classifier\": rf, \n",
    "                 \"pred\": rf.predict(X_test),\n",
    "                 \"prob\": rf.predict_proba(X_test),\n",
    "                 \"oob\": rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_rf\": {\"classifier\": bagged_rf, \n",
    "                 \"pred\": bagged_rf.predict(X_test),\n",
    "                 \"prob\": bagged_rf.predict_proba(X_test),\n",
    "                 \"oob\": bagged_rf.oob_score_,\n",
    "                },\n",
    "    \"bagged_tree\": {\"classifier\": bagged_tree, \n",
    "                 \"pred\": bagged_tree.predict(X_test),\n",
    "                 \"prob\": bagged_tree.predict_proba(X_test),\n",
    "                 \"oob\": bagged_tree.oob_score_,\n",
    "                },\n",
    "    \"sequential_rf\": {\"classifier\": seq_rf, \n",
    "                   \"pred\": seq_rf.predict(X_test),\n",
    "                   \"prob\": seq_rf.predict_proba(X_test),\n",
    "                   \"oob\": seq_rf.oob_score_,\n",
    "                   },\n",
    "    \"sequential_rf_bf\": {\"classifier\": seq_rf_bf, \n",
    "                   \"pred\": seq_rf_bf.predict(X_test),\n",
    "                   \"prob\": seq_rf_bf.predict_proba(X_test),\n",
    "                   \"oob\": seq_rf_bf.oob_score_,\n",
    "                   },                 \n",
    "}\n",
    "\n",
    "scoring_methods = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"pwa\": probability_weighted_accuracy,\n",
    "            \"neg_log_loss\": log_loss,\n",
    "            \"precision\": precision_score,\n",
    "            \"recall\": recall_score,\n",
    "            \"f1\": f1_score,\n",
    "        }\n",
    "\n",
    "all_scores_oos = pd.DataFrame()\n",
    "\n",
    "for clf in ensembles.keys():\n",
    "    for method, scoring in scoring_methods.items():\n",
    "        if scoring in (probability_weighted_accuracy, log_loss):\n",
    "            y_pred = ensembles[clf][\"prob\"]\n",
    "        else:\n",
    "            y_pred = ensembles[clf][\"pred\"]\n",
    "        score = scoring(y_test, y_pred)\n",
    "        if method == \"neg_log_loss\":\n",
    "            score *= -1\n",
    "        all_scores_oos.loc[method, clf] = score\n",
    "    all_scores_oos.loc[\"oob\", clf] = ensembles[clf][\"oob\"]\n",
    "    all_scores_oos.loc[\"oob_test_gap\", clf] = ensembles[clf][\"oob\"] - all_scores_oos.loc[\"accuracy\", clf]\n",
    "\n",
    "all_scores_oos.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d42ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_rf done.\n",
      "bagged_rf done.\n",
      "bagged_tree done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clf, SequentiallyBootstrappedBaggingClassifier):\n\u001b[0;32m      9\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m cv_scores, cv_scores_df, cms \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_cross_val_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m all_cms\u001b[38;5;241m.\u001b[39mappend(cms)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m cv_scores_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\cross_validation\\cross_validation.py:488\u001b[0m, in \u001b[0;36manalyze_cross_val_scores\u001b[1;34m(classifier, X, y, cv_gen, sample_weight_train, sample_weight_score)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq_bootstrap:\n\u001b[0;32m    485\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m clone(classifier)\u001b[38;5;241m.\u001b[39mset_params(\n\u001b[0;32m    486\u001b[0m         samples_info_sets\u001b[38;5;241m=\u001b[39mt1\u001b[38;5;241m.\u001b[39miloc[train]\n\u001b[0;32m    487\u001b[0m     )  \u001b[38;5;66;03m# Create new instance\u001b[39;00m\n\u001b[1;32m--> 488\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m prob \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict_proba(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n\u001b[0;32m    494\u001b[0m pred \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m.\u001b[39miloc[test, :])\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:312\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    Build a Sequentially Bootstrapped Bagging ensemble of estimators from the training\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    set (X, y).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    self : (object)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:559\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaggingClassifier._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Call parent _fit method\u001b[39;00m\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\Documents\\GitHub\\Machine-Learning-Blueprint\\notebooks\\..\\afml\\ensemble\\sb_bagging.py:422\u001b[0m, in \u001b[0;36mSequentiallyBootstrappedBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds, seeds])\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# Build estimators in parallel\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_indices_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# Unpack results\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JoeN\\miniforge3\\envs\\mlfinlab_env\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_cv_scores = pd.DataFrame()\n",
    "all_cv_scores_std = pd.DataFrame(dtype=pd.StringDtype())\n",
    "all_cms = []\n",
    "\n",
    "for name in ensembles.keys():\n",
    "    clf = ensembles[name][\"classifier\"]\n",
    "    w = cont_train['tW'].values\n",
    "    if isinstance(clf, SequentiallyBootstrappedBaggingClassifier):\n",
    "        w = None\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    all_cms.append(cms)\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores.loc[idx, name] = row['mean']\n",
    "        all_cv_scores_std.loc[idx, name] = f\"{row['mean']:.3f} ± {row['std']:.3f}\"\n",
    "    print(name, \"done.\")\n",
    "    \n",
    "# all_cv_scores.round(4)\n",
    "all_cv_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da5fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fold': 1, 'TN': 549.73, 'FP': 494.95, 'FN': 477.13, 'TP': 474.95},\n",
      " {'fold': 2, 'TN': 524.85, 'FP': 460.91, 'FN': 504.02, 'TP': 518.75},\n",
      " {'fold': 3, 'TN': 461.98, 'FP': 596.42, 'FN': 422.17, 'TP': 553.53}]\n"
     ]
    }
   ],
   "source": [
    "pprint(all_cms, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec20ef",
   "metadata": {},
   "source": [
    "## 3. Moving Average Crossover Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f163b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afml.strategies.ma_crossover_feature_engine import ForexFeatureEngine\n",
    "\n",
    "ma_timeframe = \"M5\"\n",
    "file = Path(r\"..\\data\\EURUSD_M15_time_2018-01-01-2024-12-31.parq\")\n",
    "ma_time_bars = pd.read_parquet(file)\n",
    "\n",
    "fast_window, slow_window = 20, 50\n",
    "ma_strategy = MACrossoverStrategy(fast_window, slow_window)\n",
    "ma_pt_barrier, ma_sl_barrier, ma_time_horizon = (0, 2, dict(days=5))\n",
    "ma_vol_multiplier = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e673d8",
   "metadata": {},
   "source": [
    "### Time-Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c09a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-27 06:58:41.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.filters.filters\u001b[0m:\u001b[36mcusum_filter\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1m12,748 CUSUM-filtered events\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACrossover_20_50 Signals:\n",
      "\n",
      "       count  proportion\n",
      "side                    \n",
      "-1    61,845    0.502062\n",
      " 1    61,287    0.497532\n",
      " 0        50    0.000406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-27 06:58:42.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mafml.strategies.signal_processing\u001b[0m:\u001b[36mget_entries\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mMACrossover_20_50 | 12,744 (10.35%) trade events selected by CUSUM filter (threshold = 0.1252%).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ma_side = ma_strategy.generate_signals(ma_time_bars)\n",
    "ma_df = ma_time_bars.loc[sample_start : sample_end]\n",
    "\n",
    "\n",
    "print(f\"{ma_strategy.get_strategy_name()} Signals:\")\n",
    "value_counts_data(ma_side.reindex(ma_df.index), verbose=True)\n",
    "\n",
    "# Volatility target for barriers\n",
    "vol_lookback = fast_window\n",
    "vol_target = get_daily_vol(ma_df.close, vol_lookback) * ma_vol_multiplier\n",
    "close = ma_df.close\n",
    "\n",
    "thres = vol_target.mean()\n",
    "_, t_events = get_entries(ma_strategy, ma_df, filter_threshold=vol_target.mean())\n",
    "\n",
    "vertical_barriers = add_vertical_barrier(t_events, close, **ma_time_horizon)\n",
    "linear_decay = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f7545",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 106.62 MB to 55.49 MB (48.0% reduction)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 172386 entries, 2018-01-01 23:15:00 to 2024-12-31 00:00:00\n",
      "Data columns (total 94 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   ma_10                           172386 non-null  float32\n",
      " 1   ma_20                           172386 non-null  float32\n",
      " 2   ma_50                           172386 non-null  float32\n",
      " 3   ma_100                          172386 non-null  float32\n",
      " 4   ma_200                          172386 non-null  float32\n",
      " 5   ma_10_20_cross                  172386 non-null  float64\n",
      " 6   ma_20_50_cross                  172386 non-null  float64\n",
      " 7   ma_50_200_cross                 172386 non-null  float64\n",
      " 8   ma_spread_10_20                 172386 non-null  float32\n",
      " 9   ma_spread_20_50                 172386 non-null  float32\n",
      " 10  ma_spread_50_200                172386 non-null  float32\n",
      " 11  ma_20_slope                     172386 non-null  float32\n",
      " 12  ma_50_slope                     172386 non-null  float32\n",
      " 13  price_above_ma_20               172386 non-null  float64\n",
      " 14  price_above_ma_50               172386 non-null  float64\n",
      " 15  ma_ribbon_aligned               172386 non-null  float64\n",
      " 16  atr_14                          172386 non-null  float32\n",
      " 17  atr_21                          172386 non-null  float32\n",
      " 18  atr_regime                      172386 non-null  float32\n",
      " 19  realized_vol_10                 172386 non-null  float32\n",
      " 20  realized_vol_20                 172386 non-null  float32\n",
      " 21  realized_vol_50                 172386 non-null  float32\n",
      " 22  vol_of_vol                      172386 non-null  float32\n",
      " 23  hl_range                        172386 non-null  float32\n",
      " 24  hl_range_ma                     172386 non-null  float32\n",
      " 25  hl_range_regime                 172386 non-null  float32\n",
      " 26  bb_upper                        172386 non-null  float32\n",
      " 27  bb_lower                        172386 non-null  float32\n",
      " 28  bb_percent                      172386 non-null  float64\n",
      " 29  bb_bandwidth                    172386 non-null  float32\n",
      " 30  bb_squeeze                      172386 non-null  float32\n",
      " 31  efficiency_ratio_14             172386 non-null  float32\n",
      " 32  efficiency_ratio_30             172386 non-null  float32\n",
      " 33  adx_14                          172386 non-null  float32\n",
      " 34  dmp_14                          172386 non-null  float32\n",
      " 35  dmn_14                          172386 non-null  float32\n",
      " 36  adx_trend_strength              172386 non-null  float64\n",
      " 37  adx_trend_direction             172386 non-null  float64\n",
      " 38  trend_window                    172386 non-null  float32\n",
      " 39  trend_slope                     172386 non-null  float32\n",
      " 40  trend_t_value                   172386 non-null  float32\n",
      " 41  trend_rsquared                  172386 non-null  float32\n",
      " 42  trend_ret                       172386 non-null  float32\n",
      " 43  roc_10                          172386 non-null  float32\n",
      " 44  roc_20                          172386 non-null  float32\n",
      " 45  momentum_14                     172386 non-null  float32\n",
      " 46  hh_ll_20                        172386 non-null  float32\n",
      " 47  trend_persistence               172386 non-null  float32\n",
      " 48  return_skew_20                  172386 non-null  float32\n",
      " 49  return_kurtosis_20              172386 non-null  float32\n",
      " 50  var_95                          172386 non-null  float32\n",
      " 51  cvar_95                         172386 non-null  float32\n",
      " 52  market_stress                   172386 non-null  float64\n",
      " 53  current_drawdown                172386 non-null  float32\n",
      " 54  days_since_high                 172386 non-null  float64\n",
      " 55  hour_sin_h1                     172386 non-null  float32\n",
      " 56  hour_cos_h1                     172386 non-null  float32\n",
      " 57  hour_sin_h2                     172386 non-null  float32\n",
      " 58  hour_cos_h2                     172386 non-null  float32\n",
      " 59  hour_sin_h3                     172386 non-null  float32\n",
      " 60  hour_cos_h3                     172386 non-null  float32\n",
      " 61  dayofweek_sin                   172386 non-null  float32\n",
      " 62  dayofweek_cos                   172386 non-null  float32\n",
      " 63  dayofyear_sin                   172386 non-null  float32\n",
      " 64  dayofyear_cos                   172386 non-null  float32\n",
      " 65  sydney_session                  172386 non-null  float64\n",
      " 66  tokyo_session                   172386 non-null  float64\n",
      " 67  london_session                  172386 non-null  float64\n",
      " 68  ny_session                      172386 non-null  float64\n",
      " 69  session_overlap                 172386 non-null  float64\n",
      " 70  friday_ny_close                 172386 non-null  float64\n",
      " 71  sunday_open                     172386 non-null  float64\n",
      " 72  month_end                       172386 non-null  float64\n",
      " 73  quarter_end                     172386 non-null  float64\n",
      " 74  sydney_session_vol              172386 non-null  float32\n",
      " 75  tokyo_session_vol               172386 non-null  float32\n",
      " 76  london_session_vol              172386 non-null  float32\n",
      " 77  ny_session_vol                  172386 non-null  float32\n",
      " 78  session_overlap_vol             172386 non-null  float32\n",
      " 79  friday_ny_close_vol             172386 non-null  float32\n",
      " 80  month_end_vol                   172386 non-null  float32\n",
      " 81  quarter_end_vol                 172386 non-null  float32\n",
      " 82  doji                            172386 non-null  float64\n",
      " 83  hammer                          172386 non-null  float64\n",
      " 84  inside_bar                      172386 non-null  float64\n",
      " 85  outside_bar                     172386 non-null  float64\n",
      " 86  near_recent_high                172386 non-null  float64\n",
      " 87  near_recent_low                 172386 non-null  float64\n",
      " 88  fractal_trend_strength          172386 non-null  float32\n",
      " 89  fractal_trend_direction         172386 non-null  float32\n",
      " 90  fractal_ma_ratio                172386 non-null  float32\n",
      " 91  fractal_trend_confirmation      172386 non-null  float64\n",
      " 92  distance_to_fractal_resistance  172386 non-null  float32\n",
      " 93  distance_to_fractal_support     172386 non-null  float32\n",
      "dtypes: float32(67), float64(27)\n",
      "memory usage: 84.9 MB\n"
     ]
    }
   ],
   "source": [
    "ma_feat_engine = ForexFeatureEngine(pair_name=symbol)\n",
    "ma_feat_time = ma_feat_engine.calculate_all_features(ma_time_bars, ma_timeframe, lr_period=(5, 20))\n",
    "ma_feat_time.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1de34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0. ma_10\n",
      "  1. ma_20\n",
      "  2. ma_50\n",
      "  3. ma_100\n",
      "  4. ma_200\n",
      "  5. ma_10_20_cross\n",
      "  6. ma_20_50_cross\n",
      "  7. ma_50_200_cross\n",
      "  8. ma_spread_10_20\n",
      "  9. ma_spread_20_50\n",
      " 10. ma_spread_50_200\n",
      " 11. ma_20_slope\n",
      " 12. ma_50_slope\n",
      " 13. price_above_ma_20\n",
      " 14. price_above_ma_50\n",
      " 15. ma_ribbon_aligned\n",
      " 16. atr_14\n",
      " 17. atr_21\n",
      " 18. atr_regime\n",
      " 19. realized_vol_10\n",
      " 20. realized_vol_20\n",
      " 21. realized_vol_50\n",
      " 22. vol_of_vol\n",
      " 23. hl_range\n",
      " 24. hl_range_ma\n",
      " 25. hl_range_regime\n",
      " 26. bb_upper\n",
      " 27. bb_lower\n",
      " 28. bb_percent\n",
      " 29. bb_bandwidth\n",
      " 30. bb_squeeze\n",
      " 31. efficiency_ratio_14\n",
      " 32. efficiency_ratio_30\n",
      " 33. adx_14\n",
      " 34. dmp_14\n",
      " 35. dmn_14\n",
      " 36. adx_trend_strength\n",
      " 37. adx_trend_direction\n",
      " 38. trend_window\n",
      " 39. trend_slope\n",
      " 40. trend_t_value\n",
      " 41. trend_rsquared\n",
      " 42. trend_ret\n",
      " 43. roc_10\n",
      " 44. roc_20\n",
      " 45. momentum_14\n",
      " 46. hh_ll_20\n",
      " 47. trend_persistence\n",
      " 48. return_skew_20\n",
      " 49. return_kurtosis_20\n",
      " 50. var_95\n",
      " 51. cvar_95\n",
      " 52. market_stress\n",
      " 53. current_drawdown\n",
      " 54. days_since_high\n",
      " 55. hour_sin_h1\n",
      " 56. hour_cos_h1\n",
      " 57. hour_sin_h2\n",
      " 58. hour_cos_h2\n",
      " 59. hour_sin_h3\n",
      " 60. hour_cos_h3\n",
      " 61. dayofweek_sin\n",
      " 62. dayofweek_cos\n",
      " 63. dayofyear_sin\n",
      " 64. dayofyear_cos\n",
      " 65. sydney_session\n",
      " 66. tokyo_session\n",
      " 67. london_session\n",
      " 68. ny_session\n",
      " 69. session_overlap\n",
      " 70. friday_ny_close\n",
      " 71. sunday_open\n",
      " 72. month_end\n",
      " 73. quarter_end\n",
      " 74. sydney_session_vol\n",
      " 75. tokyo_session_vol\n",
      " 76. london_session_vol\n",
      " 77. ny_session_vol\n",
      " 78. session_overlap_vol\n",
      " 79. friday_ny_close_vol\n",
      " 80. month_end_vol\n",
      " 81. quarter_end_vol\n",
      " 82. doji\n",
      " 83. hammer\n",
      " 84. inside_bar\n",
      " 85. outside_bar\n",
      " 86. near_recent_high\n",
      " 87. near_recent_low\n",
      " 88. fractal_trend_strength\n",
      " 89. fractal_trend_direction\n",
      " 90. fractal_ma_ratio\n",
      " 91. fractal_trend_confirmation\n",
      " 92. distance_to_fractal_resistance\n",
      " 93. distance_to_fractal_support\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(ma_feat_time):\n",
    "    print(f\"{i:>3}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863eb59",
   "metadata": {},
   "source": [
    "#### Triple-Barrier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77596f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 12716 entries, 2018-01-03 02:45:00 to 2022-12-30 12:30:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   t1      12716 non-null  datetime64[ns]\n",
      " 1   trgt    12716 non-null  float64       \n",
      " 2   ret     12716 non-null  float64       \n",
      " 3   bin     12716 non-null  int8          \n",
      " 4   side    12716 non-null  int8          \n",
      "dtypes: datetime64[ns](1), float64(2), int8(2)\n",
      "memory usage: 422.2 KB\n",
      "Triple-Barrier (pt=0, sl=2, h={'days': 5}):\n",
      "\n",
      "     count  proportion\n",
      "bin                   \n",
      "0    9,109    0.716342\n",
      "1    3,607    0.283658\n",
      "\n",
      "Average Uniqueness: 0.0668\n"
     ]
    }
   ],
   "source": [
    "ma_events_tb = triple_barrier_labels(\n",
    "    close=close,\n",
    "    target=vol_target,\n",
    "    t_events=t_events,\n",
    "    pt_sl=[ma_pt_barrier, ma_sl_barrier],\n",
    "    min_ret=min_ret,\n",
    "    vertical_barrier_times=vertical_barriers,\n",
    "    side_prediction=ma_side,\n",
    "    vertical_barrier_zero=False,\n",
    "    verbose=False,\n",
    ")\n",
    "ma_events_tb_time = ma_events_tb.copy()\n",
    "ma_events_tb.info()\n",
    "\n",
    "print(f\"Triple-Barrier (pt={ma_pt_barrier}, sl={ma_sl_barrier}, h={ma_time_horizon}):\")\n",
    "value_counts_data(ma_events_tb.bin, verbose=True)\n",
    "\n",
    "weights = get_event_weights(ma_events_tb, close)\n",
    "av_uniqueness = weights['tW'].mean()\n",
    "print(f\"Average Uniqueness: {av_uniqueness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c240c6f",
   "metadata": {},
   "source": [
    "#### Cross-Validation of Weighting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72404d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = ma_events_tb_time.copy()\n",
    "X = ma_feat_time.reindex(cont.index)\n",
    "y = cont[\"bin\"]\n",
    "t1 = cont[\"t1\"]\n",
    "\n",
    "test_size = 0.2\n",
    "n_splits = 10\n",
    "pct_embargo = 0.01\n",
    "\n",
    "train, test = PurgedSplit(t1, test_size).split(X)\n",
    "X_train, X_test, y_train, y_test = (\n",
    "        X.iloc[train],\n",
    "        X.iloc[test],\n",
    "        y.iloc[train],\n",
    "        y.iloc[test],\n",
    "    )\n",
    "cont_train = get_event_weights(cont.iloc[train], ma_df.close)\n",
    "avg_u = cont_train.tW.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edaa4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['unweighted', 'uniqueness', 'return'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decay_factors = [0.0, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "time_decay_weights = {}\n",
    "for time_decay in decay_factors:\n",
    "    for linear in (1, 0):\n",
    "        decay_w = get_weights_by_time_decay_optimized(\n",
    "                    triple_barrier_events=cont,\n",
    "                    close_index=close.index,\n",
    "                    last_weight=time_decay,\n",
    "                    linear=linear,\n",
    "                    av_uniqueness=cont_train[\"tW\"],\n",
    "                )\n",
    "        method = \"linear\" if linear else \"exp\"\n",
    "        time_decay_weights[f\"{method}_time_decay_{time_decay}\"] = decay_w\n",
    "        \n",
    "weighting_schemes = {\n",
    "    \"unweighted\": pd.Series(1., index=cont_train.index),\n",
    "    \"uniqueness\": cont_train[\"tW\"],\n",
    "    \"return\": cont_train[\"w\"],\n",
    "    }\n",
    "\n",
    "# for k, v in time_decay_weights.items():\n",
    "#     weighting_schemes[k] = v\n",
    "\n",
    "weighting_schemes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd0230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average uniqueness: 0.0735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "min_w_leaf = 0.05\n",
    "print(f\"Average uniqueness: {avg_u:.4f}\\n\")\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=100,\n",
    "    random_state=random_state,\n",
    "    min_weight_fraction_leaf=min_w_leaf,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    )\n",
    "\n",
    "clf0 = rf\n",
    "clf1 = clone(rf).set_params(class_weight='balanced_subsample')\n",
    "clf2 = clone(rf).set_params(max_samples=avg_u)\n",
    "clf3 = clone(rf).set_params(max_samples=avg_u, class_weight='balanced_subsample')\n",
    "clfs = {k: v for k, v in zip(['standard', 'balanced_subsample', 'max_samples', 'combined'], [clf0, clf1, clf2, clf3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a9faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cont_train[\"tW\"].hist(bins=100, grid=False)\n",
    "plt.title(f\"Average Uniqueness - MA_{fast_window}_{slow_window} Crossover Strategy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d38785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Weighting Schemes\n",
      "unweighted balanced_subsample model achieved the best f1 score of 0.405778\n",
      "uniqueness balanced_subsample model achieved the best f1 score of 0.326313\n",
      "return combined model achieved the best f1 score of 0.674708\n",
      "\n",
      "                           unweighted         uniqueness             return\n",
      "standard            0.000000 ± 0.0000  0.000000 ± 0.0000  0.480684 ± 0.1373\n",
      "balanced_subsample  0.405778 ± 0.0620  0.326313 ± 0.0933  0.674708 ± 0.0518\n",
      "max_samples         0.000000 ± 0.0000  0.000000 ± 0.0000  0.291804 ± 0.1409\n",
      "combined            0.358043 ± 0.0838  0.249652 ± 0.1109  0.674708 ± 0.0518\n",
      "\n",
      "Selected Best Classifier (balanced_subsample): RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       min_weight_fraction_leaf=0.05, n_jobs=-1,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "cv_gen = PurgedKFold(n_splits, cont_train.t1, pct_embargo)\n",
    "cv_scores_d = {k: {} for k in clfs.keys()}\n",
    "print(rf.__class__.__name__, \"Weighting Schemes\")\n",
    "all_clf_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "best_models = []\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    best_score, best_model = None, None\n",
    "    for param, clf in clfs.items():\n",
    "        w = sample_weights.values\n",
    "        cv_scores = ml_cross_val_score(\n",
    "            clf, X_train, y_train, cv_gen, \n",
    "            sample_weight_train=w, \n",
    "            sample_weight_score=w,\n",
    "            scoring=\"f1\",\n",
    "        )\n",
    "        score = cv_scores.mean()\n",
    "        cv_scores_d[param][scheme] = score\n",
    "        best_score = max(best_score, score) if best_score is not None else score\n",
    "        if score == best_score:\n",
    "            best_model = param\n",
    "        all_clf_scores_df.loc[param, scheme] = f\"{cv_scores.mean():.6f} ± {cv_scores.std():.4f}\"\n",
    "    best_models.append(best_model)\n",
    "    print(f\"{scheme} {best_model} model achieved the best f1 score of {best_score:.6f}\")\n",
    "\n",
    "print()\n",
    "pprint(all_clf_scores_df, sort_dicts=False)\n",
    "best_model = max(best_models, key=best_models.count)\n",
    "best_clf = clone(clfs[best_model])\n",
    "print(f\"\\nSelected Best Classifier ({best_model}): {best_clf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   unweighted       uniqueness           return\n",
      "accuracy       0.5640 ± 0.081   0.6234 ± 0.070   0.5116 ± 0.063\n",
      "pwa            0.5954 ± 0.103   0.7045 ± 0.070   0.5103 ± 0.065\n",
      "neg_log_loss  -0.6810 ± 0.025  -0.6501 ± 0.024  -0.7781 ± 0.058\n",
      "precision      0.3450 ± 0.036   0.3223 ± 0.046   0.5116 ± 0.063\n",
      "recall         0.5335 ± 0.186   0.3749 ± 0.181   1.0000 ± 0.000\n",
      "f1             0.4058 ± 0.062   0.3263 ± 0.093   0.6747 ± 0.052\n",
      "\n",
      "return model achieved the best f1 score of 0.674708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_cv_scores_d = {}\n",
    "all_cms = {}\n",
    "best_score, best_model = None, None\n",
    "all_cv_scores_df = pd.DataFrame(dtype=pd.StringDtype())\n",
    "\n",
    "for scheme, sample_weights in weighting_schemes.items():\n",
    "    w = sample_weights.values\n",
    "    cv_scores, cv_scores_df, cms = analyze_cross_val_scores(\n",
    "        best_clf, X_train, y_train, cv_gen, \n",
    "        sample_weight_train=w, \n",
    "        sample_weight_score=w,\n",
    "    )\n",
    "    score = cv_scores['f1'].mean()\n",
    "    all_cv_scores_d[scheme] = cv_scores\n",
    "    all_cms[scheme] = cms\n",
    "    best_score = max(best_score, score) if best_score is not None else score\n",
    "    if score == best_score:\n",
    "        best_model = scheme\n",
    "    for idx, row in cv_scores_df.iterrows():\n",
    "        all_cv_scores_df.loc[idx, scheme] = f\"{row['mean']:.6f} ± {row['std']:.3f}\"\n",
    "pprint(all_cv_scores_df)\n",
    "print(f\"\\n{best_model} model achieved the best f1 score of {best_score:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d97e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unweighted': [{'fold': 1, 'TN': 393.0, 'FP': 328.0, 'FN': 110.0, 'TP': 185.0},\n",
      "                {'fold': 2, 'TN': 483.0, 'FP': 248.0, 'FN': 158.0, 'TP': 127.0},\n",
      "                {'fold': 3, 'TN': 450.0, 'FP': 279.0, 'FN': 156.0, 'TP': 131.0},\n",
      "                {'fold': 4, 'TN': 578.0, 'FP': 161.0, 'FN': 187.0, 'TP': 90.0},\n",
      "                {'fold': 5, 'TN': 139.0, 'FP': 482.0, 'FN': 80.0, 'TP': 315.0},\n",
      "                {'fold': 6, 'TN': 336.0, 'FP': 419.0, 'FN': 91.0, 'TP': 170.0},\n",
      "                {'fold': 7, 'TN': 518.0, 'FP': 229.0, 'FN': 158.0, 'TP': 111.0},\n",
      "                {'fold': 8, 'TN': 596.0, 'FP': 127.0, 'FN': 205.0, 'TP': 88.0},\n",
      "                {'fold': 9, 'TN': 480.0, 'FP': 267.0, 'FN': 150.0, 'TP': 119.0},\n",
      "                {'fold': 10,\n",
      "                 'TN': 129.0,\n",
      "                 'FP': 554.0,\n",
      "                 'FN': 41.0,\n",
      "                 'TP': 292.0}],\n",
      " 'uniqueness': [{'fold': 1, 'TN': 30.15, 'FP': 15.23, 'FN': 8.09, 'TP': 8.55},\n",
      "                {'fold': 2, 'TN': 38.07, 'FP': 12.72, 'FN': 11.85, 'TP': 5.95},\n",
      "                {'fold': 3, 'TN': 42.39, 'FP': 14.82, 'FN': 14.37, 'TP': 6.75},\n",
      "                {'fold': 4, 'TN': 90.37, 'FP': 8.22, 'FN': 27.62, 'TP': 3.48},\n",
      "                {'fold': 5, 'TN': 15.7, 'FP': 10.91, 'FN': 8.86, 'TP': 7.94},\n",
      "                {'fold': 6, 'TN': 25.53, 'FP': 18.85, 'FN': 6.98, 'TP': 7.0},\n",
      "                {'fold': 7, 'TN': 42.51, 'FP': 15.83, 'FN': 12.6, 'TP': 5.37},\n",
      "                {'fold': 8, 'TN': 68.25, 'FP': 6.42, 'FN': 21.56, 'TP': 3.62},\n",
      "                {'fold': 9, 'TN': 52.85, 'FP': 14.41, 'FN': 14.41, 'TP': 6.12},\n",
      "                {'fold': 10, 'TN': 11.95, 'FP': 18.37, 'FN': 2.93, 'TP': 9.08}],\n",
      " 'return': [{'fold': 1, 'TN': 0.0, 'FP': 435.9, 'FN': 0.0, 'TP': 519.53},\n",
      "            {'fold': 2, 'TN': 0.0, 'FP': 514.25, 'FN': 0.0, 'TP': 489.13},\n",
      "            {'fold': 3, 'TN': 0.0, 'FP': 536.09, 'FN': 0.0, 'TP': 440.01},\n",
      "            {'fold': 4, 'TN': 0.0, 'FP': 657.04, 'FN': 0.0, 'TP': 642.66},\n",
      "            {'fold': 5, 'TN': 0.0, 'FP': 302.37, 'FN': 0.0, 'TP': 646.52},\n",
      "            {'fold': 6, 'TN': 0.0, 'FP': 484.12, 'FN': 0.0, 'TP': 447.37},\n",
      "            {'fold': 7, 'TN': 0.0, 'FP': 547.72, 'FN': 0.0, 'TP': 466.52},\n",
      "            {'fold': 8, 'TN': 0.0, 'FP': 568.0, 'FN': 0.0, 'TP': 563.98},\n",
      "            {'fold': 9, 'TN': 0.0, 'FP': 579.0, 'FN': 0.0, 'TP': 534.86},\n",
      "            {'fold': 10, 'TN': 0.0, 'FP': 361.7, 'FN': 0.0, 'TP': 423.23}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(all_cms, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(1000, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfinlab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
